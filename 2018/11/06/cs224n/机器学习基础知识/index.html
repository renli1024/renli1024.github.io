<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>机器学习基础知识 | Ren Li&#39;s blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
    <meta name="keywords" content="Ren Li's Blog" />
  
  <meta name="description" content="梯度下降（gradient decent）基本概念  什么是梯度：在多元函数中，梯度可理解为求各个变量的偏导数，最终各个偏导组合成梯度向量，即代表该函数在该点变化最快的方向。eg: \(f(x,y)=x^2+y^2\), 梯度向量为(2x,2y)，在点(1,1)处的梯度即为(2,2)，即沿(2,2)这个方向函数变化最快。 梯度下降的作用: 求损失函数的最小值. 因为梯度是函数值下降最快的方向, 所">
<meta name="keywords" content="cs224n">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习基础知识">
<meta property="og:url" content="https://renli1024.github.io/2018/11/06/cs224n/机器学习基础知识/index.html">
<meta property="og:site_name" content="Ren Li&#39;s blog">
<meta property="og:description" content="梯度下降（gradient decent）基本概念  什么是梯度：在多元函数中，梯度可理解为求各个变量的偏导数，最终各个偏导组合成梯度向量，即代表该函数在该点变化最快的方向。eg: \(f(x,y)=x^2+y^2\), 梯度向量为(2x,2y)，在点(1,1)处的梯度即为(2,2)，即沿(2,2)这个方向函数变化最快。 梯度下降的作用: 求损失函数的最小值. 因为梯度是函数值下降最快的方向, 所">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://renli1024.github.io/images/AI/batch不同取值的影响.png">
<meta property="og:updated_time" content="2019-04-01T21:44:41.957Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习基础知识">
<meta name="twitter:description" content="梯度下降（gradient decent）基本概念  什么是梯度：在多元函数中，梯度可理解为求各个变量的偏导数，最终各个偏导组合成梯度向量，即代表该函数在该点变化最快的方向。eg: \(f(x,y)=x^2+y^2\), 梯度向量为(2x,2y)，在点(1,1)处的梯度即为(2,2)，即沿(2,2)这个方向函数变化最快。 梯度下降的作用: 求损失函数的最小值. 因为梯度是函数值下降最快的方向, 所">
<meta name="twitter:image" content="https://renli1024.github.io/images/AI/batch不同取值的影响.png">
  
  
    <link rel="icon" href="/favicon.ico">
  
  <link href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  <script src="/js/pace.min.js"></script>
  

  
  

</head>

<body>
  <div id="container">
      <header id="header">
    <div id="header-outer">
        <div id="header-menu" class="header-menu-pos animated">
            <div class="header-menu-container">
                <a href="/" class="left">
                    <span class="site-title">Ren Li&#39;s Blog</span>
                </a>
                <nav id="header-menu-nav" class="right">
                    
                    <a  href="/">
                        <i class="fa fa-home"></i>
                        <span>Home</span>
                    </a>
                    
                    <a  href="/archives">
                        <i class="fa fa-archive"></i>
                        <span>Archives</span>
                    </a>
                    
                    <a  href="https://github.com/lrStyle">
                        <i class="fa fa-user"></i>
                        <span>Github</span>
                    </a>
                    
                </nav>
                <a class="mobile-header-menu-button">
                    <i class="fa fa-bars"></i>
                </a>
            </div>
        </div>
    </div>
</header>
      <div class="outer">
        <section id="main" class="body-wrap"><article id="post-cs224n/机器学习基础知识" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 class="post-title" itemprop="name">
      机器学习基础知识
    </h1>
    <div class="post-title-bar">
      <ul>
          
        <li>
          <i class="fa fa-calendar"></i>  2018-11-06
        </li>
        
      </ul>
    </div>
  

          
      </header>
    
    <div class="article-entry post-content" itemprop="articleBody">
      
            
            <h2 id="梯度下降（gradient-decent）"><a href="#梯度下降（gradient-decent）" class="headerlink" title="梯度下降（gradient decent）"></a>梯度下降（gradient decent）</h2><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML" async></script></p>
<ul>
<li>什么是梯度：在多元函数中，梯度可理解为求各个变量的偏导数，最终各个偏导组合成梯度向量，即代表该函数在该点变化最快的方向。<br>eg: \(f(x,y)=x^2+y^2\), 梯度向量为(2x,2y)，在点(1,1)处的梯度即为(2,2)，即沿(2,2)这个方向函数变化最快。</li>
<li>梯度下降的作用: 求损失函数的最小值. 因为梯度是函数值下降最快的方向, 所以经常用梯度来构造参数的更新表达式, 以此来求使得损失函数的函数值最小的参数值.</li>
</ul>
<h3 id="Vanilla-Gradient-Descent（普通梯度下降）"><a href="#Vanilla-Gradient-Descent（普通梯度下降）" class="headerlink" title="Vanilla Gradient Descent（普通梯度下降）"></a>Vanilla Gradient Descent（普通梯度下降）</h3><p>1、求解梯度向量<br>2、一点点沿着梯度的方向迭代更新函数值，使函数最终下降到局部最小值处。<br>$$<br>\theta^{new}_j=\theta^{old}_j-\alpha\nabla_{\theta}J(\theta)=\theta^{old}_j-\alpha\frac {\partial}{\partial \theta^{old}_j}J(\theta)<br>$$<br>注1: \(J(\theta)\)是损失函数, \(\theta\)是参数, \(\alpha\)是步长（step size).<br>注2: 步长\(\alpha\)的值若取太小则求解速度慢，取则会造成抖动。<br>解决方法：距离谷底较远时，步幅大些比较好（加快速度）；接近谷底时，步幅小些比较好（以免跨过界）。距离谷底的远近可以通过梯度的数值大小间接反映，接近谷底时，坡度会减小，因此可设置步长与梯度数值大小正相关。</p>
<h3 id="Stochastic-Gradient-Descent（SGD，随机梯度下降）"><a href="#Stochastic-Gradient-Descent（SGD，随机梯度下降）" class="headerlink" title="Stochastic Gradient Descent（SGD，随机梯度下降）"></a>Stochastic Gradient Descent（SGD，随机梯度下降）</h3><p>VGD中，损失函数相当于每个数据样本取平均值，因此每次更新都需要遍历所有data，当数据量太大，更新一次梯度会花费大量时间，因此并不可行。<br>解决这个问题的基本思路：只通过一个随机选取的数据(xn,yn)来获取梯度（通常损失函数都是很多项的变量加和得到的，这时只取一项计算其梯度，用来估计整体的梯度），这种方法叫随即梯度下降。<br>虽然这样估计梯度非常粗糙，但事实证明这种方法效果还不错。</p>
<h2 id="Softmax函数"><a href="#Softmax函数" class="headerlink" title="Softmax函数"></a>Softmax函数</h2><ul>
<li>作用：Takes an un-normalized vector, and normalizes it into a probability distribution. After applying Softmax, each element \(x_i\) will be in the interval \([0,1]\) and \(\sum_ix_i=1\).</li>
<li>公式：<br>$$<br>p(x_i) = \frac {exp(e_i)} {\sum_{n=1}^Nexp(x_n) }<br>$$</li>
<li>应用：可用于分类任务中，对目标进行线性分类；也经常用在神经网络中，用于将输出值归一化（原先值可能有负数，可能大于1，且所有值加和不为1），可视为产生概率分布。</li>
</ul>
<h2 id="Sigmoid函数"><a href="#Sigmoid函数" class="headerlink" title="Sigmoid函数"></a>Sigmoid函数</h2><h2 id="epoch，batch，iteration概念解释"><a href="#epoch，batch，iteration概念解释" class="headerlink" title="epoch，batch，iteration概念解释"></a>epoch，batch，iteration概念解释</h2><p>结论先行：epoch是全量数据集经过一次计算的过程，batch是全量数据集中的一小份，iteration则是batch经过一次计算的过程。（“一次计算”的含义：计算了一次梯度，并用优化算法（eg. 梯度下降）对神经网络进行了一次更新）</p>
<h3 id="batch"><a href="#batch" class="headerlink" title="batch"></a>batch</h3><ul>
<li>bacth指将数据集分为若干小份，一个小份一个小份去计算梯度、更新神经网络，通常也成为mini-batch。</li>
<li>为什么会有mini-batch<ul>
<li>神经网络中，所有的优化方案都是梯度下降，一般两种方式：第一种是遍历全部数据集算一次损失函数，然后算函数对各个参数的梯度，更新梯度，这种方法最大的缺点就是计算开销大；另一种是每看一个数据就算一次损失函数，然后求梯度更新参数，称为随机梯度下降。这种方法虽然速度块，但收敛性能不好，可能在最优点附近晃来晃去。</li>
<li>batch即是两种方案的折衷，即小批的梯度下降，把数据分为若干个批，按批来更新参数。计算量不大，同时一批中所有数据共同决定梯度下降的方向，减少了随机性和震荡性。</li>
<li>下图是三种计算方式的比较，蓝色线表示取一次取全量数据集计算，收敛效果更好，适合数据集不大的情况；红色线为随机取数据计算（Batch_Size等于1的情况），可以看出较难以收敛；绿色线为mini-batch，减轻了stochastic的震荡性，计算量增加也不大，是一种较为折衷的训练方式。</li>
</ul>
</li>
</ul>
<p><img src="/images/AI/batch不同取值的影响.png" width="400" height="250" alt="batch不同取值的影响" align="center"></p>
<ul>
<li>batch size对训练过程的影响<ul>
<li>若batch size过小，训练数据就会非常难收敛，从而导致underfitting。</li>
<li>增大batch size，不仅收敛效果更好，而且处理速度也会加快（单次batch计算可以并行化地处理更多数据，单次epoch的迭代次数减少，即提高运行速度）。</li>
<li>但增大batch size，所需内存容量增加（每次计算需要将batch中的数据加载进内存），所以也不能一味地增加bacth size。</li>
</ul>
</li>
</ul>
<h3 id="epoch"><a href="#epoch" class="headerlink" title="epoch"></a>epoch</h3><p>当完整的数据集通过了神经网络一次，这个过程就称为一次epoch，神经网络训练通常会将整个数据集在神经网络上计算多次，即多个epoch。</p>
<ul>
<li>为什么要使用多个epoch<br>提升训练效果。经验证明只对数据集计算一次不足以拟合神经网络，所以将数据集在同样的神经网络中传递多次以提升训练效果。<br>但注意epoch次数过多会导致过拟合的问题，且计算开销会增大，因此也要合理选择epoch次数。</li>
</ul>
<h3 id="iteration"><a href="#iteration" class="headerlink" title="iteration"></a>iteration</h3><p>iteration是相对batch而言的，对batch的数据进行一次计算就算做一次iteration。<br>eg. 训练集有1000个样本，batchsize=10，那么训练完整个样本就需要：1000/10 = 100次iteration（即1次epoch需要100次iteration）。</p>

            <div class="post-copyright">
    <hr />
    <div class="content">
        <p>Post Date： 2018-11-06</p>
        <p>版权声明：&nbsp;本文为原创文章，转载请注明出处</p>
    </div>
</div>

      
        
            

        
    </div>
    <footer class="article-footer">
        
        <ul class="article-footer-menu">
            
            
  <li class="article-footer-tags">
    <i class="fa fa-tags"></i>
      
    <a href="/tags/cs224n/" class="color2">cs224n</a>
      
  </li>

        </ul>
        
    </footer>
  </div>
</article>


    <aside class="post-toc-pos post-toc-top" id="post-toc">
        <nav class="post-toc-wrap">
            <ol class="post-toc"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#梯度下降（gradient-decent）"><span class="post-toc-number">1.</span> <span class="post-toc-text">梯度下降（gradient decent）</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#基本概念"><span class="post-toc-number">1.1.</span> <span class="post-toc-text">基本概念</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Vanilla-Gradient-Descent（普通梯度下降）"><span class="post-toc-number">1.2.</span> <span class="post-toc-text">Vanilla Gradient Descent（普通梯度下降）</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Stochastic-Gradient-Descent（SGD，随机梯度下降）"><span class="post-toc-number">1.3.</span> <span class="post-toc-text">Stochastic Gradient Descent（SGD，随机梯度下降）</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Softmax函数"><span class="post-toc-number">2.</span> <span class="post-toc-text">Softmax函数</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Sigmoid函数"><span class="post-toc-number">3.</span> <span class="post-toc-text">Sigmoid函数</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#epoch，batch，iteration概念解释"><span class="post-toc-number">4.</span> <span class="post-toc-text">epoch，batch，iteration概念解释</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#batch"><span class="post-toc-number">4.1.</span> <span class="post-toc-text">batch</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#epoch"><span class="post-toc-number">4.2.</span> <span class="post-toc-text">epoch</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#iteration"><span class="post-toc-number">4.3.</span> <span class="post-toc-text">iteration</span></a></li></ol></li></ol>
        </nav>
    </aside>
    



    
</section>
        
      </div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info" class="inner">
      <p>
        Powered by  <a href="http://hexo.io/" target="_blank">Hexo</a>
        Theme <a href="//github.com/wongminho/hexo-theme-miho" target="_blank">MiHo</a>
      &copy; 2019 Ren Li<br>
      </p>
    </div>
  </div>
</footer>
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<script src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
<script>
  var mihoConfig = {
      root: "https://renli1024.github.io",
      animate: false,
      isHome: false,
      share: false,
      reward: 1
  }
</script>
<div class="sidebar">
    <div id="sidebar-search" title="Search">
        <i class="fa fa-search"></i>
    </div>
    <div id="sidebar-category" title="Categories">
        <i class="fa fa-book"></i>
    </div>
    <div id="sidebar-tag" title="Tags">
        <i class="fa fa-tags"></i>
    </div>
    <div id="sidebar-top">
        <span class="sidebar-top-icon"><i class="fa fa-angle-up"></i></span>
    </div>
</div>
<div class="sidebar-menu-box" id="sidebar-menu-box">
    <div class="sidebar-menu-box-container">
        <div id="sidebar-menu-box-categories">
            
        </div>
        <div id="sidebar-menu-box-tags">
            <a href="/tags/Algorithm/" style="font-size: 12.86px;">Algorithm</a> <a href="/tags/C/" style="font-size: 11.43px;">C++</a> <a href="/tags/C-Sharp/" style="font-size: 10px;">C_Sharp</a> <a href="/tags/English/" style="font-size: 20px;">English</a> <a href="/tags/Git/" style="font-size: 10px;">Git</a> <a href="/tags/JSP/" style="font-size: 10px;">JSP</a> <a href="/tags/Java/" style="font-size: 10px;">Java</a> <a href="/tags/Lingo/" style="font-size: 10px;">Lingo</a> <a href="/tags/Linux/" style="font-size: 10px;">Linux</a> <a href="/tags/Mac/" style="font-size: 10px;">Mac</a> <a href="/tags/MachineLearning/" style="font-size: 17.14px;">MachineLearning</a> <a href="/tags/Network/" style="font-size: 15.71px;">Network</a> <a href="/tags/Other/" style="font-size: 18.57px;">Other</a> <a href="/tags/Paper-Notes/" style="font-size: 12.86px;">Paper Notes</a> <a href="/tags/SQL/" style="font-size: 10px;">SQL</a> <a href="/tags/Swift/" style="font-size: 10px;">Swift</a> <a href="/tags/TensorFlow/" style="font-size: 14.29px;">TensorFlow</a> <a href="/tags/cs224n/" style="font-size: 15.71px;">cs224n</a> <a href="/tags/nlp/" style="font-size: 10px;">nlp</a> <a href="/tags/python/" style="font-size: 17.14px;">python</a> <a href="/tags/uwtsd-modules/" style="font-size: 10px;">uwtsd_modules</a> <a href="/tags/课程笔记/" style="font-size: 10px;">课程笔记</a>
        </div>
    </div>
    <a href="javascript:;" class="sidebar-menu-box-close">&times;</a>
</div>
<div class="mobile-header-menu-nav" id="mobile-header-menu-nav">
    <div class="mobile-header-menu-container">
        <span class="title">Menus</span>
        <ul class="mobile-header-menu-navbar">
            
            <li>
                <a  href="/">
                    <i class="fa fa-home"></i><span>Home</span>
                </a>
            </li>
            
            <li>
                <a  href="/archives">
                    <i class="fa fa-archive"></i><span>Archives</span>
                </a>
            </li>
            
            <li>
                <a  href="https://github.com/lrStyle">
                    <i class="fa fa-user"></i><span>Github</span>
                </a>
            </li>
            
        </ul>
    </div>
    <div class="mobile-header-tag-container">
        <span class="title">Tags</span>
        <div id="mobile-header-container-tags">
            <a href="/tags/Algorithm/" style="font-size: 12.86px;">Algorithm</a> <a href="/tags/C/" style="font-size: 11.43px;">C++</a> <a href="/tags/C-Sharp/" style="font-size: 10px;">C_Sharp</a> <a href="/tags/English/" style="font-size: 20px;">English</a> <a href="/tags/Git/" style="font-size: 10px;">Git</a> <a href="/tags/JSP/" style="font-size: 10px;">JSP</a> <a href="/tags/Java/" style="font-size: 10px;">Java</a> <a href="/tags/Lingo/" style="font-size: 10px;">Lingo</a> <a href="/tags/Linux/" style="font-size: 10px;">Linux</a> <a href="/tags/Mac/" style="font-size: 10px;">Mac</a> <a href="/tags/MachineLearning/" style="font-size: 17.14px;">MachineLearning</a> <a href="/tags/Network/" style="font-size: 15.71px;">Network</a> <a href="/tags/Other/" style="font-size: 18.57px;">Other</a> <a href="/tags/Paper-Notes/" style="font-size: 12.86px;">Paper Notes</a> <a href="/tags/SQL/" style="font-size: 10px;">SQL</a> <a href="/tags/Swift/" style="font-size: 10px;">Swift</a> <a href="/tags/TensorFlow/" style="font-size: 14.29px;">TensorFlow</a> <a href="/tags/cs224n/" style="font-size: 15.71px;">cs224n</a> <a href="/tags/nlp/" style="font-size: 10px;">nlp</a> <a href="/tags/python/" style="font-size: 17.14px;">python</a> <a href="/tags/uwtsd-modules/" style="font-size: 10px;">uwtsd_modules</a> <a href="/tags/课程笔记/" style="font-size: 10px;">课程笔记</a>
        </div>
    </div>
</div>
<div class="search-wrap">
    <span class="search-close">&times;</span>
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
            <i class="icon icon-lg icon-chevron-left"></i>
        </a>
        <input class="search-field" placeholder="Search..." id="keywords">
        <a id="search-submit" href="javascript:;">
            <i class="fa fa-search"></i>
        </a>
    <div class="search-container" id="search-container">
        <ul class="search-result" id="search-result">
        </ul>
    </div>
</div>

<div id="search-tpl">
    <li class="search-result-item">
        <a href="{url}" class="search-item-li">
            <span class="search-item-li-title" title="{title}">{title}</span>
        </a>
    </li>
</div>
<script src="/js/search.js"></script>
<script src="/js/main.js"></script>









  <script src="/js/pop-img.js"></script>
  <script>
     $(".article-entry p img").popImg();
  </script>

  </div>
</body>
</html>