{"meta":{"title":"Ren Li's blog","subtitle":"Think and write down","description":null,"author":"Ren Li","url":"https://renli1024.github.io"},"pages":[],"posts":[{"title":"Shell常用命令总结","slug":"linux/shell常用命令总结","date":"2019-08-02T03:25:10.365Z","updated":"2019-08-05T07:56:29.718Z","comments":true,"path":"2019/08/02/linux/shell常用命令总结/","link":"","permalink":"https://renli1024.github.io/2019/08/02/linux/shell常用命令总结/","excerpt":"","text":"常用Bash命令Bash命令适用于Linux和Mac下的terminal 创建空目录（在当前目录下）：mkdir xxx： 切换目录：cd &lt;目录路径&gt;（&lt;目录路径&gt;可以是绝对路径，也可以是当前目录的相对路径） 显示当前目录路径：pwd 查看当前文件夹下的文件：ls 删除文件：rm [文件名] 删除整个文件夹：rm -rf [文件夹名] 查看当前目录下各个文件及目录占用空间大小：du -sh *，du -sh * | sort -n统计文件大小，并按文件大小排序。du: disk usage,-s, –summarize: display only total for each directory（不列举子目录的大小）-h, –human-readable: print sizes in human readable format（按KB/M/G的格式，否则会只打印Byte字节数）最后*表示列出所有的文件&amp;目录 使程序在后台运行，nohup command，这样关闭当前terminal也不会杀掉进程（使用ssh连接的场景，ssh断了执行的命令还会继续执行）nohup: no hangup，hangup意为“挂断”，hangup (HUP) signal表示用户退出登陆了（关闭了当前的terminal）（即hang up），因此程序就停止了。nohup 命令即保证了程序不会随着用户的log off而结束。 使程序打印到某个文件中，command &gt;file_name 2&gt;&amp;1 &amp;，这样程序的标准输出都会直接写到指定的文件中。&gt;：表示redirection，即将标准输出的结果输出到文件中（而不是输出到命令行中），未写明file discriptor表示写到文件中的是标准输出。2：是一种file discriptor，表示stderr，2&gt;&amp;1表示将stderr的结果redirect到和1相同的文件中（&amp;表示相同文件）（&gt;后要么接file_name，要么接&amp;x）。数字的含义：2表示的是file discriptor，0 - stdin，1 - stdout，2 - stderr。最后的&amp;：command的最后接&amp;表示命令在后台运行，terminal不用等到当前命令结束才能执行下一条命令。 查看当前的进程：ps -ef，列出所有的活动进程；若要筛选某些进程，ps -ef | grep xxx，把名字包含xxx的进程列出来。 结束进程：kill PID，结束pid对应的进程，pid：process identifier，即进程对应的序号。eg. 12345678910111213(base) renli-mbp:test lrrr$ python test.py &gt;log &amp;[1] 40207(base) renli-mbp:test lrrr$ ps 40207 PID TT STAT TIME COMMAND40207 s003 R 0:06.74 python test.py(base) renli-mbp:test lrrr$ kill 40207(base) renli-mbp:test lrrr$ ps 40207 PID TT STAT TIME COMMAND[1]+ Terminated: 15 python test.py &gt; log# 这个时候进程已经结束了，只是还没有被回收，因此会显示Terminated(base) renli-mbp:test lrrr$ ps 40207 PID TT STAT TIME COMMAND# 这时进程已经真正消失了 grep sort","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://renli1024.github.io/tags/Linux/"},{"name":"Mac","slug":"Mac","permalink":"https://renli1024.github.io/tags/Mac/"}]},{"title":"python文档写法","slug":"Python/Python文档写法","date":"2019-07-24T08:15:48.623Z","updated":"2019-07-31T09:13:41.691Z","comments":true,"path":"2019/07/24/Python/Python文档写法/","link":"","permalink":"https://renli1024.github.io/2019/07/24/Python/Python文档写法/","excerpt":"总结下python文件的文档写法，虽然针对是python的，但对大部分语言也都通用。","text":"总结下python文件的文档写法，虽然针对是python的，但对大部分语言也都通用。 文档有两方面的好处，一是可以帮助阅读代码，大部分IDE在预览函数/类时都会将其文档也实时加载出来；二是后期可以方便导出成整体的文档文件，便于用户查阅。 函数文档 这部分没有固定的格式，通常只需写明：description、params和return值三部分信息即可。 因为格式比较简单，因此也没必要使用插件，直接自己随手写了就ok。写在函数下面，这样IDE预览函数的时候就可以直接访问到文档了。 格式参考如下：1234567891011def fn(param1, param2): \"\"\"Description here. Params: param1(int): param2(int): Returns: bool: The return value. \"\"\" 类文档直接在类下面写类的描述信息即可，关于类的property和method的文档直接写在其下面即可。123456789class MyClass():@propertydef some_property(self): \"\"\"This is the property description\"\"\" return xxxdef some_method(self, param1): \"\"\"\"function document(see above section)\"\"\" 文件头文档直接在文件头写相应的描述信息即可。1234\"\"\"BERT finetuning runner.\"\"\"import tensorflow as tsimport numpy as np","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"https://renli1024.github.io/tags/Python/"}]},{"title":"TensorFlow数据输入","slug":"TensorFlow/Tensorflow数据输入","date":"2019-07-23T11:07:55.109Z","updated":"2019-07-23T12:45:27.763Z","comments":true,"path":"2019/07/23/TensorFlow/Tensorflow数据输入/","link":"","permalink":"https://renli1024.github.io/2019/07/23/TensorFlow/Tensorflow数据输入/","excerpt":"本文主要介绍了TensorFlow官方推荐的数据输入格式：tf.data.Dataset，这种格式具有两大优点：1、提供了管道式的数据输入机制，便于进行并行处理、节省输入时间；2、提供了常用的数据预处理操作，并给出了编程接口，便于编写数据预处理模块。PS：整天看英文文档，感觉中文竟然有点词穷了…遂这篇博客尝试下用英文书写，一方面便于直接引用英文文档的用词，避免说法混淆；其次也锻炼下我的英文写作能力。那么开始吧！","text":"本文主要介绍了TensorFlow官方推荐的数据输入格式：tf.data.Dataset，这种格式具有两大优点：1、提供了管道式的数据输入机制，便于进行并行处理、节省输入时间；2、提供了常用的数据预处理操作，并给出了编程接口，便于编写数据预处理模块。PS：整天看英文文档，感觉中文竟然有点词穷了…遂这篇博客尝试下用英文书写，一方面便于直接引用英文文档的用词，避免说法混淆；其次也锻炼下我的英文写作能力。那么开始吧！ 基本概念 tf.data.Dataset reprents a sequence of elements, where each data example (features) is regarded as a single seperate element. Most commonly, the element is a tuple of tensors consists of one data example and one label corresponding to the example. In addition, for the sake of readablity, we often transform the the data example to the form of dictionary where value is fature value and key is its name. Example can be found here Dataset can be constructed in two ways: 1. reading in-memory data from some array based structures like numpy arrays/pandas dataframes; 2. reading data from disk files and the formats can be csv, tsv, plain text, TFRecord. After constructing the dataset, there are usually some pre-processing works for data and we can use tf.data.Dataset.map() function to achieve data trasformation. We can use iterator mechanism to access elements of a dataset. However, in some high level APIs of tensorflow (like tf.Estimator) this process is pre-implemented and what we only need to do is providing the dataset constructed to them. Dataset Constructionfrom in-memory data We can use tf.data.Dataset.from_tensor_slices() or tf.data.Dataset.from_tensors() methods to read in-memory data into a tensor. from_tensor_slices() will slice the tensor provided along 0th dimension/axis so the dataset will get many elements. While from_tensors() method directly see the tensor passed as a single one so the dataset will only get one element. example code12345678910111213dataset1 = tf.data.Dataset.from_tensor_slices(tf.random_uniform([4, 10]))print(dataset1.output_types) # ==&gt; \"tf.float32\"print(dataset1.output_shapes) # ==&gt; \"(10,)\"dataset2 = tf.data.Dataset.from_tensor_slices( (tf.random_uniform([4]), tf.random_uniform([4, 100], maxval=100, dtype=tf.int32)))print(dataset2.output_types) # ==&gt; \"(tf.float32, tf.int32)\"print(dataset2.output_shapes) # ==&gt; \"((), (100,))\"dataset3 = tf.data.Dataset.zip((dataset1, dataset2))print(dataset3.output_types) # ==&gt; (tf.float32, (tf.float32, tf.int32))print(dataset3.output_shapes) # ==&gt; \"(10, ((), (100,))) from csv/tsv file Effectly csv/tsv files both belongs to plan text, the only difference is that in one line, csv file elements are seperated by comma(,) while tab(‘\\t’) for tsv files. So we can use tf.data.TextLineDataset to extract data of each line in the csv/tsv file. It is worth noting that this step is only to extract data out of the file, and transforming the data to corresponding format(e.g. split the line and construct feature columns) will be undertook by tf.data.Dataset.map() function。 example code12345678910111213141516171819def map_function(line): COLUMNS = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'label'] FIELD_DEFAULTS = [[0.0], [0.0], [0.0], [0.0], [0]] fields = tf.decode_csv(line, FIELD_DEFAULTS) feature = dict(zip(COLUMNS, fields)) label = feature.pop('label') return feature, labeldt = tf.data.TextLineDataset(\"path/to/iris_training.csv\")print(dt) # &lt;TextLineDataset shapes: (), types: tf.string&gt;dt = dt.map(map_function)print(dt)# &lt;MapDataset shapes: (&#123;SepalLength: (), SepalWidth: (), PetalLength: (), PetalWidth: ()&#125;, ()) \\# types: (&#123;SepalLength: tf.float32, SepalWidth: tf.float32, \\# PetalLength: tf.float32, PetalWidth: tf.float32&#125;, tf.int32)&gt; from TFRcord file TFRecord is a binary file format for tensorflow. to be updated Data preprocessing dataset = dataset.map(map_func=parse_fn), to transform data to the format approriate for model using. Functionality should be implemented in parse_fn function. Details can be seen here. How to use datasetbasic usagedataset = dataset.shuffle(1000).repeat().batch(batch_size)shuffle(buffer_size) is to shuffle the dataset, buffer_size determines the degree of shffuling.repeat() is to determine whether the data can be repeat by iterator.batch() is to set the batch size. pipeliningdata extracting by dataset and data processing by model can be executed at the same time.123456# changedataset = dataset.batch(batch_size=FLAGS.batch_size)# todataset = dataset.batch(batch_size=FLAGS.batch_size)dataset = dataset.prefetch(buffer_size=FLAGS.prefetch_buffer_size) # commonly buffer_size is set to 1 parallelizingextracting multiple data examples parallely (because data examples have little loigic dependence each other so can be highly parallelized).12345# changedataset = dataset.map(map_func=parse_fn)#todataset = dataset.map(map_func=parse_fn, num_parallel_calls=FLAGS.num_parallel_calls)","categories":[],"tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://renli1024.github.io/tags/TensorFlow/"}]},{"title":"Estimator用法","slug":"TensorFlow/Estimator","date":"2019-07-21T09:24:16.762Z","updated":"2019-08-07T08:07:03.338Z","comments":true,"path":"2019/07/21/TensorFlow/Estimator/","link":"","permalink":"https://renli1024.github.io/2019/07/21/TensorFlow/Estimator/","excerpt":"Estimator是Tensorflow提供的一种高阶API，在数据输入输出、模型构建、模型配置、模型保存等方面都进行了封装，隐藏了传统静态图的运行流程和底层细节，便于研究人员更专注于模型本身，本文即对Estimator的用法进行简要介绍。","text":"Estimator是Tensorflow提供的一种高阶API，在数据输入输出、模型构建、模型配置、模型保存等方面都进行了封装，隐藏了传统静态图的运行流程和底层细节，便于研究人员更专注于模型本身，本文即对Estimator的用法进行简要介绍。 Estimators的好处 模型内部有并行优化，因此无需修改代码就可以直接将运行在本地的代码部署到服务器/GPU集群/TPU上； Estimators对模型各部分进行了封装，因此便于代码重用； 代码可读性更好，隐藏了tensorflow底层的实现细节。 如何使用Pre-made Estimators 构造数据输入函数input_fninput_fn的任务：将从文件中读入的feature和label封装起来，转换为dataset的形式（或者是dictionary &amp; label 的形式，本质是一样的，dataset就是对其的封装），以此来作为Estimator的输入数据。通常训练、评估和测试集各构造一个函数：train_input_fn, eval_input_fn, test_input_fn，也可选择直接在函数内部读取文件，返回一个dataset即可。 123456789101112131415# dataset的形式def train_input_fn(features, labels, batch_size): \"\"\"An input function for training\"\"\" # Convert the inputs to a Dataset. dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels)) # Shuffle, repeat, and batch the examples. return dataset.shuffle(1000).repeat().batch(batch_size)# dictionary &amp; label的形式def input_fn(dataset): # manipulate dataset, extracting the feature dict and the label return feature_dict, label# 输出1：训练/测试数据(dictionary)，key（str）: feature name, value（tensor）: feature data；# 输出2：标签label（tensor）：包含所有数据的标签。 构造feature columnsfeature columns是tensorflow的一种描述数据的格式，包含了数据/feature的名称、类型和一些预处理操作，Estimator会根据feature columns的描述来决定如何处理传入的数据（dataset）。feature columns类型：list，里面元素类型：tf.feature_column。 1234# Feature columns describe how to use the input.my_feature_columns = []for feature_key in train_features.keys(): my_feature_columns.append(tf.feature_column.numeric_column(key=feature_key)) 初始化Pre-made Estimator，传入feature columns、以及必要的模型配置信息。 1234567# Build a DNN with 2 hidden layers and 10 nodes in each hidden layer.classifier = tf.estimator.DNNClassifier( feature_columns=my_feature_columns, # Two hidden layers of 10 nodes each. hidden_units=[10, 10], # The model must choose between 3 classes. n_classes=3) 调用train/eval/predict方法来进行训练、评估和预测。 1234# 训练模型classifier.train( input_fn=lambda:train_input_fn(features, labels, batch_size), steps=train_steps) input_fn参数要求传入是无参的函数句柄，因此使用lambdab表达式来构造； steps规定了函数训练多少步停止（可以由数据大小、epoch数和batch size算出），在eval过程中不用指定steps。 1234567# 评估模型eval_result = classifier.evaluate( input_fn=lambda:iris_data.eval_input_fn(test_x, test_y, args.batch_size))print('\\nTest set accuracy: &#123;accuracy:0.3f&#125;\\n'.format(**eval_result))# output# Test set accuracy: 0.967 The eval_result dictionary also contains the average_loss (mean loss per sample), the loss (mean loss per mini-batch) and the value of the estimator’s global_step (the number of training iterations it underwent). 123456789101112131415161718192021222324252627# 使用模型预测expected = ['Setosa', 'Versicolor', 'Virginica']predict_x = &#123; 'SepalLength': [5.1, 5.9, 6.9], 'SepalWidth': [3.3, 3.0, 3.1], 'PetalLength': [1.7, 4.2, 5.4], 'PetalWidth': [0.5, 1.5, 2.1],&#125;predictions = classifier.predict( input_fn=lambda:eval_input_fn(predict_x, batch_size=args.batch_size))template = ('\\nPrediction is \"&#123;&#125;\" (&#123;:.1f&#125;%), expected \"&#123;&#125;\"')for pred_dict, expec in zip(predictions, expected): class_id = pred_dict['class_ids'][0] probability = pred_dict['probabilities'][class_id] print(template.format(iris_data.SPECIES[class_id], 100 * probability, expec))# output# Prediction is \"Setosa\" (99.6%), expected \"Setosa\"# Prediction is \"Versicolor\" (99.8%), expected \"Versicolor\"# Prediction is \"Virginica\" (97.9%), expected \"Virginica\" Estimator.predict()returns a Python iterable, yielding a dictionary of prediction results for each example. 而prediction results具体是什么结构则要看模型（model_fn）中是怎么定义的。本例中即为dict类型，key包括class_ids, probabilities等，具体情况具体分析。 如何自己构造Estimators 自己构造Estimator和Pre-made Estimators的不同就在于：1. model function（其定义了模型的结构和参数）；2. metrics &amp; loss 函数（用于评价模型并对模型进行优化）。 使用Pre-made Estimators时别人已经帮你实现好了，而自己构造Estimators则需要先自己实现mode function，然后再传入Estimator中即可（loss函数一般在model function中实现）。 Feature Columns介绍 feature columns是tensorflow的一种描述数据的格式，包含了数据/feature的名称、类型和一些预处理操作，Estimator会根据feature columns的描述来决定如何处理传入的数据（dataset）。 feature columns类型：list，里面的元素类型：tf.feature_column。 tf.feature_column总共有两大类：Dense Column（数值数据）和Categorical Column（类别数据），以及bucketized column(兼具两者的特点)。 类别(前面都有tf.feature_column.) 解释 numeric_column 最简单的数值数据, here) 函数详细解释： tf.feature_column.numeric_column()12345678910111213tf.feature_column.numeric_column( key, # 数据命名 shape=(1,), # 数据元的shape default_value=None, dtype=tf.dtypes.float32, # 数值类型，默认float32 normalizer_fn=None)# Represent a 10-element vector in which each cell contains a tf.float32.vector_feature_column = tf.feature_column.numeric_column(key=\"Bowling\", shape=10)# Represent a 10x5 matrix in which each cell contains a tf.float32.matrix_feature_column = tf.feature_column.numeric_column(key=\"MyMatrix\", shape=[10,5]) Bucketized column Dataset介绍Feature Column模型保存 checkpoint Estimator会自动保存两类文件：checkpoint和event file，前者是保存模型的结构、参数等信息，后者是保存训练期间的变量信息（如loss、global_step等）。 构建Estimator时通过传入model_dir参数来指定模型保存的路径。 模型重新训练时会自动加载最近的一次checkpoint文件，因此可以实现模型的继续训练。","categories":[],"tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://renli1024.github.io/tags/TensorFlow/"}]},{"title":"","slug":"nlp/bert","date":"2019-07-16T12:01:01.319Z","updated":"2019-07-17T00:56:49.758Z","comments":true,"path":"2019/07/16/nlp/bert/","link":"","permalink":"https://renli1024.github.io/2019/07/16/nlp/bert/","excerpt":"","text":"language modelling 何为语言模型？语言模型本质任务是预测，即通过上文来预测下文，也可理解为生成模型（生成单词/句子等）；而生成的词向量只能说是语言模型的副产物，可以理解为语言模型所需要一些信息蕴含在了其中（最主要的是语义方面的信息），因此其也可以作为一维feature作为其他任务的输入；而比如在word2vec中词向量的某些特性：如相近词义单词在向量空间中离得近、词向量间有加减的线性关系等，也可理解为语言模型的副产物。 目前language modelling主要有两类方法：一种是feature based方法，先训练好词向量，之后将词向量作为一维特征输入下游任务模型中，训练下游任务模型来做；第二种是fine-tuning based方法，同样是训练词向量，这种方法分为pretrain和fine-tune两步，pre-train阶段同样是训练词向量，在fine-tune阶段沿用训练好的模型结构和模型参数，通过增加输出层的方式来匹配下游任务的输出格式（输入格式和pretrain阶段保持一致），同时使用下游任务的数据集来微调模型参数，从而使模型适配下游任务motivation of bert 传统语言模型要么是单向left-to-right的（Mikolov 2013 word2vec，训练任务是通过前面的词预测后面的词），要么只是将左边和右边的embedding简单拼接在一起（ELMo）（导致see itself的问题？），都没有充分利用左右上下文的信息。 作者认为双向模型可以improve pretrain fine-tune模型，而且fine-tune模型无需task spesific的模型结构，更有通用性。","categories":[],"tags":[]},{"title":"","slug":"nlp/attention","date":"2019-07-16T11:53:32.939Z","updated":"2019-07-17T03:13:12.732Z","comments":true,"path":"2019/07/16/nlp/attention/","link":"","permalink":"https://renli1024.github.io/2019/07/16/nlp/attention/","excerpt":"","text":"attention基本概念self-attentiontransformer是一种序列转换（sequence trunsduction）模型，不依赖任何循环/卷积神经网络结构，只使用注意力机制。 motivation of transformer 计算量减少（相比循环和卷积结构） 计算过程更好的可并行性（循环神经网络并行性很差） 更好地学习长距离的依赖（循环神经网路当序列元素间距离增加时，就更不容易学依赖）","categories":[],"tags":[]},{"title":"TensorFlow模型保存和重新加载","slug":"TensorFlow/TensorFlow模型保存和加载","date":"2019-04-02T22:16:41.219Z","updated":"2019-06-12T03:22:06.269Z","comments":true,"path":"2019/04/03/TensorFlow/TensorFlow模型保存和加载/","link":"","permalink":"https://renli1024.github.io/2019/04/03/TensorFlow/TensorFlow模型保存和加载/","excerpt":"训练好的模型参数保存起来，以便以后直接使用或进行进一步的训练，这是我们经常要做的事情，本文对TensorFlow模型保存和重新加载的方法进行了介绍。","text":"训练好的模型参数保存起来，以便以后直接使用或进行进一步的训练，这是我们经常要做的事情，本文对TensorFlow模型保存和重新加载的方法进行了介绍。 保存模型本质上保存的是模型的各项参数，对神经网络来说就是网络的结构信息、各个边的权值等，tf中提供了两种可以用来保存模型的格式： checkpoints格式，a format dependent on the code that created the model。对应的tf.train.Saver类。 SavedModel格式，a format independent of the code that created the model。对应tf.saved_model模块。 tf.train.Saver基本方法Saver类保存模型的基本方法为：1、定义变量2、使用Saver.save()方法保存3、重新定义变量4、使用Saver.restore()方法加载 这种方法要求按照原有模型重新定义一遍变量和网络结构，restore()方法会将保存的值加载到对应的变量中（即加载到名字相同的变量）。 因为重新定义一遍网络太过麻烦，且要保证重新定义的变量名字、类型都与原变量相同，因此这种方法实际用处不大。 example code：1234567891011121314151617181920212223# save the modelimport tensorflow as tf W = tf.Variable([[1,1,1],[2,2,2]],dtype = tf.float32,name='W') v = tf.Variable([[4,4],[5,5]], dtype = tf.int32, name='v')s = tf.train.Saver()with tf.Session() as sess: sess.run(tf.global_variables_initializer()) s.save(sess, \"run/model\") # restore the modelimport tensorflow as tf # 类型必须相同W = tf.Variable(tf.zeros([2,3], dtype = tf.float32), name='W') v = tf.Variable(tf.zeros([2,2], dtype = tf.int32), name='v')s = tf.train.Saver()with tf.Session() as sess: s.restore(sess, 'run/model') # 只用传入文件前缀即可 print(W.eval()) print(v.eval()) 不需要重新定义网络结构的加载方法很多时候我们都希望能够读取一个文件然后直接使用模型，而不是还要把模型重新定义一遍，因此就有了这种方法。基本流程为：1、定义变量2、使用Saver.save()方法保存3、使用tf.train.import_meta_graph()加载网络结构，会返回一个saver对象4、使用saver.restore()方法恢复网络中的变量值5、使用graph.get_operation_by_name()和graph.get_tensor_by_name()方法获取op和tensor；使用collection机制获取之前保存的值。 example code： 12345678910111213141516171819202122232425import tensorflow as tf# 不需要定义网络结构的方法# store the modelW = tf.Variable([[1,1,1],[2,2,2]],dtype = tf.float32,name='W') v = tf.Variable([[4,4],[5,5]], name='v')b = tf.Variable([[7,7], [8,8]], name='b')tf.add_to_collection('b_collection', b)s = tf.train.Saver()with tf.Session() as sess: sess.run(tf.global_variables_initializer()) s.save(sess, \"run/model\")# restore the modelwith tf.Session() as sess: s = tf.train.import_meta_graph(\"run/model.meta\") s.restore(sess, \"run/model\") # 只用传入文件前缀即可 graph = tf.get_default_graph() W = graph.get_tensor_by_name(\"W:0\") v = graph.get_tensor_by_name(\"v:0\") b = tf.get_collection(\"b_collection\")[0] print(W.eval()) print(v.eval()) print(b.eval()) 如何获取op：tf.Graph.get_operation_by_name(&#39;name&#39;) 如何获取tensor/variable/placeholder：tf.Graph.get_tensor_by_name(&#39;name&#39;)，注意tensor的命名规则：&lt;op_name&gt;:&lt;output_index&gt;。 对于Variable，get_tensor_by_name是获取了其内部封装的tensor，但可以像使用Variable那样使用这个的tensor（因为variable的外部op如v/initial_value, v/Assign, v/read也是被保留在图中的）。 saver只会存tensorflow相关的数据：如tensor、operation和collection，对于python的变量类型（如string，int），saver默认不会保存，可以通过collection来存（但需要注意：string在collection中是以b’str’形式保存的，取出后需要转化为utf-8格式）。 如何重新开始训练模型 在初次定义模型时，不要把输入数据、标记数据定义为tensor类型，这样saver就不会保存训练数据，节省保存模型的大小。 恢复模型后可重新生成训练数据来训练，数据一般也会做shffule处理，所以不用担心会一直训练某一小部分的数据。 初次定义模型时养成好习惯，对tensor/opertaion等都要起好名字，这样才能在以后恢复。 需要恢复的重要变量有：train_op，loss，global_step，模型输入的placeholder等。训练过程其实就是sess.run(loss, train_op)，所以这些变量尤为重要。 不需要恢复optimizer类，只需要恢复train_op即可，train_op中就已经包含了当初定义的optimizer信息。 恢复模型后不用再sess.run(tf.global_variables_initializer())，否则保存的变量值都会被重新覆盖掉。 模型的保存格式 模型和数据会被保存为三个文件：filename.data-00000-of-00001、filename.index、filename.meta，三个文件名字都是一样的，只是后缀不同。 三个文件作用如下：.meta文件存储计算图结构，.data文件存储计算图中所有的变量值，.index文件则负责指示如何在.data文件中查找计算图变量对应的值（相当于一个.meta文件和.data文件的映射）。 initinit( var_list=None, reshape=False, sharded=False, max_to_keep=5, keep_checkpoint_every_n_hours=10000.0, name=None, restore_sequentially=False, saver_def=None, builder=None, defer_build=False, allow_empty=False, write_version=tf.train.SaverDef.V2, pad_step_number=False, save_relative_paths=False, filename=None) 参数解释： var_list：指定要保存的变量，默认是保存所传入Session中的全部变量； max_to_keep：最多保存的模型数量，默认为5，即只保存最近的5次模型训练结果；若为None或0，则保存所有的模型。 keep_checkpoint_every_n_hours：每隔多长时间保存一次模型； 通常情况下直接调用构造函数即可，不用指定参数。 tf.train.Saver.save()save( sess, save_path, global_step=None, latest_filename=None, meta_graph_suffix=’meta’, write_meta_graph=True, write_state=True, strip_default_attrs=False) 函数作用：保存模型。 参数解释： sess：运行模型的session，默认是将session中所有的参数都保存下来； save_path：保存模型的路径，可以是相对路径，也可以是绝对路径。 global_step：文件名后缀，用训练步数对文件名添加的数字标记。 注1：save_path其实是模型文件名的一部分（前缀），比如如果值为”ckpt/mnist”，会将模型保存到ckpt目录下，文件名为”mnist-xxx”，xxx为后缀，由global_step指定。 注2：无需事先创建目录，若路径中的目录不存在tf会自动创建。 return：返回文件的绝对路径，type：string。 tf.train.Saver.restore()restore( sess, save_path) 函数作用：恢复之前保存的模型。 参数解释： sess：要恢复到哪个session； save_path：文件保存的路径。可直接传入save()函数的返回值来掉用。 return：void tf.train.import_meta_graphtf.train.import_meta_graph( meta_graph_or_file, clear_devices=False, import_scope=None, **kwargs) 函数作用：加载计算图结构信息。 参数解释： meta_graph_or_file：.meta后缀文件路径 return：返回一个Saver对象，可后续进行restore操作 tf.train.Saver.last_checkpoints Saver类的一个属性，type：list，保存了储存在磁盘上的模型的名字（包括路径），依照产生顺序从旧到新排列。 list中任何一个元素都可以直接作为参数传给restore()函数。","categories":[],"tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://renli1024.github.io/tags/TensorFlow/"}]},{"title":"Python3函数、模块用法记录","slug":"Python/Python3重要函数记录","date":"2019-04-01T13:29:50.557Z","updated":"2019-08-01T11:37:39.511Z","comments":true,"path":"2019/04/01/Python/Python3重要函数记录/","link":"","permalink":"https://renli1024.github.io/2019/04/01/Python/Python3重要函数记录/","excerpt":"","text":"os模块os 模块提供了非常丰富的方法用来处理文件和目录，具体介绍如下。 os.makedirs(path)：按照所给地址生成目录。os.pathos.path模块主要用于处理文件的目录信息，常用方法有如下几个： os.path.join(path, *paths)：将多个字符串合成一个目录，中间以目录分隔符隔开。使用这个函数保证在各个系统下目录元素都可以被正确地组合。 os.path.curdir：这是path模块的一个属性而非函数，返回当前目录的相对路径（在Mac OSX下就是.）。 os.path.abspath(path)：将相对路径转化为绝对路径。 os.path.exists(path)：检查某个目录或文件是否存在。关于相对路径 python文件中写的相对路径都是相对与当前目录下而言的，如果直接调用命令行：则是相对当前命令行的路径；如果在IDE里执行，通常情况下是相对于当前IDE打开的项目文件夹的路径（因为项目文件夹是命令的执行路径），在其他语言的IDE里情况也类似。 相对路径不一定是相对python文件所在的文件夹，而是相对执行命令的路径。 time模块Python提供了time 和 calendar 两个模块可以用于处理日期和时间相关信息，首先介绍time模块。 time.time()：返回当前时间的时间戳（1970纪元后所经过的浮点秒数）。 python导入自建模块 模块（modeule）的实现就是.py文件，想使用其他文件中的函数/类，文件开头声明from 文件名 import 函数/类即可。 在同一个目录下的模块文件可直接导入（当前的目录会被默认导入到系统搜索路径中）。 导入在不同目录下的文件，总共分为三步：eg. 在目录a中导入目录b下的crawler.py文件： 首先目录b下要有__init__.py文件（空文件即可），有这个文件目录b才能被初始化为模块。 将目录b的父地址添加到模块搜索路径中，import sys，sys.path.append(&quot;parent_dirctory_of_b&quot;)，只有这样目录b才能被检测到。 import b.crawler即可（模块间的上下级关系通过.来表示）。注1：或者将目录b的地址添加到搜索路径，之后直接import crawler注2：添加到搜索路径中的地址，绝对路径or相对路径都可以（推荐相对路径），但注意相对路径不一定是相对python文件的地址，在IDE中通常为相对当前工程文件夹的地址。 import 和 from import的区别 import module1语句直接将这个模块导入到当前文件中，如果要使用模块中的函数/类，则需要通过模块来调用：module1.function1/module1.class1 from module1 import function1则直接导入特定的函数/类，使用函数时就直接调用function1即可。 何时使用from import：一般用来导入类，因为调用类本身的成员就需要加点.，再加上模块和类之间的点，显得比较冗杂。注1: 两种方法都是赋值语句，相当于在新的文件中声明了相应的变量，因此要注意源文件中不能有重名的module1/function1变量名，否则会被覆盖。注2：不推荐from module1 import *这种方式，因为很有可能造成变量名冲突（module1模块中和当前文件中）。 其他函数记录存储/加载数据 picklefile为文件对象，open(&quot;file_address&quot;, &quot;wb&quot;/&quot;rb&quot;)存储为wb，读取维rb，都按二进制来就行。pickle.dump(obj, file)：存储pickle.load(file)：加载 如何查看变量类型type(object)函数：123i = 123print(type(i))# &lt;type 'int'&gt;","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"https://renli1024.github.io/tags/Python/"}]},{"title":"Python3 数据结构","slug":"Python/Python3 Data Structure","date":"2019-03-06T12:36:45.514Z","updated":"2019-07-28T04:18:31.350Z","comments":true,"path":"2019/03/06/Python/Python3 Data Structure/","link":"","permalink":"https://renli1024.github.io/2019/03/06/Python/Python3 Data Structure/","excerpt":"本文介绍了python3常用的数据结构。","text":"本文介绍了python3常用的数据结构。 字符串string双引号””、单引号’’括起来都是字符串访问字符串中元素：str[i]数字转字符串：str()；字符串转数字：int()/float()求字符串长度：len()截取字符串：str[x:y]，前包后不包字符-&gt;ASCII：ord(&#39;a&#39;); ASCII-&gt;字符：chr(78) 转义字符 符号 意义 \\n 换行符，另起一行 \\r 将光标的位置回退到本行的开头位置，因此再输出就会覆盖之前的值 注1：\\r在VSCode的DEBUG CONCOLE下不起效果（不会覆盖之前的值），只在TERMINAL下起效果。 注2：用\\r可以实现很多有趣的小功能，如倒计时（每次用新string覆盖上一条string）、进度条等。 格式化字符串百分号法 占位符 含义 %d 十进制整数 %f 浮点数，保留小数点后面六位 .3%f 浮点数，保留小数点后面三位 %e 浮点数，保留小数点后面六位有效数字，指数形式输出 %s 字符串 具体用法：带占位符的字符串 + % + 要填充的内容（有多项的话用括号括起来，中间用逗号分割）12print('%d' % 20) # 输出20s1 = \"i am %s, i am %d years old\" % ('jeck',26) #按位置顺序依次输出 format法 由花括号{}充当占位符123str1 = \"I like &#123;&#125;\".format(\"you\") # \"I like you\"str2 = \"I like &#123;0&#125; and &#123;1&#125;\".format(\"running\",\"swimming\") # \"I like running and swimming\"str3 = \"I like &#123;&#125; and &#123;&#125;\".format(\"running\",\"swimming\") # 与str2等价，会自动按0,1,2的顺序向占位符中填充 列表list即数组，但里面元素类型可不一致，lst=[‘a’,13,”lrrr”]数组尾追加元素：lst.append，数组间插入元素：lst.insert(i,x)删除数组元素：lst.pop(i)，返回值为删除的元素将数组元素顺序颠倒：lst.reverse()数组排序函数：lst.sort()字符串-&gt;数组：split();数组-&gt;字符串：join() List Comprehension机制list comprehension是python中一种简洁的生成list的方式，可以在括号[]内部写生成的表达式，甚至可以加一些逻辑判断条件，用法如下：123456789101112131415161718192021222324252627# create a new list with the values doubledvec = [-4, -2, 0, 2, 4]list1 = [x*2 for x in vec] # [-8, -4, 0, 4, 8] # 加判断条件list1 = [x for x in vec if x &gt;= 0] # [0, 2, 4]# call a method on each elementfreshfruit = [' banana', ' loganberry ', 'passion fruit '][weapon.strip() for weapon in freshfruit]# 生成 ['banana', 'loganberry', 'passion fruit']# 同样可以生成元组[(x, x**2) for x in range(6)]# 若有多个for语句则从左到右依次嵌套# flatten a list using a listcomp with two 'for'vec = [[1,2,3], [4,5,6], [7,8,9]]# 生成 [1, 2, 3, 4, 5, 6, 7, 8, 9][num for elem in vec for num in elem][(x, y) for x in [1,2,3] for y in [3,1,4] if x != y]# 生成 [(1, 3), (1, 4), (2, 3), (2, 1), (2, 4), (3, 1), (3, 4)]# 相当于# for x in [1,2,3]:# for y in [3,1,4]:# if x != y: 元组tuple元素值不可改变的list，遍历操作与list相同初始化：t=(1,&quot;ab&quot;,[123,&quot;abc&quot;]) 或 d=dict([(&quot;1&quot;,&quot;22&quot;),(&quot;2&quot;,&quot;22&quot;)])用数组初始化优点：遍历比列表快；对数据进行“写保护”；可在字典中用作key 字典dict即哈希表，以键值对存储：dic={&quot;n1&quot;:&quot;ab&quot;,&quot;n2&quot;:&quot;cd&quot;,&quot;n3&quot;:12}键(key)不可修改，可以是字符串或元组；但键值可以更改。通过键访问键值：dic[‘n1’] 如何根据value查key123for k, v in dictionary.items(): if v == search_avalue: print(k) 字典和JSON格式相互转化12345678910111213import jsondict_obejct = &#123; 'a' : 1, 'b' : 2, 'c' : 3, 'd' : 4, 'e' : 5 &#125;# 将dict对象转化为json字符串dict_json = json.dumps(dict_obejct)print(dict_json)# &#123;\"a\": 1, \"b\": 2, \"c\": 3, \"d\": 4, \"e\": 5&#125;# 之后直接将字符串写到文件中里即可（最后记得加 \\n）# 从文件中读取的json字符串json_str = \"&#123;\\\"a\\\": 1, \\\"b\\\": 2, \\\"c\\\": 3, \\\"d\\\": 4, \\\"e\\\": 5&#125;\"dict_object = json.loads(json_str)# JSON的object类型直接即转化为python的dict类型 JSON类型和Python类型转化(默认和dict相互转化) JSON Python object dict array list/(tuple) string str number(int) int, long number(real) float true True false False null None 集合set无序、不重复序列，s=set([123,&#39;lrrr&#39;,&quot;asd&quot;])-&gt;s={&#39;lrrr&#39;, 123, &#39;asd&#39;}集合增加元素：add；删除元素：remove不可改变的集合：frozenset，集合一旦创建就不能再增加/删除元素。可进行集合的“交并补”等运算，得到新的集合。 range类型 用于产生一个有序序列，通常和for循环嵌套使用 range(a,b,t)：a为起点，b为终点，t为步长，是一个前开后闭的区间（包括起点不包括终点）注：a默认0，t默认1。range主要用于产生一个序列，在for in循环中很常见123x = range(10) #x是从0到9的一个range类型for i in x: print(i) #循环输出0-9 range转List：list(range(1,10,3)) 迭代器iter123456遍历操作while True: it.__next__()数组转迭代器：it=iter(list)文件流默认为可迭代对象，可直接调用__next__() generator和可迭代类型（Iterator）类似，区别：其不保存所有值，其只计算一个值，保存一个值，计算下一个值时这个值就会被覆盖。适用于数据只使用一次的场景。在函数中可使用yield语句来返回一个generator，类似return语句，但区别是在调用时其并没有真正计算值，只是返回了一个generator，等到真正访问generator时才会去一个一个地计算其值。","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"https://renli1024.github.io/tags/Python/"}]},{"title":"TensorFlow 函数、类记录","slug":"TensorFlow/TensorFlow重要函数记录","date":"2019-03-05T23:01:35.967Z","updated":"2019-07-21T05:55:15.421Z","comments":true,"path":"2019/03/06/TensorFlow/TensorFlow重要函数记录/","link":"","permalink":"https://renli1024.github.io/2019/03/06/TensorFlow/TensorFlow重要函数记录/","excerpt":"本文介绍了我遇到的一些TensorFlow的函数和类，记录了相关用法和自己的理解，一方面为了整理自己的思路，加深印象，另一方面也方便以后查阅。","text":"本文介绍了我遇到的一些TensorFlow的函数和类，记录了相关用法和自己的理解，一方面为了整理自己的思路，加深印象，另一方面也方便以后查阅。 构建卷积层tf.nn.conv2dtf.nn.conv2d( input, filter, strides, padding, use_cudnn_on_gpu=True, data_format=’NHWC’, dilations=[1, 1, 1, 1], name=None) 最常见的卷积层构造方法。 参数解释： input：为输入卷积层的数据，用4维的tensor来表示，shape为[batch, in_height, in_width, in_channels]，具体含义是[训练时一个batch的图片数量, 图片高度, 图片宽度, 图像通道数]，注意这是一个4维的Tensor，要求类型为float32和float64其中之一； filter：表示卷积核，同样是4维的tensor，shape为[filter_height, filter_width, in_channels, out_channels]，具体含义是[卷积核的高度，卷积核的宽度，图像通道数，卷积核个数]，ilter_height, filter_width也可以说是卷积核在input的对应维度上的window size；第三维in_channels，就是参数input的第四维；out_channels有两个含义，一是有多少个卷积核，二是最终输出图像的通道数（一个卷积核的计算结果对应一个输出通道的值）； strides：表示卷积核在各个维度上的跨度，同样是4维tensor（各个维度的意义和input参数相同），[1, 1, 1, 1]表示卷积核一个一个像素移动着计算，[1, 2, 2, 1]表示在in_height和in_width维度上每隔一个像素计算一次。 padding：表示如何计算图像边缘的像素。只有两个可选值：VALID和SAME，VALID表示图像边缘一圈的像素不计算，SAME表示将图像边缘进行扩充以计算所有图像内像素（通常用0填充）。详细内容可参见TensorFlow官方Neural Network教程。 return：返回值为经过卷积计算的结果（也被成为feature map），shape为[batch, out_height, out_width, out_channels]，其中batch和input的batch相同，后三个参数则由卷积核来决定。 如何计算：由卷积核在input图像上不断滑动，做卷积预算，最终得出输出的feature map，feature map的长宽要试输入图像、卷积核和padding方式共同决定。 tf.nn.max_pooltf.nn.max_pool( value, ksize, strides, padding, data_format=’NHWC’, name=None) 函数作用：构建池化层的操作，实现下采样。 参数解释： value：需要池化的输入，一般池化层接在卷积层后面，所以输入通常是feature map，所以依然是[batch, height, width, channels]这样的shape； ksize：池化窗口在各维度上的大小，一般是[1, height, width, 1]，即保持batch和channel维度不变，只在height和width维度上做池话操作； strides：和卷积类似，窗口在每一个维度上滑动的步长，一般是[1, stride, stride, 1]（保持batch和channel不变）； padding：和卷积类似，可取’VALID’ 或者’SAME’； return：返回经过maxpool计算后的tensor，shape为[batch, height, width, channels]。 这个函数实现的是max_pool（最大池化操作），即在一个范围内的值中选最大值，作为卷积后二次提取的特征。 tf.train.Optimizer类 这个类是tensorflow中各种优化器的父类，作用：给定一个目标函数/损失函数，根据一定的算法（优化器算法），来不断计算、更新函数中的变量，以使得最终函数取得最小值，即达到优化目标。 下面介绍一些常用的函数API，虽然在各个优化器子类中会有一定变化，但大体还是一致的。 常用的优化类 GradientDescentOptimizer：梯度下降优化器； AdamOptimizer：Adam优化器，一般直接用这个就行； init通常会在初始化时定义优化器的学习率/更新率，egoptimizer = tf.train.AdamOptimizer(1e-3)。 compute_gradientscompute_gradients( loss, var_list=None, gate_gradients=GATE_OP, aggregation_method=None, colocate_gradients_with_ops=False, grad_loss=None) 函数作用：计算loss函数中各变量的梯度。 参数解释： loss：损失函数，在tf中就是一个变量； var_list：需要计算梯度的变量列表，只有在这个列表中的变量才会计算梯度，默认是TRAINABLE_VARIABLES collection中的所有变量。那有人可能会问，TRAINABLE_VARIABLES collection里那么多变量，岂不是会有很多多余的？是这样的，但因为有那些多余的变量都不再loss函数中，因此计算出来的梯度也是0，所以也不会有影响。 gate_gradients：指定了计算操作可以并行化的程度，通常不管。 return：A list of (gradient, variable) pairs，即返回一个梯度-变量对的列表，反应了每个变量所计算出的梯度。 apply_gradientsapply_gradients( grads_and_vars, global_step=None, name=None) 函数作用：用计算出来的梯度更新变量。 参数解释： grads_and_vars：List of (gradient, variable) pairs，即为compute_gradients函数的返回值。 global_step：标记变量，记录已进行了多少次变量更新操作，每更新一次global_step会自动加1。 注：在一次apply_gradients中会进行多次变量更新操作（会一直优化变量直到达到了指定误差），因此需要一个变量来记录进行了多少次更新。 return：返回op，执行该操作即进行优化更新操作。 minimizeminimize( loss, global_step=None, var_list=None, gate_gradients=GATE_OP, aggregation_method=None, colocate_gradients_with_ops=False, name=None, grad_loss=None) 函数作用：该函数相当于compute_gradients和apply_gradients的封装（先进行compute_gradients再进行apply_gradients），直接就返回一个最小化的Operation操作，没有中间先得到梯度、再应用梯度这些步骤了，更为简便。 return：返回op，执行该操作即进行优化更新操作。 如何使用Optimizer 直接调用minimize函数 12345opt = GradientDescentOptimizer(learning_rate=0.1)opt_op = opt.minimize(loss)# 执行优化操作opt_op.run() 如果想对梯度进行一些修改，或者想观察梯度的变化情况，则分开执行compute_gradients和apply_gradients函数，中间可随意操作梯度，只要保证梯度以(gradient, variable) list的形式传入即可。 123456789101112opt = GradientDescentOptimizer(learning_rate=0.1)# 计算梯度grads_and_vars = opt.compute_gradients(loss)# 对梯度进行操作capped_grads_and_vars = [(MyCapper(gv[0]), gv[1]) for gv in grads_and_vars]# 更新变量opt_op = opt.apply_gradients(capped_grads_and_vars)# 执行优化操作opt_op.run() 注1：执行一次minimzie()/apply_gradients()返回的op操作，就相当于更新一次神经网络各边的权值（即函数中指定的var_list），明显只更新一次肯定不能使网络达到最优，因此就要多次调用op操作，而具体调用多少次呢？大多情况下没有明确的答案，要看何时loss函数收敛到一定范围就可以了。注2：一般是一个mini-batch调用一次优化op，然后设置一个epoch次数（如300、500），使神经网络在全量数据集上优化更新一个较大的次数，就认为达到最优了。注3：最终loss函数画出来应该是一个先下降再趋于平稳的曲线，说明模型确实学到东西了，且loss函数最终收敛了（至少达到了局部极小值）。如果画出来的曲线还在下降，说明更新次数不够，还应该继续训练。 模型、数据可视化Protocal Buffer Protocol buffers 是谷歌推出一种数据序列化格式，通常以string字符串的形式实现，数据转化为protocal buffer后就可以存储到磁盘上并在需要时重新加载。 protocol buffer是一种跨平台、跨语言的格式，可类比XML，但更为轻量化。 tensoeflow中就使用protocal buffer格式来存储模型和数据。 TensorBoard TensorBoard主要作用是可视化，可以读取存储到磁盘上的Protocol Buffer格式的文件，并进行可视化展示，计算图、计算过程的变量变化都可进行可视化显示。 TensorBoard官方文档 tf.summary函数在tensorflow程序中主要使用tf.summary的各类方法将数据转化为protocol buffer格式并存储到磁盘上，具体介绍如下。除了保存基本的变量外，还可保存文本（tf.summary.text）、图像（tf.summary.image）、音频（tf.summary.audio）格式的文件，且都可以用tensorboard进行展示。 tf.summary.scalartf.summary.scalar( name, tensor, collections=None, family=None) 函数作用：将标量转化为probuf格式，一般在画loss、accuary时会用到这个函数。 参数解释： name：将标量以什么名字进行保存，在tensorboard中就会使用这个名字来显示变量。type：string。 tensor：待存储的tensor，注意tensor的shape必须为()，即tensor必须是标量（即就一个数）。 其他参数一般用不到。 return：会返回一个string格式的tensor，存储probuf化的标量信息。 tf.summary.histogramtf.summary.histogram( name, values, collections=None, family=None) 函数作用：用于存储tensor，不同于scalar只能存储一个数，distribution任何shape都可以存，其用来记录tensor中各个元素的分布情况。 参数解释： name：tensorboard中显示的名字； values：待存储的的tensor值； renturn：会返回一个string格式的tensor，存储probuf化的tensor信息。 在tensorboard中有两种查看histogram信息的方法：HISTOGRAMS和DISTRIBUTIONS，前者以直方形式显示统计结果， 后者提供更为抽象的统计信息。 HISTOGRAMS可理解为频数分布直方图的堆叠，有两种显示模式：OVERLAY和OFFSET，OVERLAY意为覆盖，即不同的线代表不同的时间/step。如果较晚的线与较早的线重合，就以覆盖方式画线，横轴：值，纵轴：数量；OFFSET则将先按时间/step的前后分开画，但横纵轴的含义不变，横轴：值，纵轴：数量。 DISTRIBUTIONS可理解为多分位数折线图的堆叠， TensorBoard Histogram Dashboard文档 tf.summary.mergetf.summary.merge( inputs, collections=None, name=None) 函数作用：用于管理多个summary，将多个protocol buffer的数据整合到一个protocol buffer中，所以每次就可以只计算总的probuf了。 参数解释： inputs：待合并的多个tensor，每个tensor都是包含protocol buffer的string类型；type：包含多个tensor的list； 其他参数不常用。 return：返回一个string类型的tensor，存储整合后的protocol buffer（包含了inputs中的各个probuf）。 tf.summary.merge_alltf.summary.merge_all( key=tf.GraphKeys.SUMMARIES, scope=None, name=None) 函数作用：用于管理所有的summary，将所有的protocol buffer整合到一个里，一次性计算所有的summary。 参数解释： key：指定了整合哪个范围内的summary，默认为tf.GraphKeys.SUMMARIES（就是所有的summary，summary默认都添加到这里）。 scope：过滤掉不想整合的summary。 三个参数通常情况下都不指定。 return：返回一个string类型的tensor，存储整合后的protocol buffer。 tf.summary.FileWriter类 将变量转化为protocol buffer形式后，就需要将其写到文件中了，提供的将probuf写到文件中的类为：FileWriter。 tensorflow称存储probuf的文件为event file，就是存储计算过程中各种事件的文件的意思。 event file采用的是异步更新机制（系统会在空闲的时候才更新文件），保证了对文件的操作不会拖慢模型训练速度。 构造函数init( logdir, graph=None, max_queue=10, flush_secs=120, graph_def=None, filename_suffix=None, session=None) logdir参数：要将event file保存在哪个目录下； 其他参数不用管。 tf.FileWriter.add_graphadd_graph( graph, global_step=None, graph_def=None) 函数作用：将graph存储到FileWriter对应的event file中。之后tensorboard读取event file就可以对计算图进行可视化展示。 参数解释： graph：待存储的计算图； global_step：计数变量，每次调用函数就+1； return：无返回值。与其他返回op的函数不同，执行这个函数后数据就直接被写到文件了。 通常不使用这个函数，而是直接将sess.graph传入FileWriter的构造函数中。 tf.FileWriter.add_summaryadd_summary( summary, global_step=None) 函数作用：将summary函数产生的protocol buffer数据存储到FileWriter对应的event file中。 参数解释： summary：待存储的summary protocol buffer；注意必须先run()/eval()才能生成probuf，之后才能传入函数，不然就只传了一个空tensor。 global_step：计数变量，每次调用函数就+1； return：无返回值，函数直接执行写入操作（实际是异步的）。 Tensor shape information：将tensor的shape反映到图中（通过边的粗细程度） tf.FileWriter.flush() 将所有pending的数据立即写入文件。 因为add函数是异步执行的，所以调用函数后系统不会立即将数据写入文件。 使用tensorboard123456# 初始化一个存储文件writer = tf.summary.FileWriter('.')# 将计算图存到文件中writer.add_graph(tf.get_default_graph())# 文件写到磁盘上writer.flush() 如何调用TensorBoard： tensorboard --logdir=PATH；省略形式：tensorboard --logdir .，直接在当前目录下运行。注：annaconda下需要先进入相应python环境，才可以使用tensorboard命令。 之后在localhost: 6006上即可访问。 tensorboard分析：在tensorboard中会按照name scope将相关节点都聚集到一个父节点中，因此良好的name scope命名规则会很有利于模型可视化。 关于name_scope和variable_scope的区别：name_scope：为了更好地管理变量的命名空间而提出的。比如在 tensorboard 中，因为引入了 name_scope， 我们的 Graph 看起来才井然有序。variable_scope：大部分情况下是跟 tf.get_variable() 配合使用，来实现变量共享的功能。但tensorboard也会对同一variable_scope的变量进行聚集和整理。 tf.nn.embedding_lookuptf.nn.embedding_lookup( params, ids, partition_strategy=’mod’, name=None, validate_indices=True, max_norm=None) 函数作用：根据序号查找tensor中的相应项。当params为一个tensor时，根据ids返回查到的行；当params是多个tensor所构成的list时，则根据分隔策略返回查到的各个tensor的行。 构成params的tensor通常为2维的，此时查到的是行；如果tensor是一维的，则是查找相应的项。 参数解释： params：待查找项的集合；type：单个tensor或多个tensor的list。 ids：用来查找项的索引；type：整型list或tensor，1-D/mul-D都可。 partition_strategy：分隔策略，指定了怎样由索引去查找对应项。type：”mod” 或 “div”。只有在len(params) &gt; 1时才有用，即params是由多个tensor构成时才有用。 return：返回一个tensor，表示查到的params的行。shape为ids的shape再加上所查到的行，即rank = ids_rank + 1。 partition_strategy进一步解释： 默认为mod：按余数来分隔各个tensor，0~n-1分别表示第一个tensor到最后一个tensor的第一项，n~2n-1分别表示第一个tensor到最后一个tensor的第二项，以此类推； div：按除数来分隔tensor，从前到后依次查找每个tensor中的元素。example code：123456789101112131415161718192021222324252627282930313233343536373839404142# params为单个tensor的情况params = tf.constant([[10, 20, 30],[40, 50, 60]])ids = tf.constant([0, 1, 1])print(tf.nn.embedding_lookup(params,ids).eval()) # 输出# [[10 20 30]# [40 50 60]# [40 50 60]]# params为多个tensor的情况，需要指定分隔策略params1 = tf.constant([[10, 20, 30],[40, 50, 60]])params2 = tf.constant([[70, 80, 90],[100, 110, 120]])ids = tf.constant([0, 1, 2, 3])print(tf.nn.embedding_lookup([params1, params2],ids).eval()) # 输出# [[ 10 20 30]# [ 70 80 90]# [ 40 50 60]# [100 110 120]]print(tf.nn.embedding_lookup([params1, params2],ids, partition_strategy='div').eval()) # div分隔策略下，输出为# [[ 10 20 30]# [ 40 50 60]# [ 70 80 90]# [100 110 120]]# 若ids是多维的，查到的内容不变，则仅仅是将查找结果整理成相应的多维数组的形式而已。params1 = tf.constant([[10, 20, 30],[40, 50, 60]])params2 = tf.constant([[70, 80, 90],[100, 110, 120]])ids = tf.constant([[0, 1], [2, 3]])print(tf.nn.embedding_lookup([params1, params2],ids, partition_strategy='div').eval()) # 输出# [[[ 10 20 30]# [ 40 50 60]]# [[ 70 80 90]# [100 110 120]]] 如何构建词汇表词汇表本质是一个word: id字典，用于将token词和对应的整数映射起来，即把每个词变成一个独立的整数，这样我们就可以通过相应的index来存储、操作token，节省存储空间、加快速度，也便于后期做词嵌入。tensorflow有VocabularyProcessor和tf.keras.preprocessing.text.Tokenizer两种实现方法，下面分别介绍。 VocabularyProcessor类 这个类tensoflow官方已经不推荐使用了（替代手段为tf.keras.preprocessing.text.Tokenizer的相关API），但因为有时要阅读别人代码，所以还是简单总结下这个类的使用方法。 构造方法：tf.contrib.learn.preprocessing.VocabularyProcessor (max_document_length, min_frequency=0, vocabulary=None, tokenizer_fn=None)max_document_length：文档的最大长度。如果文本的长度大于最大长度，那么它会被剪切，反之则用0填充；min_frequency：词频的最小值，出现次数小于最小词频的词不会被收录到词汇表中；vocabulary：CategoricalVocabulary对象，直接none就行；tokenizer_fn：分词函数，直接none就行。 example code 1234567891011121314151617from tensorflow.contrib import learnimport numpy as npmax_document_length = 4x_text =[ 'i love you', 'me too']vocab_processor = learn.preprocessing.VocabularyProcessor(max_document_length)vocab_processor.fit(x_text) # 训练一个词汇表print(next(vocab_processor.transform(['i me too'])).tolist()) # 输出index形式的文档x = np.array(list(vocab_processor.transform(x_text)))print(x)# 输出[1, 4, 5, 0][[1 2 3 0] [4 5 0 0]] 一些常用函数：VocabularyProcessor.fit()：训练词汇表，词汇表第0位默认为&lt;UNK&gt;（”: 0”），用于标示不在词汇表中的词；VocabularyProcessor.transform()：根据词汇表将句子转化成相应的数字序列，并返回；VocabularyProcessor.fit_transform()：先训练一个词汇表，再返回训练集的数字序列；VocabularyProcessor.vocabulary_.mapping[key]：根据key(即token词)取对应id；VocabularyProcessor.vocabulary.mapping.get(key, default=None)：根据key(即token词)取对应id，没取到返回的default参数值；VocabularyProcessor.vocabulary._mapping.keys()：返回所有keys； tf.keras.preprocessing.text.Tokenizer类12345# Tokenizertokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=20000， oov_token='&lt;UNK&gt;')tokenizer.fit_on_texts(train_text)train_idxs = tokenizer.text_to_sequences(train_text)test_idxs = tokenizer.text_to_sequences(test_text) 更多见：文本预处理方法小记-知乎 关于collectiontf.add_to_collectionadd_to_collection( name, value) 函数作用：将某个变量添加到默认graph的某个collection中（是tf.tf.get_default_graph().add_to_collection的简写形式）。 参数解释： name：collection的名字，若collection不存在则自动创建一个并添加； value：要被添加的变量； return：无返回值。 其他函数关于axis参数和dimension的理解 在Tensorflow和numpy的函数中，经常会有axis这个参数，这是一个和维度dimension息息相关的概念，下面来进行介绍。 axis：中文意思为“轴”，本质是一个方向！表示在当前维度上数量增加的方向，与笛卡尔坐标系中的x轴和y轴表达是一个意思。 axis是从0开始计数的，在一个矩阵/2D tensor中，axis0表示竖直方向，axis1表示水平方向。在更高维的张量中，axis0、axis1也是表示相同的方向。 但注意，在一维tensor（即数组/向量）中axis的表示有些不同，一维tensor只有一个axis，为axis0，且axis0的方向是水平的。原因在于：一维tensor本质应该是列向量，这样axis0方向就是竖直的了，与高维tensor统一；但因为人们的表示习惯，把一维tensor表示为行向量了，因此才会有axis0的差异。 dimension：维度，本质和axis是一样的，也是指方向。但有两种上下文的理解：1、这个东西是几维几维的，是指这个东西有多少个“方向”来描述；2、这个东西的1维2维3维，是指第几个方向，即1维对应axis 0，2维对应axis 1，这样。 详细解释参照：NUMPY AXES EXPLAINED tf.splittf.split( value, num_or_size_splits, axis=0, num=None, name=’split’) 函数作用：将大tensor分割成几个小tensor 参数解释： value：输入数据，为tensor类型； num_or_size_splits：指定了两种分割策略。若输入的是一个整数n，则会在axis维度上平均分成n个小tensor；若输入的是一个tensor/list，则会按照指定的大小来分； axis：指定了要沿哪个维度来分，注意维度的计数从0开始。 return：包含被分割的小tensor的list example code：1234567891011value = tf.get_variable(name=\"value\", shape=[5, 30])# 平均分 &amp; 沿维度1分split0, split1, split2 = tf.split(value, num_or_size_splits=3, axis=1)print(split0.shape) # [5, 10]# 按指定的大小分 &amp; 沿维度1分split0, split1, split2 = tf.split(value, [4, 15, 11], 1)print(split0.shape) # [5, 4]print(split1.shape) # [5, 15]print(split2.shape) # [5, 11] tf.concattf.concat( values, axis, name=’concat’) 函数作用：将多个小tensor拼接为一个大tensor（沿着axis指定的维度） 参数解释： values：将要拼接的tensor集合；type：list of tensor。 axis：在哪个维度上进行拼接；type：int； 返回值：一个拼接后的新tensor。 注：待拼接的各个tensor，除了axis维度，其他维度的长度必须相等。 tf.reshapetf.reshape( tensor, shape, name=None) 函数作用：改变一个tensor的shape。 参数解释： tensor：原tensor。 shape：要被改变成的shape；type：list； 返回值：reshaped tensor。 注1：shape中的某个维度可以指定为-1，表示该维度的长度由系统推断，最多只能指定一个维度为-1。如果shape就直接是[-1]，则会将原tensor平铺为1-Dtensor。 注2：要把元素都填充到新tensor的各个维度中，肯定要以一定的顺序读取原tensor中的元素，那按什么样的顺序进行读取呢？可以理解为深度优先，即先把一个元素所有的低维度子元素读完，再读下一个元素。填充时也是这个顺序。 tf.transposetf.transpose( a, perm=None, name=’transpose’, conjugate=False) 函数作用：对矩阵进行转置。更本质来说是对tensor的维度顺序进行调整，如将第3维调整到第2维，第2维调到第1维等； 参数解释： a：待转置的tensor； perm：在新tensor中原先各维度的排列顺序，即指定如何转置tensor；type：list；默认为[n-1, …, 0]，表示从后到前依次转置，即为2-D矩阵的转置方式。 conjugate：用处不大，只在元素为复数时有用。 return：转置后的新tensor。 example code1234567891011121314151617181920212223242526x = tf.constant([[1, 2, 3], [4, 5, 6]])tf.transpose(x) # [[1, 4]# [2, 5]# [3, 6]]# Equivalentlytf.transpose(x, perm=[1, 0]) # [[1, 4]# [2, 5]# [3, 6]]# 'perm' is more useful for n-dimensional tensors, for n &gt; 2x = tf.constant([[[ 1, 2, 3], [ 4, 5, 6]], [[ 7, 8, 9], [10, 11, 12]]])# (2, 2, 3) shape转置为 (2, 3, 2) shapetf.transpose(x, perm=[0, 2, 1]) # [[[1, 4],# [2, 5],# [3, 6]],# [[7, 10],# [8, 11],# [9, 12]]] tf.squeezetf.squeeze( input, axis=None, name=None) 函数作用：去除tensor中大小为1的维度（因为这些维度本身意义不大）。对应了函数名squeeze“挤压”。 参数解释： input：输入tensor axis：可以自己指定要去除具体哪一个大小为1的维度，list类型 return：返回一个处理后的tensor example code123456# 't' is a tensor of shape [1, 2, 1, 3, 1, 1]tf.shape(tf.squeeze(t)) # [2, 3]# remove specific size 1 dimensions# 't' is a tensor of shape [1, 2, 1, 3, 1, 1]tf.shape(tf.squeeze(t, [2, 4])) # [1, 2, 3, 1] tf.expand_dimstf.expand_dims( input, axis=None, name=None, dim=None(deprecated)) 函数作用：对tensor添加维度，添加的维度长度为1。常用来对tensor增加batch维。 参数解释： input：待操作的tensor； axis：指定在哪个位置添加维度，位置从0开始； dim：这是deprecated的参数，不推荐使用； return：改变后的tensor。 example code123456789# 't' is a tensor of shape [2]tf.shape(tf.expand_dims(t, 0)) # [1, 2]tf.shape(tf.expand_dims(t, 1)) # [2, 1]tf.shape(tf.expand_dims(t, -1)) # [2, 1]# 't2' is a tensor of shape [2, 3, 5]tf.shape(tf.expand_dims(t2, 0)) # [1, 2, 3, 5]tf.shape(tf.expand_dims(t2, 2)) # [2, 3, 1, 5]tf.shape(tf.expand_dims(t2, 3)) # [2, 3, 5, 1] tf.tiletf.tile( input, multiples, name=None) 函数作用：通过多次复制一个tensor的方式构造新tensor。可以理解为用tf.concat拼接相同的tensor。 参数解释： input：将要被复制的tensor； multiple：指定input中各个维度将要被复制的次数；type：list，且长度必须和input的维度数相等。 return：所构造的新tensor。 example code1234567891011121314with tf.Session(): x = tf.constant([[1, 2, 3], [4, 5, 6]]) y1 = tf.tile(x, [2, 1]) y2 = tf.tile(x, [1, 2]) print(y1.eval()) print(y2.eval())# 输出：# [[1 2 3]# [4 5 6]# [1 2 3]# [4 5 6]]# [[1 2 3 1 2 3]# [4 5 6 4 5 6]] tf.stacktf.stack( values, axis=0, name=’stack’) 函数作用：将一个list内的多个tensor叠成一个(rank+1)的tensor，多的那一维就是tensor的数量。 参数解释： values：list of tensor； axis：要叠到新tensor的哪个维度上，默认为0，即各个tensor以行的形式进行排列。 return：返回新的tensor example code12345x = tf.constant([1, 4])y = tf.constant([2, 5])z = tf.constant([3, 6])tf.stack([x, y, z]) # [[1, 4], [2, 5], [3, 6]] (Pack along first dim.)tf.stack([x, y, z], axis=1) # [[1, 2, 3], [4, 5, 6]] tf.math.zero_fractiontf.math.zero_fraction( value, name=None) Aliases：tf.nn.zero_fraction 函数作用：返回value中值为0的元素所占的比例。因为relu激活函数有时会大面积的将输入参数设为0，所以此函数可以有效衡量relu激活函数的有效性。 如何设置GPU的使用 通过CUDA_VISIBLE_DEVICES环境变量可以设置程序可以看到的GPU，因此也就只能使用相应的GPU。注：这种方法不仅会对tensorflow程序生效，对所有的程序都会生效。 两种设置方式： 在python程序中设置（推荐），os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;2, 3&quot;，后面的数是GPU的序号，可通过nvidia-smi命令来查看。这种设置方法只对此python程序有效，推荐。 在命令行中设置，export CUDA_VISIBLE_DEVICES = &quot;2, 3&quot;。","categories":[],"tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://renli1024.github.io/tags/TensorFlow/"}]},{"title":"TensorFlow Programming","slug":"TensorFlow/TensorFlow Programming","date":"2019-03-02T14:49:54.960Z","updated":"2019-06-12T02:49:09.330Z","comments":true,"path":"2019/03/02/TensorFlow/TensorFlow Programming/","link":"","permalink":"https://renli1024.github.io/2019/03/02/TensorFlow/TensorFlow Programming/","excerpt":"本文介绍了TensorFlow的程序结构和编程相关的知识。","text":"本文介绍了TensorFlow的程序结构和编程相关的知识。 Introduction to Computing Graph TensorFlow中程序都是以计算图(computational graph)的形式来进行的，大致可以包含两部分：构造计算图、运行计算图。 计算图可以看作是一系列运算操作的静态集合，其规定了计算的流程。注意计算图是静态的，只构造好计算图是无法计算出结果的，必须运行计算图才可以得到结果（使用tf.Session）。 构造计算图 计算图由两种成分组成：tf.Tensor 和 tf.Operation，tf.Operation可以看作是图中的节点，tf.Tensor可看作是图中的边。 如何构造计算图： 调用相关方法，生成tf.Operation (node) 和 tf.Tensor (edge) 对象 将它们添加到tf.Graph对象中。 注：实际上tensorflow会自动将它们添加到default graph中，许多程序也仅仅使用default graph，因此第二步就可以省略。但如果我们要使用多个计算图，就需要手动将operation和tensor添加到相应的graph中。 multiple graphs programming 大部分情况下一个graph就足够了，但如果有时候一个graph太复杂，或者有太多无关的操作，可以另开一个graph来计算。 具体步骤： 通过tf.Graph()函数来生成graph； 通过with another_graph.as_default():语句块来切换当前的默认graph，在这个语句块内的所有操作都会添加到默认的计算图中； 可通过tf.get_default_graph()来获取当前默认的计算图，返回tf.Graph()对象。 运行计算图创造session 计算图的运行是通过tf.Session来进行的，其可以理解为计算图的运行机制，负责执行运算图所定义的tensor或operation。 要执行计算图首先需要创造一个session，因为session对象使用后需要释放（因为session会占有一定物理资源如GPU、网络连接等），所以建议用with语句块来创造session对象，这样语句块结束后可以自动释放资源。12with tf.Session() as sess: # code relavant to sess 初始化session session的构造函数有三个optional参数，可以让我们对session进行一些设置__init__(target = &#39;&#39;, graph = None, config = None); target：执行session的设备，常用于分布式计算情境下。默认是在当前本地设备上执行。 graph：session所执行的计算图，默认是default graph，如果只使用一个计算图不用管这个参数。 config：session的配置参数，通过传入tf.ConfigProto对象来对session进行设置。ConfigProto常用参数： allow_soft_placement：是否允许设备代替，指定在GPU上运行的代码，如果GPU不存在，会被替换到CPU上执行。通常设为true。 log_device_placement：是否打印设备的分配信息，通常设为flase. 执行session session可以执行的有两种类型，一种是tensor，一种是operaton；若执行的是tensor，则会返回tensor所对应的值（type：numpy.ndarray）；若执行的是operation，则方法只是执行相应的操作，不会返回值，如initialize和train操作。 session的执行也有两种方法： 一种是sess.run(tensor/operation)； 另一种是调用tf.Operation.run()/tf.Tensor.eval()函数：op.run()实际是tf.get_default_session().run(op)的简写，tensor.eval()也是tf.get_default_session().run(tensor)的简写，因此这两个方法执行的前需要确保正确设置了default session（上一种方法因为已指定了session，也就不需要default session了）。 而如何设置default session，主要通过with语句块： with tf.Session():，生成session的同时将其自动设置为了default session（当然出语句块也就清除掉了）； with sess.as_default():，将已有的某个session设置为default session。as_default()方法会返回一个context manager，对应的session在本语句块内会被自动设置为default session。 注：as_default()方法出语句块时只会清除default session设置，并不释放掉session（因为这个方法本就是为session的重用而生的），因此如果session不用了要手动close掉。1234sess = tf.Session()print(sess.run(变量名)) # sess.run会自动检测计算这个变量所需要的依赖，之后执行计算图，计算出结果并输出。print(sess.run(&#123;\"变量1\": 变量1, \"变量2\": 变量2&#125;)) # sess.run可以一次传入多个变量，但要以字典的形式传入（即键值对的形式） 构造Layer 计算图的一个重要构成部分就是layer，也就是神经网络中的layer，在layer中封装了可以被训练的变量（如weights, biases等）以及作用于他们的操作（各种优化算法），是神经网络训练的核心。 关于layer的使用，把它理解成一个函数即可，本质就是：输入数据-&gt;经过一定运算-&gt;输出数据的过程。1234567891011# 构造一个densely-connected layersess = tf.Session()x = tf.placeholder(tf.float32, shape=[None, 3])linear_model = tf.layers.Dense(units=1) # units：dimensionality of output unit？？y = linear_model(x)# 必须先对layer中的参数初始化（weight matrix 和 bias）init = tf.global_variables_initializer()sess.run(init)print(sess.run(y, feed_dict=&#123;x: [[1, 2, 3], [1, 2, 3]]&#125;)) 在不同的设备上执行operation通过with tf.device():语句：eg. with tf.device(&quot;/device:CPU:0&quot;): TensorFlow中的with语句在TensorFlow中可以用with语句块进行资源管理的类：with tf.Graph():with tf.Session():with tf.device() TensorFlow训练实例1234567891011121314151617181920212223# inputs and labelsx = tf.constant([[1], [2], [3], [4]], dtype=tf.float32)y_true = tf.constant([[0], [-1], [-2], [-3]], dtype=tf.float32)# define the modellinear_model = tf.layers.Dense(units=1)# define predictiony_pred = linear_model(x)# define loss functionloss = tf.losses.mean_squared_error(labels=y_true, predictions=y_pred)# define optimizeroptimizer = tf.train.GradientDescentOptimizer(0.01)# define train operationtrain = optimizer.minimize(loss)# train the model (run train operation in session), iterate 100 timesfor i in range(100): _, loss_value = sess.run((train, loss)) print(loss_value) TensorFlow vs PyTorchTFPros Large community support, abundant docs and tutorials. Powerful visulization tool - tensorboard. Appropriate for development. Cons Beginner unfriendly, complicate mechanism (Must build computational graph fisrt before run it). Some functions are redundant and deprecated (many deprecating warnings). PyTPros More Pythonic and code is conciser. Easy to use, beginner friendly and can quickly verify model. Approriate for scientific research and experiment. Cons No formal visulization support (some third party tools but hard to use). The core part like convolution, batch norm is easier to use than TensorFlow, but the auxiliary part is harder. For example, saving and loading model, calculating shapes operations are more complicate. SummaryTensorFlow: more powerful but more complicate.PyTorch: more beginner friendly, easy to use but less powerful.","categories":[],"tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://renli1024.github.io/tags/TensorFlow/"}]},{"title":"Linux基础知识","slug":"linux/linux基础知识","date":"2019-02-22T21:03:46.852Z","updated":"2019-08-02T03:29:54.990Z","comments":true,"path":"2019/02/23/linux/linux基础知识/","link":"","permalink":"https://renli1024.github.io/2019/02/23/linux/linux基础知识/","excerpt":"","text":"Shell Shell字面理解是“壳程序”（操作系统可以分为核心kernel和外壳Shell两部分），用于用户和系统内核间的交互。相当于是一个命令解析器，其接收用户命令，然后调用相应的内核指令，完成相应的功能。 Shell有很多种，如Bourne SHell(sh)、Bourne Again SHell(bash)、C SHell(csh)等，这些Shell最大的区别就是命令集的不同。 注1：在linux/mac中预设的Shell就是bash；在Windows中的Shell是cmd和PowerShell，cmd功能较为简单，PowerShell功能则非常强大，可以看作cmd的超集。 注2：如何区分各种shell？可通过命令的开头字符，如果是$, #则为bash($为普通用户，#为管理员root超级用户)；如果是PS &lt;当前地址&gt;则为Powershell，如果直接是&lt;当前地址&gt;则为cmd。 注3：同时Shell又是一种编程语言，可自动执行一连串的命令，并具有定义变量、循环/分支控制结构等特性。 目录写法 绝对路径：从根目录开始，以/开头 相对路径：相对当前目录的路径，不以/开头 ./表示当前目录，../表示上一级目录（iterable） ~表示当前用户目录，即/Users/user_name/ 路径结尾：文件夹的话结尾最好加/以和文件区分两种斜杠区别正斜杠/：网址路径，linux、mac下地址路径（斜率为正因此称为正斜杠），网址路径和地址路径本质是一样的，都是资源定位符；反斜杠\\：转义字符、win下地址路径； Command-line syntax: some basic concepts命令行是指可以在终端中运行的命令，通常会有很多的选项、参数，这些选项和参数有多种组合形式，而如何描述这些组合形式则需要一定的规则（syntax），这套规则不仅运用在command line的相关文档中，很多函数相关的文档也用这套sytax来规定如何使用参数，对其了解清楚会很便于我们后续阅读文档，因此在此介绍一些基本的概念。 command line基本形式program_name command --option &lt;argument&gt;，如git commit -m &lt;msg&gt;program_name：执行命令的程序；command：程序要做的动作/要干什么事；--option：动作的一些附加选项；&lt;argument&gt;：这些附加选项的参数信息； 命令中常见的符号 &lt;positional argument&gt;：尖括号angle brackets，表示位置参数，即必须要传入值的参数，positional指传入的是哪个参数的值是由位置指定的，因此其都是跟在某个option后面固定位置的； 注意&lt;&gt;只等用来表示参数，不同表示option. [optional option]：方括号square brackets，用来表示可选的选项，放在这里的选项都是可写可不写的。（直接写出来的选项都是必须写的） (required option)：圆括号parens，表示必须写的选项的，其和直接把选项写出来的区别是：其通常和|pipe符号连用，表示一组必须要有一个的相斥选项； {default values}：花括号curly braces，用来指定一些默认的值； |：竖线pipe，用来表示一组相斥的选项，即多个选项只能选其一。 -和--：短杠dash，分为单短杠和双短杠两种，短杠后接参数的简写形式，双短杠则接参数的全称，两种情况是等效的。eg. git commit -m &lt;msg&gt;=git commit --message=&lt;msg&gt; 参考博客docopt（一款命令解析软件的文档）Command-line syntax: some basic concepts 环境变量/PATH基本概念 环境变量是指一些列和系统直接相关的变量，其中最常用的为PATH变量（但不仅仅包含PATH），通常来说设置环境变量即为设置PATH变量的意思。 PATH变量中存储了一系列路径，输入终端的指令都要到PATH变量包含的路径中，搜索名字匹配的文件来执行。 设置PATH变量的好处：如果不加到PATH变量中，每次执行程序就必须输入程序对应的目录，而将程序的目录加入PATH后，每次就只需要输入程序名就可以了（终端会自己去目录下搜索名字匹配的程序）。 如何修改PATH变量 如何查看：echo $PATH 环境变量格式：字符串形式，”dir1:dir2:dir3”，目录间以分号:分隔。 如何设置环境变量： 修改环境变量对应的文件，只针对当前用户的环境变量，在/Users/user_name/.bash_profil环境中修改；针对所有用户的环境变量：在/etc/profil文件中修改。 设置PATH=&quot;{$PATH}:directory_path&quot; 或者直接通过终端执行上述命令也可以。 export命令设置环境变量：export name=value；显示所有环境变量：export -p。注1: export的效力仅及于该次登陆操作，一旦退出用户，此次登陆就无效了。注2: export和普通赋值的区别：本质都是对变量赋值，区别在于export的变量，次进程后续产生的子进程也可以访问，但普通赋值的变量就只能对当前的进程起作用。 terminal 操作命令 光标移至行首：ctrl+a 光标移至行尾：ctrl+e 删除一行/结束当前命令：ctrl+c Shell脚本编写 开头定义解释器环境 #! /bin/bash 定义变量：variable_name=xxx，直接等号赋值即可。注意：等号两边不能有任何空格！ 使用变量：${variable_name}，美元符号指明这是一个变量，外面的花括号用来指明变量边界（可选）。 脚本保存为：script_name.sh 脚本执行：sh script_name.sh","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://renli1024.github.io/tags/Linux/"},{"name":"Mac","slug":"Mac","permalink":"https://renli1024.github.io/tags/Mac/"}]},{"title":"TensorFlow Data Structure","slug":"TensorFlow/TensorFlow Data Structure","date":"2019-02-21T11:36:45.061Z","updated":"2019-06-12T02:48:43.611Z","comments":true,"path":"2019/02/21/TensorFlow/TensorFlow Data Structure/","link":"","permalink":"https://renli1024.github.io/2019/02/21/TensorFlow/TensorFlow Data Structure/","excerpt":"本文介绍了TensorFlow的基本数据类型和使用方法。","text":"本文介绍了TensorFlow的基本数据类型和使用方法。本文中tf都指代的是TensorFlow Introduction TensorFlow中可以认为只有两种基本数据结构：tensor 和 operation。operation代表一个操作，对应计算图中的节点，也可以认为是函数；tensor本质是一个句柄，代表的是operation的计算结果，也可认为是函数的返回值。 tf.Tensor tensor的中文意思是“张量”，可将其理解为高维向量，向量是一维tensor，矩阵是二维tensor。 Tensor底层的值是由numpy.array来实现的，因此两者间会有很多共通之处。 关于tensor和op的关系：A Tensor is a symbolic handle to one of the outputs of an Operation。即tensor本质是一个句柄，绑定着op的结果，因此一个tensor必然会有一个operation（但一个op可以输出多个tensor），所以tensor中才会有Tensor.op属性，表示是什么op产生了这个tensor。 也正因为tensor是句柄，并不存储值，只存储计算结果，所以只有经过计算，tensor才会有相应的值，因此只有运行Session后才能得出tensor的值。 tensor命名规则 tensor的命名格式为&lt;op_name&gt;:&lt;output_index&gt; 对返回tensor的API，会自动创建op，并通过name参数指定的操作的名字（即op_name）；如果后续有相同命名的操作，则在op_name后加_1；对于其产生的tensor，则按产生顺序自动在后面加:0/:1/:2等。 一般op_name命名为大写开头。 example code：123456789101112131415161718192021W1 = tf.Variable([[1,1,1],[2,2,2]],dtype = tf.float32,name='Var') W2 = tf.Variable([[1,1,1],[2,2,2]],dtype = tf.float32,name='Var')A1 = tf.add(W1, W2)B1, B2 = tf.split(W1, 2)C1 = tf.constant(value=[1,2,3], name=\"Con1\")P1 = tf.placeholder(tf.int32, shape=(2,3), name=\"Pla1\")print(W1)print(W2)print(A1)print(B1)print(B2)print(C1)print(P1)# &lt;tf.Variable 'Var:0' shape=(2, 3) dtype=float32_ref&gt;# &lt;tf.Variable 'Var_1:0' shape=(2, 3) dtype=float32_ref&gt;# Tensor(\"Add:0\", shape=(2, 3), dtype=float32)# Tensor(\"split:0\", shape=(1, 3), dtype=float32)# Tensor(\"split:1\", shape=(1, 3), dtype=float32)# Tensor(\"Con1:0\", shape=(3,), dtype=int32)# Tensor(\"Pla1:0\", shape=(2, 3), dtype=int32 Rank of Tensorsrank指tensor的秩，即维数。不同rank的tensor会有不同的数学意义： rank 数学意义 0 Scalar(标量) 1 Vector(向量) 2 Matrix(矩阵) 3 Cube(立方体) 4 一行Cube（立方体再向高维抽象） 如何获得tensor的rank：因为其不是Tensor的属性之一，所以无法直接访问对象获得，只能通过tf.rank(some_Tensor)方法来获取维数（返回的一个封装了rank值的tensor） 访问tensor中的某个scalar：每一维指定对应的标号即可。eg. my_scalar = my_matrix[1, 2], my_column_vector = my_matrix[:, 3]。其中:表示取这一维度中的所有数。 Shape of Tensors shape表示tenor各维度的长度，或者说各个维度中元素的个数。eg. tf.constant([[[1., 2., 3.]], [[7., 8., 9.]]])：rank为3，shape为[2, 1, 3]。 tensor的shape可以只指定一部分，如TensorShape([None, 256])，只指定了列数为256列，行数会在运行时自动被推断出。 如何获得tensor的shape： 通过tf.Tensor.shape属性（推荐）：返回一个TensorShape对象，通过slice机制来访问封装在TensorShape中各个维度的长度； 通过tf.shape(my_tensor)方法：返回一个Tensor对象，表示原tensor的shape。因为是tensor类型，所以必须运行后才能知道其具体值。但好处因为是在运行时计算的，所以此时shape一定是fully-defined的。 如何改变tensor的shape：通过tf.reshape()方法。12345678rank_three_tensor = tf.ones([3, 4, 5])matrix = tf.reshape(rank_three_tensor, [6, 10]) # Reshape existing content into a 6x10 matrixmatrixB = tf.reshape(matrix, [3, -1]) # Reshape existing content into a 3x20 matrix. # -1 tells reshape to calculate the size of this dimension. Data Types of Tensors 每个tf.tensor都有一个dtype属性，表示tensor中存储的数据的数据类型，通过tf.tensor.dtype访问。 常用数据类型有：tf.int32（对应python中的整型）, tf.float32（对应python中的浮点型）。 如何转换tensor类型：float_tensor = tf.cast(tf.constant([1, 2, 3]), dtype=tf.float32) 如何得到tensor的值 通过tf.Tensor.eval()方法，它其实是tf.get_default_session().run(tf.Tensor)方法的简写。 注1：eval()方法必须在默认的session被激活的情况下才可执行（通过with tf.Session().as_default():语句块）。 注2：eval方法同样可以传入feed_dict，如t.eval(feed_dict={p:2.0}) tf.Variable tf.Variable为tensorflow中的变量，值可以通过附加在其上的操作更改。 声明一个Variable后，系统会生成四个相关操作：v_name/initial_value, v_name, v_name/Assign, v_name/read, tf即通过这四个op实现对Variable值的更改。 tensor和variable的关系 variable对应tf.Variable类型，tensor应该对应的是tf.Tensor。从内部实现上讲，variable本质是对tensor的一种封装。 TensorFlow官方将tf.Variable定义为Tensor-like objects，即类tensor类型（其他还有numpy.ndarray, list以及其他python基本类型: bool, float, int, str），这些类型在传入函数时会被隐式转换为tensor类型（using tf.convert_to_tensor() method），因此也可以当作tensor来使用。 tf.Variable实现的意义在于提供一种值可以更改的类tensor类型。因为tensor本身实质上属于常量，值一旦初始化是不可更改的（tf.constant()、tf.placeholder()都只是产生tensor的方法，返回值是tensor)。 所以如果要在graph中训练参数，那么参数只能是variable形式（tensor不能改变值），tensor则用来表示输入、输出值，在graph中传递中间的计算值。 定义Variables 官方推荐使用tf.get_variable()函数来定义、初始化以及调用变量，配合tf.variable_scope来确保不会不小心重用或声明新的变量。 就不要用tf.Variable()。 tf.get_variable()方法原型：1234567891011121314151617tf.get_variable( name, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, collections=None, caching_device=None, partitioner=None, validate_shape=True, use_resource=None, custom_getter=None, constraint=None, synchronization=tf.VariableSynchronization.AUTO, aggregation=tf.VariableAggregation.NONE) 其主要有两个作用： 计算图中不存在name参数的值时，会声明一个变量，等价于调用variable的构造函数tf.Variable()； 计算图中已存在name参数时，返回对应的变量，因此可通过这个方法来根据名字获取变量； 详细参数说明：name：必填参数，用于指定变量的名字；shape：指定变量的shape；initializer：指定变量的初始器，默认为tf.glorot_uniform_initializer。collections：指定变量属于的集合，默认为GraphKeys.GLOBAL_VARIABLES。 初始化variablevariable在使用前必须初始化，初始化变量有两步： 在声明变量时指定initializer参数，其可以是一个tf.initializer对象，也可以是一个tensor。若是initializer则会按该initializer的方式来初始化，若是tensor则会用该tensor的值来初始化。默认初始器参数为tf.glorot_uniform_initializer。 调用tf.global_variables_initializer()方法，对tf.GraphKeys.GLOBAL_VARIABLES集合中的变量进行初始化（按变量指定的initializer参数进行初始化）。 使用variable 因为variable是tensor-like类型，所以直接像普通tensor一样使用variable即可。 12v = tf.get_variable(\"v\", shape=(), initializer=tf.zeros_initializer())w = v + 1 如何为variable重新分配值：使用tf.Variable.assign()、tf.Variable.assign_add()、tf.Variable.assign_sub()三个方法，可用对Variable重新赋值。 1234v = tf.get_variable(\"v\", shape=(), initializer=tf.zeros_initializer())assignment = v.assign_add(1) # assign方法会返回一个新分配值的tensortf.global_variables_initializer().run()sess.run(assignment) Variable collectionstf提供了collection机制，使得变量的存储和访问变得很方便。系统常用collections： tf.GraphKeys.GLOBAL_VARIABLES：全局共享的变量（每个设备都可以访问），变量默认都存储在这个集合中。 tf.GraphKeys.TRAINABLE_VARIABLES：存储会被训练的变量，tf.Optimizer就是优化此集合下的变量。注：所有变量默认都是存储在TRAINABLE_VARIABLES和GLOBAL_VARIABLES这两个集合中。TRAINABLE_VARIABLES属于GLOBAL_VARIABLES的一个子集，两者并不冲突。 tf.GraphKeys.LOCAL_VARIABLES：用于存储临时变量，在这个集合中的变量不会被优化。 如何将变量添加到指定集合中： 在声明变量的时候指定collections参数 通过调用tf.add_to_collection(collection_name, variable_name)函数。 tf.variable_scope机制tf.variable_scope的作用有两点： 对变量使用范围加以限制，以方便变量的create和share，在一个scope中构造的变量就只能在这个scope中使用。 起到tf.name_scope的作用，对变量命名进行整理。 example code： 1234567def my_image_filter(input_images): with tf.variable_scope(\"layer1\"): tf.get_variable(name='Var', shape=[1]) # \"layer1/Var\" with tf.variable_scope(\"layer2\"): tf.get_variable(name='Var', shape=[1]) # 会重新定义一个\"layer2/Var\"变量，而非重用之前的变量 但如果确实希望重用相同的内部变量，可通过如下方法： 123456789101112131415161718# example 1with tf.variable_scope(\"layer1\"): V1 = tf.get_variable(name='Var', shape=[1])with tf.variable_scope(\"layer1\"): V2 = tf.get_variable(name='Var') # 报错，禁止重用变量# example 2with tf.variable_scope(\"layer1\"): V1 = tf.get_variable(name='Var', shape=[1]) V2 = tf.get_variable(name='Var') # 报错，禁止重用变量# example 3with tf.variable_scope(\"layer1\"): V1 = tf.get_variable(name='Var', shape=[1]) # \"layer1/Var\"with tf.variable_scope(\"layer1\", reuse=True): V2 = tf.get_variable(name='Var') # 正确, V1, V2重用同一个变量 tf.variable_scope和tf.name_scope的区别 name_scope：仅仅是为了更好地管理变量的命名空间而提出的，对变量的使用没有任何影响。此外tensorboard会将一个name_scope下的变量整理在一个父节点中，因此良好的name scope命名规则会很有利于模型可视化。 variable_scope：不仅仅是管理命名空间，还是为了限制变量的使用范围，常和 tf.get_variable()配合使用，来实现变量共享的功能。tensorboard也会对同一variable_scope下的变量进行整理。 可以认为variable_scope是name_scope针对variable的“加强版”。 tf.constanttf.constant是常量tensor，其在声明的时候就定义好值了，且值不可改变。eg. tf.constant(3.0, dtype=tf.float32) tf.placeholder占位符，声明的时候只需要指定类型即可，在运算的时候再指定值。12345x = tf.placeholder(tf.float32)y = tf.placeholder(tf.float32)z = x + yprint(sess.run(z, feed_dict=&#123;x: 3, y: 4.5&#125;))print(sess.run(z, feed_dict=&#123;x: [1, 3], y: [2, 4]&#125;)) 注：placeholder不能eval()，其值只能通过feed_dict的形式传入。 feed_dict：将值以字典的形式传入placeholder，字典的键可以为： placeholder的变量名，直接传入变量名； placeholder的name属性，字符串类型，但必须满足&lt;op_name&gt;:&lt;output_index&gt;的格式（tf中tensor的命名规范），否则系统无法将其对应到相应的placeholder上。","categories":[],"tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://renli1024.github.io/tags/TensorFlow/"}]},{"title":"正则表达式","slug":"正则表达式","date":"2019-02-07T12:10:58.222Z","updated":"2019-07-26T11:31:46.762Z","comments":true,"path":"2019/02/07/正则表达式/","link":"","permalink":"https://renli1024.github.io/2019/02/07/正则表达式/","excerpt":"因为正则表达式的在文本处理，字符串匹配中有着重要应用，因此本文对其基本语法规则及在Python中的应用进行了简要介绍。","text":"因为正则表达式的在文本处理，字符串匹配中有着重要应用，因此本文对其基本语法规则及在Python中的应用进行了简要介绍。注：本文大部分是对博文正则表达式30分钟入门教程，LiZeC的正则表达式笔记以及python re库官方文档的归纳和整理，更详细内容可查阅原文。 Examples 正则表达式 要匹配的字符串 \\bhi\\b 单词“hi” 不能直接用hi来匹配，否则会将him,history,high等单词也匹配上） \\bhi\\b.*\\bLucy\\b hi后面不远处跟着一个Lucy 0\\d{2}-\\d{8} 以0开头，然后是两个数字，然后是一个连字号“-”，最后是8个数字(也就是中国的电话号码) \\ba\\w*\\b 以字母a开头的单词 ^[A-Za-z]+$ 由26个字母组成的字符串 ^[A-Za-z0-9]+$ 由26个字母和数字组成的字符串 ^[0-9]*[1-9][0-9]*$ 正整数形式的字符串（不能全0） (\\d{1,3}\\.){3}\\d{1,3} IP地址表达式（应用了分组的概念） 对于上述IP地址匹配，一个缺点是将256.300.888.999这种不可能存在的IP地址也匹配了。如果能使用算术比较的话，或许能简单地解决这个问题，但是正则表达式中并不提供关于数学的任何功能，所以只能使用冗长的分组，选择，字符类来描述一个正确的IP地址：((2[0-4]\\d|25[0-5]|[01]?\\d\\d?)\\.){3}(2[0-4]\\d|25[0-5]|[01]?\\d\\d?) 0\\d{2}-\\d{8}|0\\d{3}-\\d{7}：这个表达式能匹配两种以连字号分隔的电话号码（应用了分支条件）：一种是三位区号，8位本地号(如010-12345678)，一种是4位区号，7位本地号(0376-2233445)| 基本语法 正则表达式(regular expression)描述了一种字符串匹配的模式(pattern)，主要用来匹配特定的字符串。 正则表达式中分为普通字符和特殊字符，普通字符表示匹配和其相同的字符；特殊字符并不匹配他们本身，而是有特殊含义的，具体有：. ^ $ * + ? { } [ ] \\ | ( )，除了这些特殊字符外都是普通字符。 若要匹配这些字符本身，则需要加上\\进行转义（escape），如\\*表示匹配*本身。 因为python字符串也是使用\\作为转义字符，因此在python中使用正则表达式需要再加一个反斜杠，即用\\\\表示转义；也可以用原声字符串的形式，即在字符串前面加，如r&quot;\\w&quot;。 一些特殊字符含义 &nbsp;&nbsp;&nbsp;&nbsp;字符&nbsp;&nbsp;&nbsp;&nbsp; 含义 . 匹配任意单个字符(除换行符“\\n”外) () 指定分组 [] 指定字符类 {} 指定重复次数 \\s 匹配任意的空白符，包括包括空格，制表符(Tab)，换行符，中文全角空格等 \\w 匹配任意字母、数字、下划线、汉字（即匹配普通字符） \\s 匹配任意的空白符（空格、制表符(Tab)、换行符、中文全角空格等） \\d 匹配数字（0-9） \\b 检测单词的开始或结束（单词边界），如空格，标点符号或者换行但\\b并不匹配这些单词分隔字符中的任何一个，它只匹配一个位置 ^ 检测字符串的开始 $ 检测字符串的结束 一些字符的反义表示如\\w，\\b这些特殊字符的大写表示相反的含义，具体如下： &nbsp;&nbsp;&nbsp;&nbsp;字符&nbsp;&nbsp;&nbsp; 含义 \\W 匹配不是字母、数字、下划线、汉字的字符（多用来匹配特殊字符） \\S 匹配任意不是空白符的字符 \\D 匹配任意非数字的字符 \\B 匹配不是单词开头或结束的位置 关于\\b的一些说明 注：\\b, ^, $匹配的并不是字符，而是一个位置如对于\\blove\\b，用来匹配句子”I love youlove “，其匹配出来的只有第一个love，第二个love不会匹配；其次其只匹配第一个love这个单词本身，而不包括其两端的空格（因为\\b只只是检测单词边界，如空格，标点符号或者换行，而并不匹配这些字符）。 所以如果想要检测单词边界，同时匹配空白符，则需要再指定\\s。 eg.匹配连续出现三次的单词，如果中间不加\\s就匹配不出来（\\b只匹配位置，不匹配任何字符）；同时前后最好用\\b来指定，因为这个单词可能在一行的开始（前面无任何字符），或者最后一个单词后面接了\\n等情况。1repeat_elements = re.findall(r\"\\b(\\w+)\\b\\s\\1\\b\\s\\1\\b\", \"123 mention mention mention 321 123\") 重复匹配限定符以下字符称为“限定符”（限制次数的符号），跟在特殊字符的后面，表示重复该字符特定次数。如\\d+匹配1个或更多个的数字。 限定符 含义 * 重复\\(\\geq\\)0次 + 重复\\(\\geq\\)1次 ? 重复0次或1次 {n} 重复n次 {n,} 重复\\(\\geq\\)n次 {n,m} 重复n到m次 贪婪、懒惰匹配原则 正则表达式的匹配原则为贪婪匹配：即在满足条件的情况下，匹配尽可能多的字符。eg. a.*b会匹配以a开始，以b结束的最长的字符串。如果用来搜索aabab，则会匹配整个字符串aabab而非aab。 若需要懒惰匹配：即匹配尽可能少的字符，就在相应的重复字符后加?即可。eg. a.*?b匹配以a开始，以b结束的最短的字符串，搜索aabab会匹配到aab和ab两个子串（之所以没有仅仅匹配到ab子串，是因为正则表达式的匹配还会考虑开始的先后顺序，最开始匹配的优先级最高）。 懒惰匹配限定符如下： 限定符 含义 *? 重复\\(\\geq\\)0次，但尽可能少重复 +? 重复\\(\\geq\\)1次，但尽可能少重复 ?? 重复0次或1次，但尽可能少重复 {n,}? 重复\\(\\geq\\)n次，但尽可能少重复 {n,m}? 重复n到m次，但尽可能少重复 字符类 在 [ 和 ] 中的若干字符构成一个字符类(character class)。 字符类是为了匹配某种字符集合，表示此位置可以匹配这个类中的任意一个字符。 整个字符类所起到的作用和普通字符相同，都是只匹配单个字符，因此字符类可作为整体再接受其他限定，如? + {n,m}等等。 可以使用-来表示一个范围，例如[a-c]表示[abc] 在字符类中的特殊符号不被转义 反向匹配：在字符类中，如果以^开头，则表示匹配除此字符类中提及的任何其他字符。如[^5]匹配任何不是5的字符。 分枝条件 在正则表达式表示“或”的逻辑，两个条件用|连接即可。eg. \\d{5}-\\d{4}|\\d{5}这个表达式用于匹配美国的邮政编码。美国邮编的规则是5位数字，或者用连字号间隔的9位数字。 在使用分枝条件时要注意各个条件的顺序，如果上文改成\\d{5}|\\d{5}-\\d{4}的话，那么就只会匹配5位的邮编(以及9位邮编的前5位)。因为一旦前面的分枝满足的话就不会再管其他条件了。 注释不推荐在正则表达式内部写注视，注释推荐写在正则表达式的外部语言中。 正则表达式高级特性分组 上文提到了如何重复单个字符（直接在字符后面加表示重复的限定符即可），但若想重复多个字符，就需要用到分组的概念。 用小括号()来指定分组（也叫子表达式），之后就可以对这个分组的整体进行重复或其他操作。eg. (\\d{1,3}\\.){3}\\d{1,3}，就是一个比较粗糙的IP地址匹配式。 后向引用 使用小括号指定一个分组后，这个分组可以作为一个整体在后文中作进一步处理。 默认情况下，每个组会有一个组号，从左到右，第一个出现的分组组号为1(注意不是0)，第二个为2，以此类推。 如何引用：在后问中使用\\+组号的形式来引用，如\\1表示引用1号分组的。eg. \\b(\\w+)\\b\\s+\\1\\b可以来匹配如go go 或kitty kitty 这种连着两个重复单词。 零宽断言 用于查找在某些内容前面或后面的东西（但不包括这些内容），类似于^ $ \\b这种占位符，用于指定一个位置，这个位置应该满足一定的条件(即断言)，因此被称为零宽断言。 (?=exp)：用于匹配exp前面出现的表达式。e.g \\b\\w+(?=ing\\b)用于匹配以ing为结尾的单词的前面部分（不包括ing） (?&lt;=exp)：用于匹配exp后面出现的表达式。e.g (?&lt;=\\bre)\\w+\\b用于匹配以re开头的单词的后面部分（不包括re） 更多示例：(?&lt;=\\s)\\d+(?=\\s)：匹配以空白符间隔的数字(不包括这些空白符)((?&lt;=\\d)\\d{3})+\\b：要给一个很长的数字中每三位间加一个逗号(当然是从右边加起了)，你可以这样查找需要在前面和里面添加逗号的部分（用它对1234567890进行查找时结果是234567890） 负向零宽断言 用于确保某个模式不会出现。与字符类[^exp]的区别：虽然不匹配这个字符，但字符类总是会匹配某个字符的，这会限制字符类的应用场景；而负向零宽断言不匹配字符，其只指代一个位置。eg. 如果用\\b\\w*q[^u]\\w*\\b来匹配“出现了字母q,但是q后面跟的不是字母u”的单词，则像“Iraq, Benq”这种q直接作为最后一个字符的情况就会出错（字符类总要匹配一个字符），因此就需要负向零宽断言。 (?!exp)：断言此位置的后面不能匹配表达式exp。eg.\\b((?!abc)\\w)+\\b匹配不包含连续字符串abc的单词 (?&lt;!exp)：断言此位置的前面不能匹配表达式exp。eg. (?&lt;![a-z])\\d{7}匹配前面不是小写字母的七位数字。 递归匹配 用于匹配一些嵌套的层次结构，如(100*(50+15))，如果只是简单地使用\\(.+\\)则只会匹配到最左边的左括号和最右边的右括号之间的内容。假如原来的字符串里的左括号和右括号出现的次数不相等，比如(5/(3+2)))，那我们的匹配结果里两者的个数也不会相等。如果想要想匹配到最长的，而且配对正确的字符串，就需要用到递归匹配。 具体内容参见博文正则表达式30分钟入门教程 在Python中使用正则表达式example code1234567891011121314151617181920# 查找字符串中连续出现三次的子串（中间以空格分隔）list_result = re.findall(r\"\\b(\\w+)\\b\\s\\1\\b\\s\\1\\b\", \"123 mention mention mention 123 entity entity entity\")print(list_result)# ['mention', 'entity']match_result = re.finditer(r\"\\b(\\w+)\\b\\s\\1\\b\\s\\1\\b\", \"123 mention mention mention 123 entity entity entity\")if match_result == None: print(\"no repeat elements\")else: for match in match_result: print(match.group(), \"start:\", str(match.start())+\",\", \"end:\", str(match.end()))# mention mention mention start: 4, end: 27# entity entity entity start: 32, end: 52m = re.findall(r\"(\\w+) (\\w+)\", \"Isaac Newton, physicist\")print(m)# [('Isaac', 'Newton')]，包含多个子分组的情况下会以tuple的形式返回 使用原生字符串 正则表达式中使用\\n表示转义，而python中恰好也使用\\n表示转义，因此在python中使用正则表达式则需要\\\\来表示反斜杠。 为了节省过多的反斜杠，可以使用Python原生字符串特性，即在字符串开头加上r，如r\\d，在这个字符串中每个字符表示其本身，Python不进行转义。 re库在Python中使用正则表达式直接导入re库即可 import re。 常用函数介绍 只是简单检测字符串是否存在，使用findall()函数即可；否则使用finditer()，返回的match对象方便进行之后的操作；替换、分隔操作直接使用split()、sub()函数； 函数（常用性排序从上至下） 功能 re.findall() 在字符串中查找所有满足条件的子串，返回string list re.finditer() 在字符串中查找所有满足条件的子串，返回匹配出的macth对象的iterator re.split() 将正则表达式作为separator来分割字符串，返回string list re.sub() 在字符串中替换所有匹配正则表达式的子串，返回替换后的字符串 re.search() 在字符串中查找匹配的子串第一次出现的位置，匹配成功返回match对象，否则返回None re.match() 从字符串的起始位置开始匹配，即匹配字符串的开头是否和正则表达式匹配，返回match对象或None re.fullmatch() 匹配整个字符串是否和正则表达式匹配，返回match对象或None re.escape() 自动在字符串中为特殊字符添加 “\\” 转义符，返回修改后的字符串 具体见下文解释 参数说明： re.findall(pattern, string, flags=0)pattern: 表示正则表达式的字符串，推荐使用python原生字符串r&quot;string&quot;flags: 正则表达式的控制标记return: 返回string list，list中每一项表示匹配出来的字符串 re.sub(pattern, repl, string, count=0, flags=0)repl: 用来替代匹配到的子串的字符串 re.search(pattern, string, flags=0)参数同上return: 匹配成功返回match对象，否则返回None re.match(pattern, string, flags=0)参数同上return：匹配成功返回match对象，否则返回None re.fullmatch(pattern, string, flags=0)参数同上return：匹配成功返回match对象，否则返回Non re.escape(pattern)eg. pattern1 = re.escape(&#39;python.exe&#39;))，pattern1就为”python\\.exe”，可直接作为pattern参数传入其他函数中，用来匹配“python.exe”。当pattern含有大量特殊字符时使用这个函数就很方便。 Match类re.search()和re.match()两个函数的返回对象，包含了匹配的相关信息，常用函数和属性如下： 名称 说明 match.group() 返回特定的分组，string或tuple的形式 match.start() 返回特定分组的起始地址 match.end() 返回特定分组的结束地址 （会比实际大1位，因为python字符串截取前闭后开的特性） match.string 为传入到re.search()或re.match()的待匹配字符串 match.groups() 以tuple的形式返回所有分组，element即为各个分组 match.group([group1(int), …])[group1]（可选）：需要返回的组号；没有传参时组号默认为0，对应整个匹配到的字符串，通常情况不用传参数即可。这里的分组指的就是在正则表达式中通过小括号()指定的分组，每个分组从左到右会有一个组号，且组号从1开始。return: string字符串 match.start([group])、match.end([group])两个函数中group都是指组号，返回特定组号的起始、终止地址，默认即指整个匹配的字符串，见小节开头的例子； 分组的对应子串可通过match.string[m.start(g):m.end(g)]来获取。 控制标记flag介绍用于规定正则表达式的一些匹配规则，作为flags参数传入正则表达式函数|标记名(简写/全称)|含义||:-:|:-||re.A / re.ASCII|使\\w,\\b,\\s和\\d只匹配ASCII字符 eg. 不会匹配汉字和其他Unicode字符||re.I / re.IGNORECASE|忽略正则表达式大小写||re.M / re.MULTILINE|使得^表示每一行的开始，$表示每一行的结束 原义仅表示一个单词的开始和结束||re.S / re.DOTALL|使得.可以匹配\\n字符||re.X / re.VERBOSE|忽略正则表达式内部的空白符|注：这些变量在VSCode的python下没有提示，但可以运行。 str.replace()和re.sub的比较 str.replace(old, new[, count])是字符串的替代函数，其中new为替换的字符串，old为待替换的字符串，old只能为substring而不能为字符串，因此替换功能较为简单。 re.sub(pattern, repl, string, count=0, flags=0)则使用了正则表达式，可进行更复杂的替换操作，但同时开销也更大。 因此能用replace()尽量用，复杂的替换操作再使用正则表达式。","categories":[],"tags":[{"name":"正则表达式","slug":"正则表达式","permalink":"https://renli1024.github.io/tags/正则表达式/"}]},{"title":"lecture 4_Word Window Classification and Neural Networks","slug":"cs224n/lecture 4","date":"2019-01-27T22:29:11.473Z","updated":"2019-01-30T21:41:33.320Z","comments":true,"path":"2019/01/28/cs224n/lecture 4/","link":"","permalink":"https://renli1024.github.io/2019/01/28/cs224n/lecture 4/","excerpt":"","text":"本节课是通过任务实例展开的，首先介绍了Word Window Classification任务，之后用softmax和cross-entropy进行线性分类，之后用神经网络进行了非线性分类（引入Max-Margin loss &amp; back propogation），其间对相关方法进行了讲解。 Simple word classfication task —— linear classfication 输入输出: \\(\\{x_i, y_i\\}^N_{i=1}\\)\\(x_i\\): 词向量\\(y_i\\): 输出的分类结果（各个类别的概率分布） 分类公式：注：分类逻辑就相当于蕴含在矩阵\\(W\\)中 Loss function：但光有分类公式还不够，我们还要使分类结果最优，即：使整个数据集的分类结果\\(P(y|x)\\)最优（一个\\(P(y|x)\\)只是针对单个词的分类结果）,因此就有了损失函数。 交叉熵：其中涉及到了Kullback-Leibler divergence（KL散度），其可用于衡量两个概率之间的误差，在这个任务中我们可以用来衡量\\(P(y|x)\\)和ground truth/gold/target probability（即正确的分类结果：[0,…0,1,0,…0]，一个为1，其余为0）的误差。误差越小，代表分类结果越好。 交叉熵公式：$$H(p, q) = -\\sum_{c=1}^Cp(c)logq(c)$$我们把p(c)看成gold，把q(c)看成预测结果，就有了我们最后的损失函数。 损失函数：$$J(\\theta) = \\frac {1} {N} \\sum_{i=1}^N -log(\\frac {exp(f_{yi})} {\\sum_{c=1}^Cexp(f_c)})$$注1: \\(f = Wx\\)注2: 最终最小化损失函数即可（Maxmize \\(P(y|x)\\) -&gt; Minimize \\(-logP(y|x)\\)）。分类问题中是否更新词向量 在优化损失函数的时候，可以只选择\\(W\\)作为优化参数, 但可将词向量作为一个参数也同时进行梯度下降更新，从而使得词向量更为适合当前任务。 判断标准：当前任务的数据集的大小。若当前任务数据集不大，则更新词向量很有可能会contaminate原先的向量空间，使得效果反而下降；但若数据集总量很大，可以保证词向量优化效果，且计算资源充足，则应进行优化。 Word Window Classification 任务目标: Classify a word in its context window of neighboring words.eg. 命名实体识别任务: 对单词是Person, location, organization还是none进行分类。 相比于单个单词的分类，Word Window Classification是将上下文单词也进行考虑，从而帮助对中心词的分类。 与上文的单词分类相比，唯一改变的只是输入\\(x_i\\)，原来是一个单词的词向量，现在输入的是整个window所有单词词向量的拼接(concatenation)。通过整个window的context words来帮助对中心词的分类。 注：window模型有很多种处理方式，如可以将window中的所有单词不考虑位置作乱序处理，以及其他方法来更多地探索上下文信息。 神经网络分类 只用SoftMax分类的问题：只能提供线性分类的结果，在复杂数据集上的表现不好。 神经网络的优点是具有强大的非线性拟合能力，而这种拟合能力很大程度上来源于神经元各种各样的非线性激活函数。 Max-margin Loss function依旧是ner的任务，对单词是不是地点进行分类。s = score(museums in Paris are amzing)：中心词是地点的句子sc = score(Not all meseums in Paris)：中心词不是地点的句子公式：$$ J = max(0, 1-s+sc) $$idea：将中心词是地点的句子（正例）的得分最大化，中心词不是地点的句子（负例）的得分最小化。即正例句子的分值要比负例句子的分值 &gt; 1。注1：将\\(J\\)值最小化即可 -&gt; 0。注2：公式中的1可看作一个超参数，通常是1，也可是其他数。注3：公式是连续的，因此可使用SGD。","categories":[],"tags":[{"name":"cs224n","slug":"cs224n","permalink":"https://renli1024.github.io/tags/cs224n/"}]},{"title":"numpy笔记","slug":"Python/numpy笔记","date":"2018-12-25T17:11:34.447Z","updated":"2019-07-23T11:07:27.303Z","comments":true,"path":"2018/12/26/Python/numpy笔记/","link":"","permalink":"https://renli1024.github.io/2018/12/26/Python/numpy笔记/","excerpt":"","text":"基本类型: np.array，表示一个张量零维: np.array([1]), shape: (1, ) 或 ()一维: np.array([1,2]), shape: (2,)二维: np.array([[1,2], [3,4]]), shape: (2, 2)三维: np.array([[[1,2], [3,4]], [[5,6], [7,8]]]), shape: (2, 2, 2)四维: np.array([[[[1,2], [3,4]], [[5,6], [7,8]]], [[[1,2], [3,4]], [[5,6], [7,8]]]]), shape: (2, 2, 2, 2, 2)把维度的增加理解为向高一级的抽象(四维数组就是多个三维数组的组合).注：numpy中的axis指维度（dimension），axis/dimension = 1 指第一个维度，即“最上层”的维度。 broadcastingeg: 2*[1,2,3] = [2, 4, 6]一种节省内存的方法, 让系统自动推断矩阵的shape(不用定义两个完全一样的shape, 相同的元素可以由向量省略为一个数)详细文档: https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html 行向量-&gt;列向量:普通矩阵的转置直接.T即可, 但.T不适用行向量&amp;列向量, 因此需要其他方法: reshape(-1, 1),只指定列宽为1, -1表示让系统自动推断大小. numpy可以使用index来取数，但要传入ndarray来表征index： 123ary = np.array([1, 2, 3, 4, 5, 6, 7])a = ary[np.array([1,2,3])] # 取下标为1, 2, 3的元素print(a) # [2, 3, 4]","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"https://renli1024.github.io/tags/Python/"}]},{"title":"lecture 3_More Word Vectors","slug":"cs224n/lecture 3","date":"2018-11-26T22:55:12.828Z","updated":"2019-02-21T22:47:17.886Z","comments":true,"path":"2018/11/27/cs224n/lecture 3/","link":"","permalink":"https://renli1024.github.io/2018/11/27/cs224n/lecture 3/","excerpt":"","text":"单词的向量表征本节lecture主要是对上一节内容的扩展，重点还是在如何用向量来表征单词上，以使得单词间获得更好的相似性，而且我们可以直观地理解这种相似性。核心思想是通过计算单词间的共现（co-occurence）次数/频率/概率来表征单词间的相似性——两个单词同时出现在相同context中的次数多了，我们就认为这两个单词比较相似。 一种模型是skip-gram模型，一步步地计算每个窗口，最终得出单词间相似性。 另一种模型是Glove，基于共现矩阵的思想，一次性统计语料库中所有单词两两间的共现次数，从而得出单词间的相似性。 如何评估词向量的优劣两种评价思路：intrinsic &amp; extrinsic（内部评价和外部评价） intrinsic evaluation通过分析词向量本身的一些特性来评价：如词与词之间的余弦相似度、 欧式距离或类比关系（analogy, 即 man-woman=king-queen 这种线性关系），如果得出的词向量这些关系好（eg. 词义相似的词向量在向量空间中距离也很近），那么这个词向量就好。注：总的来说Glove表现的最好。 extrinsic evaluation通过一些下游的任务来评价词向量的好坏，如我们把训练好的词向量用于命名实体识别任务中，看词向量实际表现的怎么样。注：还是Glove模型表现的最好。 两种评价方法的优劣intrinsic evaluation速度快，可以帮助我们更好地理解这个任务本身。但实际上这并不是一种真实的评价方法，即我们不知道这种词向量模型在实际任务中到底表现得怎么样。extrinsic evaluation则是一种真实的评价方法，可以确切地得出词向量模型的好坏。但缺点是计算出最终结果很费时间，而且如果表现不好，我们并不能准确地分析出原因（到底是向量模型本身的原因，还是向量模型和其他模型互相影响(interact)的原因）","categories":[],"tags":[{"name":"cs224n","slug":"cs224n","permalink":"https://renli1024.github.io/tags/cs224n/"}]},{"title":"机器学习基础知识","slug":"机器学习基础知识","date":"2018-11-06T21:07:19.846Z","updated":"2019-05-29T01:37:58.551Z","comments":true,"path":"2018/11/07/机器学习基础知识/","link":"","permalink":"https://renli1024.github.io/2018/11/07/机器学习基础知识/","excerpt":"","text":"梯度下降（gradient decent）基本概念 什么是梯度：在多元函数中，梯度可理解为求各个变量的偏导数，最终各个偏导组合成梯度向量，即代表该函数在该点变化最快的方向。eg: \\(f(x,y)=x^2+y^2\\), 梯度向量为(2x,2y)，在点(1,1)处的梯度即为(2,2)，即沿(2,2)这个方向函数变化最快。 梯度下降的作用: 求损失函数的最小值. 因为梯度是函数值下降最快的方向, 所以经常用梯度来构造参数的更新表达式, 以此来求使得损失函数的函数值最小的参数值. Vanilla Gradient Descent（普通梯度下降）1、求解梯度向量2、一点点沿着梯度的方向迭代更新函数值，使函数最终下降到局部最小值处。$$\\theta^{new}_j=\\theta^{old}_j-\\alpha\\nabla_{\\theta}J(\\theta)=\\theta^{old}_j-\\alpha\\frac {\\partial}{\\partial \\theta^{old}_j}J(\\theta)$$注1: \\(J(\\theta)\\)是损失函数, \\(\\theta\\)是参数, \\(\\alpha\\)是步长（step size).注2: 步长\\(\\alpha\\)的值若取太小则求解速度慢，取则会造成抖动。解决方法：距离谷底较远时，步幅大些比较好（加快速度）；接近谷底时，步幅小些比较好（以免跨过界）。距离谷底的远近可以通过梯度的数值大小间接反映，接近谷底时，坡度会减小，因此可设置步长与梯度数值大小正相关。 Stochastic Gradient Descent（SGD，随机梯度下降）VGD中，损失函数相当于每个数据样本取平均值，因此每次更新都需要遍历所有data，当数据量太大，更新一次梯度会花费大量时间，因此并不可行。解决这个问题的基本思路：只通过一个随机选取的数据(xn,yn)来获取梯度（通常损失函数都是很多项的变量加和得到的，这时只取一项计算其梯度，用来估计整体的梯度），这种方法叫随即梯度下降。虽然这样估计梯度非常粗糙，但事实证明这种方法效果还不错。 Softmax函数 作用：Takes an un-normalized vector, and normalizes it into a probability distribution. After applying Softmax, each element \\(x_i\\) will be in the interval \\([0,1]\\) and \\(\\sum_ix_i=1\\). 公式：$$p(x_i) = \\frac {exp(e_i)} {\\sum_{n=1}^Nexp(x_n) }$$ 应用：可用于分类任务中，对目标进行线性分类；也经常用在神经网络中，用于将输出值归一化（原先值可能有负数，可能大于1，且所有值加和不为1），可视为产生概率分布。 Sigmoid函数epoch，batch，iteration概念解释结论先行：epoch是全量数据集经过一次计算的过程，batch是全量数据集中的一小份，iteration则是batch经过一次计算的过程。（“一次计算”的含义：计算了一次梯度，并用优化算法（eg. 梯度下降）对神经网络进行了一次更新） batch bacth指将数据集分为若干小份，一个小份一个小份去计算梯度、更新神经网络，通常也成为mini-batch。 为什么会有mini-batch 神经网络中，所有的优化方案都是梯度下降，一般两种方式：第一种是遍历全部数据集算一次损失函数，然后算函数对各个参数的梯度，更新梯度，这种方法最大的缺点就是计算开销大；另一种是每看一个数据就算一次损失函数，然后求梯度更新参数，称为随机梯度下降。这种方法虽然速度块，但收敛性能不好，可能在最优点附近晃来晃去。 batch即是两种方案的折衷，即小批的梯度下降，把数据分为若干个批，按批来更新参数。计算量不大，同时一批中所有数据共同决定梯度下降的方向，减少了随机性和震荡性。 下图是三种计算方式的比较，蓝色线表示取一次取全量数据集计算，收敛效果更好，适合数据集不大的情况；红色线为随机取数据计算（Batch_Size等于1的情况），可以看出较难以收敛；绿色线为mini-batch，减轻了stochastic的震荡性，计算量增加也不大，是一种较为折衷的训练方式。 batch size对训练过程的影响 若batch size过小，训练数据就会非常难收敛，从而导致underfitting。 增大batch size，不仅收敛效果更好，而且处理速度也会加快（单次batch计算可以并行化地处理更多数据，单次epoch的迭代次数减少，即提高运行速度）。 但增大batch size，所需内存容量增加（每次计算需要将batch中的数据加载进内存），所以也不能一味地增加bacth size。 epoch当完整的数据集通过了神经网络一次，这个过程就称为一次epoch，神经网络训练通常会将整个数据集在神经网络上计算多次，即多个epoch。 为什么要使用多个epoch提升训练效果。经验证明只对数据集计算一次不足以拟合神经网络，所以将数据集在同样的神经网络中传递多次以提升训练效果。但注意epoch次数过多会导致过拟合的问题，且计算开销会增大，因此也要合理选择epoch次数。 iterationiteration是相对batch而言的，对batch的数据进行一次计算就算做一次iteration。eg. 训练集有1000个样本，batchsize=10，那么训练完整个样本就需要：1000/10 = 100次iteration（即1次epoch需要100次iteration）。","categories":[],"tags":[{"name":"cs224n","slug":"cs224n","permalink":"https://renli1024.github.io/tags/cs224n/"}]},{"title":"lecture 2_Word Vectors","slug":"cs224n/lecture 2","date":"2018-11-05T21:32:18.948Z","updated":"2018-12-17T17:29:42.073Z","comments":true,"path":"2018/11/06/cs224n/lecture 2/","link":"","permalink":"https://renli1024.github.io/2018/11/06/cs224n/lecture 2/","excerpt":"","text":"How to represent the meaning of a word in computer离散表示（discrete representation） 把单词作为一个个原子符号（atomic symbol）来表征：hotel, conference, walk… 对应到计算机中，使用独热编码（one-hot encoding）来存储：[0 0 0 0 1 0 0 0] 存在的问题：1、向量规模过大：每个单词都对应一个单独的位，若要存储所有单词，则会需要一个非常大的向量。2、难以计算单词间的相似性：这是一种localist representation, 每个one-hot representation是独立存在的，no inherent notion of similarity, 两两间并没有天然的相似性关系。3、因此与其去研究an approach to work out similarity relationship between one-hot representations，不如直接探究an approach where representation of word encodes its meaning inherently，这样就能直观去计算单词间的similarity，这就是分布表示（distributed representation）的设计初衷。注：这里的similarity指的是单词词义上的相似，而不是结构相似。 分布表示（distributed representation） 核心思想：通过单词的上下文（context）来理解词意。如banking这个单词，我们让计算机知道经常和它一起出现的其他单词，就相当于明白了单词的用法——怎样将单词放到正确的上下文中，就相当于理解了单词的meaning。 具体方法：用向量定义词语的含义。通过调整一个单词及其上下文单词的向量，使得根据两个向量可以推测两个单词词义的相似度，就可以根据中心词向量预测上下文/根据上下文向量预测中心词。这就是我们常说的word2vec遵循的基本原则：出现在相同上下文中的单词词义会相似。 注：区分distributed和distributionaldistributed meaning：一种词义表示，和one-hot相对，one-hot将词义独立地存储在本地（[0 0 0 0 1 0 0 0]向量中），distributed则存储在一个大的稠密的向量空间中。distributional similarity：一种通过上下文来理解词义的方法，与denotational相对。We use distributional similarity to build distributed meaning. word2vec模型Skip-grams(SG) 作用通过中心词预测上下文。 定义预测单词上下文的模型预测模型：\\(p(context|w_t)\\)，表示在给定中心词\\(w_t\\)的条件下，正确预测出上下文单词的概率。再具体点：\\(p(w_{t-1}|w_t)\\)，\\(p(w_{t-2}|w_t)\\)，\\(p(w_{t+1}|w_t)\\)，\\(t, t+1, t-1\\)都是表示单词在文中出现的序号。最终形式：$$ p(w_{t+j}|w_t)=p(o|c)=\\frac {exp(u_0^Tv_c)} {\\sum_{w=1}^v exp(u_w^Tv_c)} $$\\(t, t+j\\)是单词在文中的位置.\\(o, c\\)则是单词在单词表中的序号，相当于在更为一般地表征两个单词的关联（与具体文本无关）。\\(v_c\\)是中心词的词向量，\\(u_0\\)是上下文单词的词向量。公式理解：首先是\\(u_0^Tv_c\\)，这是一个点积操作，可用来粗糙地衡量单词间相似性（单词越相似，向量值越相近，乘积越大）；其次是softmax操作，用来把值转换成概率：$$\\frac {exp(u_0^Tv_c)} {\\sum_{w=1}^v exp(u_w^Tv_c)} $$最终即得出了由中心词预测上下文单词的概率。 定义损失函数（Loss Function）1、首先对模型全部相乘，表示文本整体的预测正确率：$$ J^`(\\theta)=\\prod_{t=1}^T \\prod_{ \\begin{align}-m\\le j \\le m\\\\j \\neq 0\\end{align} }p(w_{t+j}|w_t)$$目标：整体正确率最大，maximize the function，2、做Negtive Log Likelihood处理，使maximize-&gt;minimize，即得到最终的损失函数。$$ J(\\theta)=-\\frac {1}{T} \\sum_{t=1}^T \\sum_{ \\begin{align}-m&amp; \\le j \\le m\\\\j \\neq 0\\end{align} }p(w_{t+j}|w_t)\\\\p(w_{t+j}|w_t)=\\frac {exp(u_0^Tv_c)} {\\sum_{w=1}^v exp(u_w^Tv_c)}$$最终目标：使损失函数最小。 怎样求损失函数最小值：梯度下降（gradient descent）注1：具体求解过程见lecture slide。注2：求梯度时对\\(u_o和v_c\\)都要求偏导，最后组合成梯度向量。且求的是向量的导数，和实数求偏导有一定区别。注3：当数据量过大时，可使用SGD随机梯度下降来加快速度（一个窗口计算一次梯度，用来估计整体梯度）。 怎样训练模型模型中的参数就是每个单词对应的word vector向量，将所有参数组合成一个的大向量\\(\\theta\\)，即作为损失函数的自变量。总共V个单词，每个单词对应两个词向量，词向量每个d维，因此\\(\\theta\\)总长度为2dV。为何每个单词对应两个词向量：作为中心词时一个，作为上下文单词时一个，这样更方便数学处理。 Continuous Bag of Words(CBOW)作用通过上下文预测中心词To be continued 遗留问题： SG模型中，计算每个上下文词向量的值时，context matrix是一样的？ 那计算出的结果不就一样了？————context matrix是一样的，但因为每个单词的词向量表征是不一样的，所以最终训练出来的上下文词向量也是不一样的。直观来说，context martrix是一各由中心词-&gt;上下文的转换, 在词向量空间中从一个单词向这个单词周围来扩展(词义相近单词离得近), 这种变化对每个单词都是一样的, 因此context martrix一样也是正常的. 如何迭代\\(\\theta\\)来更新梯度？把\\(\\theta\\)初始化成什么样子？————按照梯度下降的法则来更新参数; 参数初始化有多种策略. 这是有监督的学习过程，损失函数中没有出现计算误差的部分？","categories":[],"tags":[{"name":"cs224n","slug":"cs224n","permalink":"https://renli1024.github.io/tags/cs224n/"}]},{"title":"lecture 1_Introduction","slug":"cs224n/lecture 1","date":"2018-11-02T12:33:38.275Z","updated":"2018-11-14T23:55:49.554Z","comments":true,"path":"2018/11/02/cs224n/lecture 1/","link":"","permalink":"https://renli1024.github.io/2018/11/02/cs224n/lecture 1/","excerpt":"","text":"关于人类语言(human language)人类语言的特点 语言就是符号：人类语言本质是一个符号系统（symbol system），无论是汉字还是英文字母，都是一种符号，用来承载、传递我们想要表达的意思（meaning）。 语言的载体：sound, vision(writting), gesture，不论是哪一种载体，都是一种连续的交流方式。 大脑是一种符号处理器（symbolic processors）：我们可以把大脑处理语言看成是连续模式的激活过程（continious pattern of activation）。 因此我们可以得到启发：探索一种连续的编码模式来表达思想(explore a continous encoding patten of thought)。这也是很多NLP算法的处理思想，同时也解决了sparsity的问题。 关于NLPNLP levels 两大来源：通过语音或者文本。语音：语音分析（phonetic）或音韵分析（phonological）；文本：OCR识别（Optical Character Recognition，光学字符识别）或分词处理（tokenization）。通过上述方法来获取NLP的输入。 形态分析（morphological）：对单词进行形态分析：前缀（prefix）、后缀（suffix）等。 句法分析（syntactic）：分析句子结构、语法结构（structure of sentence）。 语义理解（semantic interpretation）：work out the meaning of sentences. 语篇处理（discourse processing）：因为大多数句子含义需要通过上下文（context）来推测，不能仅仅只分析当前句子，因此就有了the field of discourse processing。注：cs224n课只重点讲syntatic &amp; semantic analysis 这两块，以及一部分speech signal analysis。 NLP Applications 较低级：spell checking, keyword search, finding synonyms 中级：extracting information。个人比较感兴趣的方向，让计算机可以阅读文本，理解在讲些什么，至少知道讲的是哪方面内容；从文本中识别、抽取某方面内容；或者为文本阅读难度分级（work out the reading level of school text）,识别文本的目标受众（intended audience of document）；情感分析（positive or negetive）。 高级：机器翻译、对话机器人、智能问答、机器撰写（exploit the knowledge of world） Why is NLP hard 语言本身的困难性：Ambiguilty of language, and moreover, humen always do not say everything（为了高效表达，语言使用中会出现很多省略）. 表征语言很困难：Complexity of representing, using linguistic/situational/world knowledge. 解释语言很困难：Real meaning of the language depends on real world, common sense, and contextual knowledge. 关于deep learning传统机器学习的问题 Most traditional machine learning algorithms work well because of human-designed representations and input featured. “Machines” are only used to optimize weights that best make a final prdiction. Moreover, manually designed featured are often over-specified(lack of generalization), incomplete and take a long time to design and validate. What is deep learning Subfield of machine learning and part of representation learning. Deep learning algorithms attempt to learn (multiple levels of) representations and an output themselves. We only input the raw data. In a lot of times, deep learning means neural networks (the dominant model family). deep learning in NLP核心思想：用vector去表征语言，用神经网络去组织、计算vector。","categories":[],"tags":[{"name":"cs224n","slug":"cs224n","permalink":"https://renli1024.github.io/tags/cs224n/"}]},{"title":"Python3 Programming","slug":"Python/Python3 Programming","date":"2018-09-13T07:49:59.000Z","updated":"2019-08-03T13:08:21.310Z","comments":true,"path":"2018/09/13/Python/Python3 Programming/","link":"","permalink":"https://renli1024.github.io/2018/09/13/Python/Python3 Programming/","excerpt":"本文主要介绍Python3的基本概念、语言机制和程序结构等知识。","text":"本文主要介绍Python3的基本概念、语言机制和程序结构等知识。 基础知识面向对象 &amp; 动态类型 python是一门面向对象的语言，所有出现的值都是对象，都具有类型（可通过type()查看）。 python中对象有类型，变量无类型：变量相当于指针，只是对象的一个引用，用来访问对象的值；就像一个标签，贴到哪个对象上就代表哪个对象，可随意更改其指向的对象，因此也就没有固定类型。具体见python变量的绑定(binding)机制 Python变量也可以说是动态类型的：变量类型是在运行过程中决定的，系统会自动根据变量名绑定所绑定的对象来推断其类型，且变量的类型在程序中可随意更改。这样做的好处是为程序带来了灵活性，但坏处是增加了程序调试难度（较难明确变量类型），且变量很容易被误覆盖（没有关于类型的赋值限制）。 并非解释型语言 常有人说python是解释型语言，其是并不是这样的。python和java类似，其实是先编译再解释类型的语言，python会将源代码文件编译为pyc文件（在项目文件夹的__pycache__/下），然后再在虚拟机上解释运行。更详细的介绍可见关于编译型和解释型语言 数数的类型 int类型(signed intergers，有符号整数)：python3中int就是长整型，且python对大整数进行了特殊处理，因此一般不用担心整数溢出问题。 python中int是动态长度的，即内存中并非严格的4Byte，会根据数的大小动态变化。（不过也在4Byte左右，估算时可以就用4Byte来算）。 float类型(floating point real values)：在内存中按4Byte来存储，采用科学计数法的表示形式，最大值在在e+308级。 complex类型(complex numbers)：暂时还没用到过。 数之间的转化直接调用构造函数即可，eg. int()、float()。 float的误差问题 在计算机中数都是以二进制的形式存储的，因此十进制小数转化为二进制时会存在误差，eg. 0.1的二进制表示为0.000110011…（无限小数，无法精确表示） 虽然，但还是要明确：每次使用浮点运算都是有可能引入舍入误差的。如： 1234&gt;&gt;&gt; 0.1+0.20.30000000000000004&gt;&gt;&gt; 10/33.3333333333333335 不过大多数情况下误差是很小的（python浮点数精度为小数点后16位，到17位后才开始不准确），完全满足日常的计算需求。且对于数比较相等、比大小等情况，python内部也会对其处理，因此并不会有影响。 对于实在特殊的精确计算要求，有如下解决办法： 使用decimal模块，其实现了十进制的运算，因此不存在浮点误差； 使用fractions模块，其会按照分数的规则来计算，也不存在误差； 使用numpy等其他科学计算包12345678910111213import decimala = deciamal.Decimal(\"10.0\")b = decimal.Decimal(\"3\")print(a/b)# 3.333333333333333333333333333from fractions import Fractionprint(Fraction(10, 3)) # 分数10/3print(Fraction(10, 8)) # 分数5/4print(Fraction(5, 3))# 10/3# 5/4# 5/3 基本运算算数运算符 只要运算的两方有一方是浮点数，那么结果为浮点数； 对于除法运算/，其结果一定位浮点数。 描述 对应运算符 加 + 减 - 乘 * 除 / 取余 % 取商 math.floor(x%y)或divmod(x, y)[0] 取绝对值 abs() 取整 math.floor()（直接截断到整数位） 控制小数位数/精度 round()或字符串格式化 指数运算 ** 开平方 sqrt() 其他运算符 描述 对应运算符 boolean或 or boolean与 and boolean非 not x 是/不是其中的成员 in, not in 两个对象是否为同一个 is, is not 比较 ==, !=, &lt;. &lt;=, &gt;, &gt;= 正负号 +x, -x 按位与（转为二进制后计算） &amp; 按位异或 ^ 按位翻转 ~x 左移y位 x&lt;&lt;y 右移y位 x&gt;&gt;y 按位或：| 注释写法 注释单行注释：#多行注释：三对单/双引号，’’’xxx’’’或”””xxx””” python3和python2区别1、输出: python3是print(xxx), python2是print xxx；2、输入: 从键盘输入字符不同；3、自定义class：python2要手动继承object变量，python3则自动继承了。其他地方暂时还没碰到过。 语句 if语句123456if a==5: xxxelif a==10: xxxelse: xxx 采用四个空格的缩进来表示语句块开始，删去缩进表示语句块结束；不要忘了冒号。三元表达式：A = Y if X else Z for语句 123str=\"hello\"for i in range(len(str)): print(str[i],end=' ') #输出为h e l l o 同样注意冒号，缩进 for else语句 12345for i in range(1,10,2): #语句块else : #for循环正常结束会执行 #break直接跳出，不会执行else while语句 12while a&gt;5 : #while语句 Context Manager 机制 Python中的Context Manager指支持上下文管理的对象（这里的对象指较为广义的对象，可以是一个object，也可以是一个函数等），这种对象可以通过with语句块进行自动的上下文管理（进入语句块前和离开语句块后自动进行相应的上下文切换操作）。 常用的实现Context Manager的方式有三种： 通过面向对象的形式，实现类的__enter__() and __exit__()成员函数（最常用）； 使用生成器generator； 使用contextmanager decorator。 下面重点介绍第一种方式的实现。 With Statement python中的with语句是主要用来简化try...finally语句块，以保证clean-up code一定会被执行。 with语句本质上是一个资源管理语句（或者说上下文切换语句），其特别之处在于可以在语句块开始和退出时自动执行一些功能，这就特别适合那些需要正确初始化和释放的资源，如文件操作、tensorflow的session操作等。 因此当代码涉及到一些复杂的资源时，就可以把代码放到with语句块中，这样就可以保证资源能被正确地初始化和结束/正确地进行上下文切换。 如何实现with语句：上文所指的“资源”本质就是class，通过定义类的成员函数__enter__()和__exit__()，就可以实现让with语句自动管理资源的功能。 如何使用with语句：12345678910with expression [as name]: with-block# expression是一个object，as定义了对象在这个语句块中的变量名# eg.with open('filename', 'r') as f: for line in f: print('&gt; &#123;&#125;'.format(line))with tf.Session() as sess: # ... 函数文件操作 文件路径Windows中文件分隔符为\\\\, Linux和Mac中是/, 注意区分.绝对路径: Mac下绝对路径为/Users/lrrr/Dekstop(Doucuments, Downloads等), 起始为/Users/lrrr.相对路径: 相对是指相对于.py文件所在目录的路径, 路径中用.表示向上一级目录(..就是上两级目录). 读取文件 12345678f = open(\"test.txt\")for line in f #读取一行 print(line)或f = open(\"e:\\\\test.txt\")f.read(12) #读取12个字符f.readline() #读取一行f.readlines() #按行读取文件，并存到list中 写文件 123456f = open(\"e:\\\\test.txt\",\"w\") #先清空文件再写或f = open(\"e:\\\\test.txt\",\"a\") #追加写f.write(xxx)#插入换行f.write(xxx+'\\n') #win下会自动翻译为\\r\\n，直接在字符串中写\\n没用 Python面向对象如何定义类类和函数一样，必须先定义再使用，123456class ClassName: &lt;statement-1&gt; . . . &lt;statement-N&gt; 注：python2中class定义的写法为class ClassName(object):，之所以加object是要即成object类，而在python3中类默认继承object类，所以就不用加了。 类变量 &amp; 实例变量 Class Variables：类变量，用于描述在类的所有实例中通用的数据。定义在类的成员方法之外，所有类的实例都可以访问其值，即类和实例都可以对变量的进行引用；但赋值操作只能通过类来完成，实例.class_variable = xxx的赋值操作只会在实例内生成一个新变量，而不会修改类变量的值。 Instance Variables：实例变量，用于描述针对每个实例的特定变量。通过self.xxx的形式定义，因为有self.前缀，所以既可以定义在函数内也可在函数外，都会处于相同的namespace下。 关于Class的namespace：一个class定义后，通常会有三个namespace scope： 类scope：定义在成员函数外部，没有self.前缀的变量，属于类变量（所有成员函数也属于类scope），这部分内容类和实例都可以访问； 类成员函数scope：定义在成员函数内部，没有self.前缀的变量，属于函数的局部变量，只在函数内起作用； 实例scope：定义在成员函数内部（因为要传入self参数），必须有self.前缀，属于实例变量，这部分内容只有实例才能访问； 如何定义类属性eg.1234@propertydef dims(self): \"\"\"Returns a list of Dimensions, or None if the shape is unspecified.\"\"\" return self._dims 前面要有关键字@property；定义成函数的形式，把相应的值返回出去。 slice机制 python中类可以通过实现__setitem__和__getitem__方法，来实现以list的形式设置、访问类中的属性。即my_class[0], my_class[1]这种方式。 Python还有更强大的slice访问机制，只要是实现了上述方法，可以很方便地访问多个元素，如对数组list而言，有以下功能： 1234567891011121314array[start:stop] # items start through stop-1array[start:] # items start through the rest of the arrayarray[:stop] # items from the beginning through stop-1array[:] # a copy of the whole arrayarray[start:stop:step] # start through not past stop, by steparray[-1] # 取最末一项array[-2:] # 取最末两项array[:-2] # 从开始取到倒数第二项（不包括倒数第二项）a[::-1] # 倒序取所有元素a[1::-1] # 倒序取前两项（从1开始，倒叙取）a[:-3:-1] # 倒叙取后两项（以-3结束，倒叙取）a[-3::-1] # 从后往前倒序取所有元素（除最后两项） 还可以实现__iter__方法，实现对类中元素的迭代。 Python Naming ConventionsNaming With Underscoresto be updated: https://dbader.org/blog/meaning-of-underscores-in-python Single Leading Underscore: _var Single Trailing Underscore: var_ Double Leading Underscore: __var Double Leading and Trailing Underscore: __var__：前后都有双下划线的命名方式，通常用于有特殊用处的的成员方法，如__init__()用于类的构造函数，__setitem__()和__getitem__()用于实现sclice机制。最好不要自己定义这种命名的函数，说不定就和哪个系统保留函数冲突了。 Python变量的命名空间机制变量的绑定(binding)机制 在Python中，所有的变量名都是引用(reference)/指针(pointer)，并不是真正的对象，其只是将名字绑定到对象上，可以将其理解为指针（指向某个内存地址）。 因此变量的重新赋值操作，即a = b，只是将变量名绑定到了另一个对象上了而已，并没有更改原对象的值（况且有些类型的值根本就不可更改：imutable types）。 因此函数的参数传递也都是传引用，python中根本就没有“传值”一说。 Python有垃圾回收机制，会管理所有已分配内存的对象，当对象没有变量名引用的时候，系统就会自动将其释放掉。 引用、赋值操作与namescope 在Python中，对变量来说总共就有两种操作，一种是引用操作(reference)，即直接使用变量，属于读操作；一种是赋值(assignment)操作，即a = 123，属于写操作。 对于赋值操作(assignment)，其会更改当前local namespace下变量所绑定的值，local namespace下变量不存在就新建一个变量。因此赋值操作怎么也不会改变高层次的namespace下的变量（除非指定nonglobal/global statement，或通过attribute的形式（module_name.variable）明确指定变量）； 而对于引用操作(reference)，则会按namespace从小到大来搜索相应的变量（local-&gt;nonlocal-&gt;global-&gt;built-in），来确定变量所指向的对象。如果都找不到，程序即会出错。 可变类型和不可变类型 在python中，类型分为可变(mutable types)和不可变(imutable types)两大类，不可变类型包括int, float, bool, str, tuple, unicode，可变类型包括list, set, dict，以及大部分的自定义class都是可变类型。 这里说的可变和不可变，指的是已分配到内存上的值是否可以再更改。对于不可变类型，如int，一旦分配就不能再更改，想要新的值只能重新分配；对于可变类型，可通过其成员方法来改变其值（如list.append()方法）。 注意：对于不可变类型，通过赋值(assignment)的方式是无法改变原有内存上的值的，其只是将变量名绑定到了另一个内存地址上了而已。可变类型的值的修改只能通过特定的函数。123456list_x = [1, 2, 3]list_y = list_xlist_y = [4, 5, 6]print(list_x) # 输出依旧是[1, 2, 3]list_y.append(4)print(list_x) # 输出为[1, 2, 3, 4] 变量的命名空间(Namespaces) A namespace is a mapping from names to objects。即命名空间就是一个映射，从名字到其所指代对象的映射。 具体来说，定义在module中的名字、python的内置函数（eg. abs()）都属于namespace。 其实只要有变量名/函数名出现，就是namespace，python的变量绑定机制就是namespace所指的映射。 命名空间的四种范围(four scopes of namespace)每个namespcace都会有一个范围(scope)，以此来保证名字的可重用性（相同的名字在不同命名空间中可以指向不同的对象）。命名空间按从小到大可分为以下四种： Local Scopes：局部命名空间。在函数内即对应当前函数的命名空间，若没有global/nonlocal声明，在函数内赋值的变量默认都属于这个命名空间；在模块内即对应全局命名空间。 Scopes of enclosing functions：即外层函数的命名空间，对应non-local statement； Global Scopes：全局命名空间，指module-level的命名空间，有两种声明方式：a. 在module最顶层声明的变量默认都属于全局空间（全局空间其实就相当于module的局部空间）；b. 在函数内部，通过global statement声明的变量，会映射到全局变量空间中去寻找其指向的对象，即到module-level去寻找对象； 注1：module.name方式调用的都属于这个命名空间。 注2：直接在写在模块最顶层的变量，最终都会变为__main__ module的一部分，因此他们属于__main__ module的全局空间。 Built-in Scopes：内置命名空间，指python的内置变量、函数。 给定一个变量名，必须要确定其所属的命名空间才可知道其指向的对象，赋值操作中的变量默认都是属于local namespace。 因此外层命名空间的变量对内层函数来说都是只可读取、不可赋值的（因为若想通过a = b来更改变量所绑定值，只会创造一个属于local scope的新变量）。因此若想重写外层变量，只能通过non-local和global statement。 对于变量的引用操作(reference)，会按namespace从小到大来搜索（local-&gt;nonlocal-&gt;global-&gt;built-in），以确定变量所指向的对象。如果都找不到，程序即会出错。 example code1234567891011121314151617181920212223242526272829303132def scope_test(): def do_local(): spam = \"local spam\" def do_nonlocal(): nonlocal spam spam = \"nonlocal spam\" def do_global(): global spam spam = \"global spam\" spam = \"test spam\" do_local() print(\"After local assignment:\", spam) do_nonlocal() print(\"After nonlocal assignment:\", spam) do_global() print(\"After global assignment:\", spam)scope_test()print(\"In global scope:\", spam)# Output:# After local assignment: test spam# After nonlocal assignment: nonlocal spam# After global assignment: nonlocal spam# In global scope: global spam# 默认赋值是local的，所以不会更改scope_test()的spam；# nonlocal声明将命名空间改为了scope_test函数的级别，因此spam变量指向了正确的对象，修改成功；# global声明则将命名空间改为了module-level，因此会创造一个新的module-level的spam，而非修改原先的。 Class的命名空间类变量的命名空间是高于实例变量的，因此实例访问类变量也是可以访问的（实例内部没有，因此就会向上查找）；但实例无法对类变量进行赋值操作，一旦赋值就会生成新的实例变量覆盖掉类变量了。 其他一些杂七杂八Mac中的python Mac自带python2，且不能卸载 (一部分系统功能依赖这个python)。 因此装python3后，系统中就会带有两个版本python, python命令就不能只写python了，需要用python2和python3来区分, pip命令也是pip2 &amp; pip3(所以推荐使用annaconda来管理python版本，切换python版本后自动修改python相关环境变量)。 但可以指定python的默认解释器位置，pip也会根据python解释器而改变（具体方法待补充）。 关于面向对象 何为attritube：attribute指跟在点后面的名字，如z.real中real即是z的attribute。 类(Class)、对象(Object)和实例(Instance)区别：对象感觉是一个更为抽象的概念，如面向对象编程；类是一类方法和属性的集合，可理解为一个抽象的模版。实例是类的具体实现。接口：抽象程度更高的类，仅仅指明了应该有什么样的功能，没有规定具体实现。 Python如何在代码如何换行 Python并不使用特定的符号来标记一个语句的结束（如c++中的分号），而是通过检测回车符enter来判断，因此最好在一行内写完所有代码。 但如果遇到一行写不完的情况，有两种换行方法： 在该行代码末尾加反斜杠\\，即可在下一行接着写（但要注意\\必须是一行的最末字符，其后不能再有任何字符，包括空格）； 在括号(), {}, []内部不需要特别加\\，在项与项之间可直接enter进行换行（但不能把单个项拆开）。 注：换行后最好缩进四个空格/tab，以增强可读性。1234567891011121314test1 = \"123456\"test2 = \"123\\ 456\" # 与test相同test3 = (\"123\", \"456\")test4 = (\"123\", \"456\") # 正确，与test3相同#test4 = (\"123\", \"4# 56\") #错误，不能用enter将单个项拆开test5 = (\"123\", \"4\\ 56\") # 正确 关于编译型和解释型语言摘自Python是解释性语言吗？ 直到看到有 python py、pyc、pyo、pyd 文件 计算机是不能够识别高级语言的，所以当我们运行一个高级语言程序的时候，就需要一个“翻译机”来从事把高级语言转变成计算机能读懂的机器语言的过程。这个过程分成两类，第一种是编译，第二种是解释。 编译型语言在程序执行之前，先会通过编译器对程序执行一个编译的过程，把程序转变成机器语言。运行时就不需要翻译，而直接执行就可以了。最典型的例子就是C语言。 解释型语言就没有这个编译的过程，而是在程序运行的时候，通过解释器对程序逐行作出解释，然后直接运行这一行代码，最典型的例子是Ruby。 通过以上的例子，我们可以来总结一下解释型语言和编译型语言的优缺点，因为编译型语言在程序运行之前就已经对程序做出了“翻译”，所以在运行时就少掉了“翻译”的过程，所以效率比较高。但是我们也不能一概而论，一些解释型语言也可以通过解释器的优化来在对程序做出翻译时对整个程序做出优化（但总体上还是编译型语言效率更高）。 然而当前随着Java/Python等基于虚拟机的语言的兴起，我们往往不能把语言纯粹地分成解释型和编译型这两种。用Java来举例，Java首先是通过编译器编译成字节码文件，然后在运行时通过解释器给解释成机器文件。所以我们说Java是一种先编译后解释的语言。关于跨平台性的理解摘自解释型语言可以跨平台而编译型语言不行 对于解释型语言跨平台而编译型语言不能跨平台，网上的解释都是：编译器需依靠平台，而解释型语言依靠不同平台的解释器就可以实现跨平台。我就想如果在不同平台上装对应的编译器，不也可以实现跨平台吗？ 首先，其实说编译型语言不能跨平台是不准确的，理论上只要在不同平台装上对应的编译器，编译型语言（比如c语言）也是跨平台的。但是因为编译型语言与平台联系比较紧密、较为底层（操作系统都是用编译型语言编写的，因为编译型语言的特性——快），因此编译性语言往往会使用很多和平台相关的方法。比如，在Windows用c写了调用Windows API的程序，在Linux系统的编译器上编译自然会出错。因此如果能避免这些特殊的使用，编译型语言理论上也是跨平台的。 而对于解释型语言就很少存在这个问题，其先天就和和平台底层接触较少，所以用解释型语言写出来的程序，只要通过不同的解释器/虚拟机解释执行，就可以在对应不同的平台上使用。","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"https://renli1024.github.io/tags/Python/"}]},{"title":"Personal Recommendation Using Deep Recurrent Neural Networks in NetEase读书笔记","slug":"Paper Notes/Personal Recommendation Using Deep Recurrent Neural Networks in NetEase","date":"2018-09-13T07:49:59.000Z","updated":"2018-07-20T13:02:50.000Z","comments":true,"path":"2018/09/13/Paper Notes/Personal Recommendation Using Deep Recurrent Neural Networks in NetEase/","link":"","permalink":"https://renli1024.github.io/2018/09/13/Paper Notes/Personal Recommendation Using Deep Recurrent Neural Networks in NetEase/","excerpt":"","text":"论文地址点这里 论文内容概述本文结合RNN和FNN两种神经网络提出了一种新的个性推荐方法，希望解决传统的CF方法无法进行实时推荐的问题，最终在网易的考拉电商网站上取得了良好的效果。 简介(INTRODUCTION) 传统CF模型存在的问题因为是基于用户购物习惯的推荐，使用的是历史信息，未能利用用户当前的浏览历史，因此无法进行实时推荐。 如何进行实时推荐首先要考虑访问电商网站的用户属性，包括基本属性(浏览器、IP地址、个人基本信息、购买历史等)和动态属性(用户所浏览页面的信息)，而基于后者，我们就可以猜测用户在本次访问中究竟想要购买什么，从而完成实时推荐。 之后作者对系统主要面临的挑战、所构建DRNN的特点和其他一些技术作了介绍，即完成了本节内容。 推荐模块概述(OVERVIEW OF RECOMMENDATION MODULE) 系统流程服务器首先接收用户请求并聚合为一个会话信息，之后将其输入到推荐系统中，经过RNN和FNN计算后输出推荐结果，并在页面中显示。 数据格式数据收集：假设用户\\(u_i\\)访问网站，会生成日志文档\\(D_j^l\\)和会话文档\\(D_i^s\\)两种文档，两者关系为\\(D_i^s=\\{D_0^l,D_1^l,\\cdots,D_{k-1}^l\\}\\)，即一个会话文档对应多个日志文档。数据简化：又因为每个日志文档都可简化为一个URL地址\\(p_j\\)，因此可得\\(D_i^s=\\{p_0,p_1,\\cdots,p_{n-1}\\}\\)。最终的输入数据：访问网站的每个用户\\(u_i\\)都会对应一个\\(D_i^s\\)，即构成了神经网络的输入数据。 DRNN具体介绍(DEEP RECURRENT NEURAL NETWORK) RNN的特点RNN即循环神经网络，相比其他神经网络最大的特点是：其考虑了前后两个状态之间的关联，可以更好地处理序列信息。在本文的场景中，一个session可抽象为一系列的网页序列，因此利用RNN来进行推荐直观上是非常合适的。 基本RNN模型在单个隐藏层的RNN中，隐藏层节点除了的输入和输出外，还会有一个自连接环，可以根据时间来不断地更新它的值。更新函数：\\(a(i)=f(Ux(i)+Wa(i-1))\\)，\\(a(i)\\)表示在状态\\(i\\)下的节点值，\\(x(i)\\)表示输入值，\\(U,W\\)为相应的转移矩阵，\\(f(x)\\)为激活函数。公式理解：隐藏层节点每次更新除了会考虑输入值外，还会考虑该节点在前一状态下的值，因此RNN的结果可以反映时间序列的相应信息。 有限状态的DRNN当RNN具有多个隐藏层时，即构成了DRNN。考虑DRNN中第\\(i\\)层的某个状态\\(t\\)，其不仅会连接同层的状态\\(t+1\\)，还会连接到第\\(i+1\\)层的状态\\(t\\)，即构成了新的更新函数：$$ f(x)=\\left\\{\\begin{align}&amp;f(W_ia_i(t-1)+Z_i(a_{i-1}(t)+b_i(t)))&amp;,&amp; i&gt;1 \\\\&amp;f(W_ia_i(t-1)+Z_i(V_t+\\theta (p_t)))&amp;,&amp; i=1\\end{align}\\right.$$ 引入历史状态节点的DRNN问题背景：受限于内存，我们不可能保存用户所有产生的状态；但如果使用\\(n\\)状态的滑动窗口，则只能选择最新的\\(n\\)个数据训练模型，会降低预测精度。因此作者引入了历史状态节点(history state)的概念。当用户访问的页面数\\(x\\)超过一定数量\\(n\\)时，我们将前\\(x-n\\)个状态组合起来作为历史状态节点，有$$\\bar{V}=\\sum_{i=0}^{x-n}\\varepsilon_iV_i$$$$\\varepsilon_i=\\frac {\\theta(p_i)} {\\sum_{j=i}^{x-n}\\theta(p_j)} $$公式理解：根据用户在页面的停留时间对前\\(x-n\\)个页面作加权平均，近似表征用户的历史信息，是一个既在一定程度上保证了模型精度，计算开销又不至于太大的折中方案。 与协同过滤算法的结合问题背景：虽然协同过滤算法无法提供实时的推荐，但如果用户遵循以往购买习惯，其推荐效果还是很好的。因此作者引入了FNN模型来模拟CF算法，作为RNN的补充。另外使用FNN还有两点好处： FNN和RNN共享相同的输出层，因此可以将二者的输出融合起来作为最终结果，来表征用户购买某件商品的概率。 可以使用随机最速下降法(SGD)来训练RNN和FNN结合的权重，而不用人为地决定哪个网络更为重要，减轻了模型调参的工作量。 如何生成训练数据用户从进入网站开始到最终购买商品，会经历一定数量的页面，个性推荐的本质目标就是减少这之间页面的数量。对于一次购买行为\\(I\\)，其对应的页面路径为\\(p_0,\\cdots,p_{n-1}\\rightarrow I\\)。若对其进行优化，不一定非要优化成\\(p_0\\rightarrow I\\)这样(当然这是最优情况)，只要能减少用户的页面访问数量，都可以算作优化。因此我们的训练数据还可以是\\(p_0,p_1\\rightarrow I\\)、 \\(p_0,p_1,p_2\\rightarrow I\\)等，这样一次购买行为就可以产生\\(n\\)组训练数据，大大增加了我们的训练量。 模型的实现作者使用了Caffe框架来实现模型，整个网络包含三层隐含层，且同一层次的神经元共享相同的权重和偏置矩阵。此外，模型的RNN部分包含4个状态的输入，FNN包含1个状态的输入。 模型调优(MODEL OPTIMIZATIONS)这一节作者介绍了其为了改进模型性能所做的工作，并提出了一种自动调优框架，使得模型具有了更高的精度和更快的学习速度。 自动代码生成器问题背景：模型中包括了很多参数，调整这些参数需要更改甚至重写Caffe脚本，非常繁琐。因此作者构建了一个代码生成器，其主要任务是接收参数值，输出对应的Caffe脚本。主要思想：首先将参数分为基本参数(损失函数、学习速率等)和网络结构参数(每层的神经元数)，调整基本参数只需更改相应的值，而调整网络结构参数则需要改写Caffe脚本，因此我们只需重点关注网络结构参数即可。三种网络结构参数：文中提出了长、宽、高三种网络结构参数，分别对应隐含层数量、状态数以及隐含层与状态层的连接数，并编写了相应的代码生成算法，具体可见文中的Algorithm 1。 模型调优为了求得表现更好的模型参数，作者采用了遗传算法这种启发式算法进行模型调优。染色体结构：\\(C=(w,l,h,a_1,a_2,\\cdots,a_L,\\cdots)\\)，直观的理解就是将所有参数结合在了一起。适应度函数：\\(fit=accuracy+\\frac {1} {1+loss}\\)，\\(accuracy\\)为模型预测精度，\\(loss\\)为损失率。注：虽然遗传算法最终求得的是局部最优解，但因为参数调优本就是一个非常复杂、难以建模的过程，所以作者认为这样的解已经足够好了。 模型实验(EXPERIMENTS)这一节作者对模型进行了全面的测试和分析，并分别研究几个重要因素对模型的影响。 评价指标作者采用了预测正确率作为模型主要的评价指标，公式为\\(accuracy=\\frac {f(S)} {|S|}\\)，\\(S\\)代表训练样本总数，\\(f(S)\\)代表正确预测的样本数。 batch size的影响在使用默认参数训练模型时，增大batch size可以提高模型精度，但对于内存的消耗也更大。而一个有趣的现象是，使用调优框架后再训练模型，batch size对精度的影响就不再显著了，可见调优框架确实使得模型的表现更为优异了。 FNN的影响由Fig.11、Fig.12可得，FNN的使用显著提升了模型精度，尤其是同时使用调优框架和FNN的模型，精度提升了约10%，而且这还是在模型只推荐1个物品的情况下(即购买概率最大的那个物品)，若模型返回10个物品，模型精度可以达到50%以上。同时，使用FNN并不会影响模型的收敛速率，即模型精度的提升并不会增加计算开销，这也是很重要的一点。 历史状态节点的影响在使用默认参数训练模型时，使用历史状节点态可提高模型10%的精度；而使用了调优框架后，只能提升2%的精度，即调优过程降低了不同网络结构对模型的影响，这也侧面表明了作者所提出调优框架的优异性能。 模型最终效果在DRNN和FNN结合的情况下，模型最终的预测精度达到了33.13%，页面路径压缩到了原先的72.41%，相当于用户从点进网站到最终购买商品，少浏览了30%的页面，效果还是显而易见的，毕竟用户每多浏览一个自己不感兴趣的页面，其离开网站的概率就会越大，这也就是推荐系统的作用所在，即帮助用户更快地进行选择。 个人感悟关于推荐系统 本文提出了基于RNN和FNN的推荐系统，最主要的原因是传统的CF算法基于用户间购物历史的相似度来做推荐，考虑的更多是用户的购物习惯，这就使其无法把握用户突发的、低频的购买需求。 比如我平常很爱买衣服，网购的大部分物品都是衣服，但有一天突然想吃零食，就会在网站上浏览零食的相关页面，这时系统给我推荐的若还是衣服，就会影响用户体验，也不利于提高网站的销量，因此实时推荐是很有必要的。 但同时，在生活大部分情况中，一个人还是会遵循其所形成的习惯去购物，这时基于购物习惯的推荐便能表现出很好的效果，因此CF算法也是很有必要的。 综上，论文中使用RNN和FNN两种算法共同完成推荐，这种思路是合理的，也是符合我们的直观认知的。 关于RNN算法 RNN与其他网络最大的不同在于其隐含层节点的自连接性，在其更新函数中，不仅包括正常的输入值，还包括上一时刻中节点自身的值，这就像使得节点具有了“记忆”，这个记忆表征了时间序列中前后节点的关联，因此RNN适合处理时间序列或状态间具有一定联系的情况。 对应到本文，用户在网站上购物必然会浏览一系列页面，而这些页面是否是有关联的呢？我认为是有的。比如我要买一个钱包，在第一个页面中没有浏览到我喜欢的款式，那我下一个访问的页面也会是关于钱包的，甚至我之后的浏览可能都会围绕钱包来展开，因此我们就可从用户初始的浏览内容来推测其实时的购买兴趣，这也就是作者应用RNN进行实时推荐的原因。 关于历史状态节点(history state) 本文的一个创新在于引入了历史状态节点，来解决状态数过多、计算开销过大的问题。根据用户在页面上停留的时间，将多出的历史状态作加权平均，构成一个新的节点，这样既可以保留历史信息，又不会造成计算开销的大量增加，是一种比较折衷的方案。 这也提示我们，在数据量过大的情况下，与其直接将一部分数据丢弃掉，不如将这部分数据做整合，采用加权平均或其他的提取信息的方法，构成新的节点来参与运算，在模型精度和计算开销之间取得平衡。 关于训练数据的生成 本文针对用户一次的购买行为，将各种可能的路径优化方案都作为了训练数据送入模型进行训练，这样可以增加我们的训练量。因为对于有监督学习来说，带标签的数据是有限的，如何充分利用有限的标签数据去训练模型需要我们去研究，本文给了我们一种可行的思路。 关于模型调优 本文提出了一种模型调优框架，大致可分为“生成参数”和“生成代码”两部分。 首先将模型的相关参数整合成染色体，再利用遗传算法的杂交、变异等操作，生成下一代染色体，之后将参数传入代码生成器中生成对应的Caffe脚本，训练模型后，将结果回带到遗传算法的适应度函数中进行评估和自然选择，一轮轮地迭代，最终即可得出最优的参数组合。 因为建模的复杂性和组合爆炸等问题，模型调优一直是机器学习的一个难点，在这种情况下，利用一些启发式算法进行智能调优不失为一个好的方法，这也是文章给我们的一个启示。 改进方案关于模型的更新问题 在文章中提到，顾客每完成一次购物，就相当于得到了一个”ground truth”，可以用来训练、调整模型，这样模型随着网站的运行就会不断优化和改进。 如果顾客这次购物是在遵循自己以往的购物习惯，那么将结果用来继续训练模型是没有问题的，因为这个行为在今后还会多次发生，这样可以使得模型更了解顾客的购买习惯，从而更好地完成推荐。 但如果这是一次”unexpected”的购物行为，就像平常都喜欢买衣服的我只是突然想吃点零食，如果模型把这个突发的低频需求当作了用户的购买习惯，在今后也多次向用户进行推荐，可能会造成用户的厌烦。 因此我认为在模型的持续更新中，应该考虑到用户购买行为的属性，即对利用了RNN方式完成的推荐，要降低其对模型的后续影响。 方案实现：可以通过减少训练样本数量的方式，对于通过RNN推荐完成的购买，不要将$$ p_0 \\rightarrow I \\\\ p_0,p_1 \\rightarrow I \\\\ \\cdots \\\\ p_0,\\cdots,p_{n-1} \\rightarrow I$$所有的路径样本都送入训练，可以只送入后半段或后1/4的样本，让推荐发生的条件更为“苛刻”一些，从而使得模型不会在用户一进入网站就推荐一些低频、不经常需求的产品。 将社群属性加入到模型中 论文在”Related Work”中提到CF推荐和基于内容的推荐相结合，会在社交网络上表现得更好，因此我认为可以将这种思路应用到本文，即在推荐系统中加入一定的社群属性。 问题背景：在实际生活中，我们会更倾向于接受来自朋友的推荐，而非来自商家的推荐。尤其是本文的电商网站——网易考拉，是一个主打海淘的平台，用户对一些国外的品牌可能了解并不多，这时如果有来自自己社交圈的推荐，无疑会增加购买的概率。 方案实现：可以考虑改进文中的FNN部分的方法，即首先通过用户填写的基本信息或其他网易系应用中的用户资料(如网易音乐、游戏等)，对用户进行社群判别和分类，为每个用户构建一个“熟人圈”。在进行FNN推荐时，模型不仅推荐历史相似的用户购买的产品，也推荐来自熟人圈购买的产品，以将社群属性加入到推荐模型中。 关于推荐理由 问题背景：目前用户对于推荐系统的态度，不仅是想“知其然”，也想“知其所以然”，即除了推荐的物品本身，用户也会想知道系统为什么会给自己推荐这个物品，因此如果能给推荐物品附上推荐理由，无疑会提升网站的用户体验。 方案实现：因为本文是将两种神经网络的输出层共享，以类似加权平均的方式进行融合(见文章第三节D部分)，来计算出用户购买某件物品的概率的，因此可以将最终结果的各个部分分离出来，从大到小排序，通过分析值最大的一项或几项来构造我们的推荐理由。 具体形式：推荐理由的形式可以为“根据你以前购买过的xxx牛仔裤，我们猜你还喜欢这个”、“根据你刚刚浏览过的xxx钱包，我们猜你会喜欢这个”等等，以一种猜测、活泼的口吻对用户进行提示，以增加用户的购买欲望。","categories":[],"tags":[{"name":"Paper Notes","slug":"Paper-Notes","permalink":"https://renli1024.github.io/tags/Paper-Notes/"}]},{"title":"On Availability For Blockchain based Systems读书笔记","slug":"Paper Notes/On Availability For Blockchain based Systems","date":"2018-09-13T07:49:59.000Z","updated":"2018-09-28T20:11:10.068Z","comments":true,"path":"2018/09/13/Paper Notes/On Availability For Blockchain based Systems/","link":"","permalink":"https://renli1024.github.io/2018/09/13/Paper Notes/On Availability For Blockchain based Systems/","excerpt":"","text":"论文地址点这里 论文内容概述这是一篇偏重实验的论文，通过研究影响交易提交时间的因素，探讨了目前区块链的可靠性问题，并提出了一种交易终止策略来解决这个问题。 简介(INTRODUCTION) 区块链的可靠性问题可靠性保证不透明：从应用的角度上来说，并不清楚区块链技术是如何保证系统的可靠性的，而且多数区块链系统只能以一定概率保证交易信息的不变性。提交时间不稳定：客户端不可预知交易成功提交所需的时间。从Fig.1中可看出，61.5%的交易在3分钟内就提交了，但13.8%的交易4.5分钟还没提交(延迟了50%)，提交时间的差异可能系统可用性的下降。 论文主要研究内容 导致交易无法成功提交的因素 以太坊中的transaction inclusion机制 以太坊中gas price和gas limit两个参数对提交时间的影响 以太坊中block gas limit的影响 交易终止机制 背景知识(BACKGROUND) 区块链基本知识区块链可认为是一个分布式的公共账本，记载了交易信息和资产信息。区块链中的每个用户本地都存储着一个账本的副本，并运行着一个客户端，负责和整个网络同步更新账本信息。 区块链中的链指什么区块链系统的交易信息存储在区块(block)中，从第二个区块开始，每个区块都有前一区块的哈希值，即相当于把各个区块链起来了，最终各个区块按时间顺序链接起来呈现一套完整的数据(区块链大账本)。 区块链加密技术区块链采用了非对称加密技术，和传统对称加密最大不同是，加密和解密不再是同一把钥匙，而是分为公钥和私钥。只有特定的用户具有私钥，可以对交易信息进行加密和数字签名；而所有的用户都具备公钥，可以对交易信息解密，并通过数字签名验证交易签署者的身份。 共识算法问题背景：因为区块链是分布式存储的，所有节点都需要对区块链中块的内容和次序达成“共识”，为了解决这个问题就提出了共识算法。工作量证明算法(POW)：这是目前最广泛使用的共识算法，其基本原理是：一个节点将交易信息打包到区块中，并添加一个随机数，再做哈希和运算，之后将块发布到网络中。其他节点接收到块后，根据块中包含的参数进行大量的计算(俗称挖矿)，计算出的结果如果小于哈希和，即完成了这部分工作，得出的结果值就相当于对其工作量的“证明”。拥有“证明”后节点不仅会获得一定奖励，也拥有了创建区块的权利，新创建的区块会加到主链末端，其他节点可在其后面继续添加新区块，其后每添加一个区块，就相当于做了一次确认，当其后的区块达到了一定数量后(比特币是6个，以太坊是12个)，就相当于和网络中其他节点达成“共识”了，这个区块即正式被记录在案了。核心思想：工作量证明机制的核心思想是工作方要得出结果具有一定难度，但验证方检查结果却非常容易，因此很容易验证工作方是不是做了相应工作。既保证了工作完成后奖励的价值(需要付出大量的计算代价)，激励节点去积极打包交易信息，同时验证的简单性也保证了共识算法的效率和可靠。 分叉问题(fork)基本概念：考虑一种小概率情况，两个节点恰好同时完成了计算，创建了区块，并向全网进行了广播，这种情况就叫做分叉。形象的理解就是区块链主链的末端被连了两个块，像是分叉了一样。分叉的影响：正常情况下，网络中所有的节点达成共识，所生成的区块链就是一条主链，内容、次序都是确定的；而在分叉的情况下，区块链会向两个不同的方向延申(因为每一个区块都是依赖于上一个区块产生的)，主链的内容、次序就不确定了，各节点即无法正常地查询交易和资产信息。解决办法：所有节点都从当前最长的链开始工作。因为有统计结论，链中的区块数越多，越不容易发生分叉现象。 比特币交易的提交(COMMIT OF BITCOIN TRANSACTIONS)在本节中，作者讨论了影响比特币提交时间的因素，并进行了实验验证。 影响交易提交时间的因素交易手续费(transaction fee)：手续费的多少会影响节点打包交易信息的积极性，从而影响交易提交的时间。交易是否按顺序到达：如果一个交易比其所引用的父交易先到达，则被称为orphan。只有父交易提交后，子交易才能提交，否则子交易就会一直在mempool中等待。锁定时间(locktimes)：这是一个用户可设置的参数，可使得某个交易在特定顺序的区块产生之前一直处于不可用状态。 实验过程实验任务：观测交易的产生并记录其提交所花费的时间。为了探究不同网络环境下的情况，作者在2016年11月和2017年4月分别进行了两次实验（第二次实验的网络负载较大）。观测窗口：为了充分收集包含在区块链中的交易信息，作者定义了观测窗口：从实验开始前的第一个区块到实验结束24h后的一个区块，这之间的交易即处于观测窗口中，都会被记录下来。 实验结果作者主要研究的交易有两类：Straight-accepts和Oranphans。实验结果1（针对到达顺序因素）：由Fig.2可知两次实验中，Oranphans的提交时间都比Straight-accepts的时间要长，且在第二次实验中尤为明显，可见到达的顺序对提交时间有着显著的影响，按顺序到达的交易比无序到达的交易时间要短很多。实验结果2（针对交易手续费因素）：由Fig.3可知，交易手续费和提交时间之间并没有显著关联。实验结果3（针对locktimes因素）：通过作者分析可知，绝大多数交易并未使用locktimes这个参数，且Oranphans和Straight-accepts这两类交易结束锁定的时间差异也很大，最终作者认为locktimes并非是Oranphans延迟的主要因素。 以太坊交易的提交(COMMIT OF ETHEREUM TRANSACTIONS)在本节中，作者介绍了以太坊不能保证提交的原理，并实验研究了gas price、gas limit、network三个因素对提交时间的影响。 以太坊中交易事务的生命周期1、交易声明：交易发生并声明。2、交易打包进区块：发布节点将交易信息打包到区块中。3、区块链接到主链：节点完成打包计算，将区块链接到主链。4、交易正式提交：其后链接了一定数量的区块后，即正式提交。注：因为分叉现象或其他原因，步骤2并不能保证交易最终一定被提交，这就产生系统的可靠性问题。 实验过程实验任务：研究交易从打包到最终提交所花费的时间以及分支合并后会丢失多少已打包的交易。创建监听节点：作者改写了一个客户端节点作为监听节点，以检测交易声明和区块声明。记录时间：监听节点会记录交易声明的时间和区块到达的时间，以计算交易提交的延迟时间。计算方法：根据交易声明的时间和包含此交易的第一个区块到达的时间，我们计算这之间的时间差，结果就是Fig.5中的1st inclusion；当第一个块变为叔块时，我们可根据包含此交易的第二个区块到达的时间，计算出2nd inclusion；同理，3rd inclusion也是这么计算的；此外，我们根据最后一个区块的到达时间，可以计算出12 confirmations和36 confirmations。将上述计算出的结果绘成图表，就是文中的Fig.5。 实验结果实验结果1（各类提交时间的对比）：从Fig.5中可知，相比1st/2nd/3rd inclusion，12/36 conclusion的提交时间更长，而36 conclusion尤为明显，这说明交易数量越多，交易提交所花费的时间越长。实验结果2（针对gas price因素）：从Fig.6中可知，总体趋势是gas price越高，延时越短，但gas price高于25Gwei后对延时的影响就非常小了。这也侧面解释为什么大部分交易定价在[20,25)的区间内(性价比最高)。实验结果3（针对maximum gas因素）：虽然有个别交易因maximum gas过高而有明显的延时，但作者依旧认为maximum gas和提交时间之间没有很强的关联性。实验结果4（针对network delays因素）：虽然没有得出明确的结论，但作者分析了in-order和out-of-order交易在提交延迟和数量方面的数据后，认为网络延迟对交易的传播是有负面影响的。 BLOCK GAS LIMIT对以太坊的影响(IMPACT OF THE BLOCK GAS LIMIT IN ETHEREUM) 产生原因出台gas limit per block的原因是希望通过限制每个区块消耗的gas总量，防止DDoS攻击。如果交易所需的气体超过了限制值，交易就无法被包含到块中，这就使得大规模的分布式拒绝服务攻击难以发生。 问题背景在没有限制之前，签署合约花费了150万的气体，因此作者认为限制会对合约相关的交易产生负面影响，但对单纯的资金转移交易应该影响不大，之后作者即针对这个观点进行了分析。 分析结果由Fig.10可知，在50万气体的限制下，有46.21%的合约类交易无法正常进行；在200万气体的限制下，也有18.78%的合约类交易无法产生。因为气体限额的存在，大量的合约类交易无法进行，这也验证了作者之前的观点。 以太坊的交易终止机制(TRANSACTION ABORT IN ETHEREUM)这一节主要对应了作者在摘要中提到的观点：终止机制的缺失会使大量交易处于既未终止也未提交的”pending”状态，严重影响系统的可靠性。为解决这个问题，作者提出了一种交易终止的机制，并进行了实验考察。 终止原理竞争法：如果先前的交易\\(Tx_i\\)在规定的时间内未提交，账户可以重新发布一个具有相同nonce序号的交易\\(Tx_i^{\\prime}\\)，赋予其更高的手续费，并将交易的接收方设为自己。一旦\\(Tx_i^{\\prime}\\)成功提交，\\(Tx_i\\)就会自动过期了，即终止了其状态。重传法：账户重新发布一个与\\(Tx_i\\)内容相同的交易\\(Tx_i^{\\prime\\prime}\\)，但设置较高的手续费，这样虽然\\(Tx_i^{\\prime\\prime}\\)交易信息和\\(Tx_i\\)是一样的，但数字签名和哈希值却不一样(因为手续费不一样)，这样其他节点会把其当作一个新的交易。只要交易\\(Tx_i\\)和\\(Tx_i^{\\prime\\prime}\\)任何一个成功提交了，另外一个即过期了(因为nonce是一样的)，这样也可以达到终止的目的。 实验模拟的三种情况1、交易在规定时间内没有被打包2、因为手续费不足，用户决定撤回之前发布的交易3、因为账户余额不足，交易无法被正常提交，即进入”pending”状态 对情况1的实验实验原理：为了降低交易被打包的概率，作者减少了交易的手续费，分别为市场均价的0%、10%、…、90%，并设置了10min的截止时间。如果截止时间内原交易未提交，就按照上文提到的竞争法进行终止。实验结果1：大部分交易都成功提交了，甚至30%-90%市场价的交易全部成功提交。出现这样的情况，我猜测可能是因为设置的终止时间太长了，即虽然手续费低，但只要时间足够长，交易还是有可能成功提交的。实验结果2：在0-20%市场价的交易中，有16个没有成功提交，但最后都成功终止了，终止成功率为100%。 对情况2的实验实验原理：这种情况考虑的是客户端希望撤回原先的交易，因此相比情况1，设置的截止时间要短一些（因为如果再设置很长时间的话，就失去模拟用户自行撤回的意义了），实验中是取所有交易提交时间的中位点，即3min。实验结果1：截止时间缩短后，未提交的交易数明显增多，总共有53个交易没有提交，甚至0-20%市场价的交易全部没有提交成功，这也验证了我在实验1中的猜想。实验结果2：虽然未提交的交易数量大大增加，但依旧每个交易都成功终止了，成功率为100%。 对情况3的实验实验原理：首先作者创建了两个交易：\\(Tx_1(bonce=n+1,value=\\frac {k} {1000})\\)和\\(Tx_1(bonce=n+1,value=\\frac {999k} {1000})\\)，k为当前账户的余额。其次为了模拟余额不足这种情况，作者采用了一种很巧妙的方式：先发送\\(Tx_2\\)，隔5s后再发送\\(Tx_1\\)，这样可以使得\\(Tx_2\\)顺利发出，因为先发\\(Tx_1\\)的话，一旦其被顺利打包，\\(Tx_2\\)就会因为余额不够而无法发送到网络中了。采用这种方式，\\(Tx_2\\)就有可能比\\(Tx_1\\)先发到网络中，又因为\\(Tx_1 nonce&lt;Tx_2 nonce\\)，所以\\(Tx_1\\)必然会比\\(Tx_2\\)先打包，这样\\(Tx_2\\)就会因余额不够而停滞在网络中，即成功模拟了因余额不足所导致的”pending”状态。实验结果：作者进行了100次实验，终止成功率依然是100%，结合前两次实验的结果，说明终止机制的效果还是非常好的。 个人感悟对于区块链的理解 区块链的本质是一个去中心化的分布式账本。我认为区块链就是一个账本，记载了所有交易信息和资产信息，但和传统金融记录方式的不同在于，区块链账本并非存储在某一个中心，其在每一个用户的本地都有存储的副本，相当于每个用户都是一个中心。 去中心化带来的好处：首先是不用考虑中心的故障问题，就像双11，你再想买一个东西，淘宝服务器一旦瘫痪就不行了，所有的交易都依赖于这个第三方的中心；其次是不用担心信息泄露的问题，还是淘宝的例子，你要买东西、卖家要卖东西，都要提供个人信息，交易完成后也会产生交易信息，这些都被存在淘宝的服务器中，在当今这个强调个人隐私的时代，这是非常让人困扰的；第三是安全，区块链技术具有不可篡改性，我们不用担心因第三方中心的原因导致我们的资产受损失(如银行破产)。 去中心化带来的问题：最大的问题是我们如何在各个节点间同步数据。在中心化系统中，中心说什么就是什么，其他人只需和中心保持同步即可；而在去中心化系统中，我们需要和全网进行同步，难度增大了很多，为了解决这个问题，也就出现了共识机制，大家共同记账，一定数量的节点达成共识后，就可正式在网络中进行同步了；而为了提高大家记账的积极性，就出现了工作量证明算法，对于成功记账的人会有奖励，大家都去积极记账了，账本自然就可以不断地维护、更新了。 对于区块链可靠性的理解 本文对于区块链可靠性的研究主要围绕“交易提交时间”这个概念，一个交易产生了，最好的情况是在规定时间内顺利打包，加入到区块链主链中。但因为复杂的网络环境、交易手续费或其他种种因素，一个交易的提交很可能会产生延迟，甚至会出现交易既没有提交、又没有销毁的”pending”状态。 这就需要我们去探讨两个方面的问题：到底有哪些因素会影响交易的提交时间？交易如果没有顺利提交我们应该采取什么办法？前者就是文章第三、第四节主要研究的内容，通过具体的实验分析了各种可能影响因素；后者则是作者在第六节研究的内容，提出了一种交易终止机制并进行了实验测试。 对于交易终止机制的理解 文中提到了两种交易终止的方法：竞争法和重传法，虽然有些区别，但本质思想都是一样的，都是利用了“nonce相等”的原理来终止原来的交易。 文中还提到，虽然以太坊不像比特币那样把每一个块都链接起来，但其每个块都有唯一的顺序号nonce，而且主链上的区块必须是按顺序的，因此我们就可以利用nonce号来使某次交易过期，从而达到终止的目的。 其他一些感想 论文中还有一点使我印象很深刻，就是整篇文章都贯穿着实验的思想，作者进行了大量的实验去研究某些因素的影响，对所提出的终止机制也进行了具体的实验探究，实验过后还有对实验结果的合理分析，这些都使得整篇文章的逻辑结构很清晰，值得我在今后的科研工作中去学习。 改进方案对比特币实验中无序现象产生的原因进行研究 在第三节中，作者研究了到达顺序对交易提交时间的影响，最终得出了结论：顺序到达的交易比无序到达的交易的延时要短。 作者虽然分析出了现象，但对产生这种现象的原因并没有深入研究，我认为如果对无序现象产生的原因进行研究，也会有助于改善区块链系统的可靠性问题。 方案实现：可参考文中第三节引言部分提到的几种情况，我认为可以主要研究节点转发策略和节点负载这两个因素，转发策略的不同可能会打乱原先的交易分发顺序，从而使得交易无法按顺序到达其他节点；而节点负载主要会影响交易传播的速度，不同节点的传播速度如果不同，也可能会导致交易失序。有了初步的分析，我们可设计实验来具体研究：首先选择一定量的矿工节点，将其按照不同的转发策略和不同的节点负载进行分组，转发策略可通过观察客户端版本、研究底层转发行为的实现代码等方式得出，而节点负载可通过观测相应网络指标得到。之后可以对两种因素进行控制变量分析，从而研究其对交易到达顺序的影响。 对比特币实验2中部分Orphans数据未统计的情况进行改进 在比特币的实验2中，因为高网络负载的原因，有20%的Orphans交易最后未被打包到块中，观测样本因此少了20%，作者也认为这对实验结果是一个很大的限制，因此我认为可根据这一点做下改进。 方案实现：我考虑了两种思路，思路一：选择网络负载比实验2小但比实验1大的一个时间点，按照同样的方式做实验3，这样既可观测到不同网络环境下的实验结果，也可以减小网络负载对Orphans交易的影响，不至于使实验观测到的样本减少太多；思路二：保持实验1和实验2的网络条件不变，增加观测窗口的时长，分别进行实验3和实验4。由Fig.2可知计算的是累积比例，因此增加观测窗口相当于延长了一段X轴，Orphans Exp 2这条线最终就有机会到达1，而对其他三条曲线则不会有影响(它们已经很接近1了)，因此就可收集到更多的Orphans数据。","categories":[],"tags":[{"name":"Paper Notes","slug":"Paper-Notes","permalink":"https://renli1024.github.io/tags/Paper-Notes/"}]},{"title":"Notes of Efficient Estimation of Word Representations in Vector Space读书笔记","slug":"Paper Notes/Efficient Estimation of Word Representations in Vector Space","date":"2018-09-13T07:49:59.000Z","updated":"2019-03-23T12:53:11.608Z","comments":true,"path":"2018/09/13/Paper Notes/Efficient Estimation of Word Representations in Vector Space/","link":"","permalink":"https://renli1024.github.io/2018/09/13/Paper Notes/Efficient Estimation of Word Representations in Vector Space/","excerpt":"","text":"论文地址点这里 论文内容概述这是谷歌发布的关于词向量的经典论文，针对传统模型无法表征单词间关联性的问题，本文提出了两种连续的词向量模型，并针对模型实现了分布式学习模块，最后基于词向量的线性运算设计了一种评价模型精度的方法，取得了良好的效果。 简介(INTRODUCTION) 传统NLP技术的特点传统NLP技术主要是基于单词间没有相似性的思想，将词汇以单词表索引的形式来表示。这样做虽然有很多好处，如简单、健壮、使用大量数据训练的简单模型的效果好于使用少量数据训练的复杂模型等；但同样也有很多限制，如语料数据库没有足够的数据、无法表征单词间的关联等。因此作者认为原先的技术很难再取得突破，需要去发掘新的技术。 论文主要工作1、从大量单词和短语数据中学习出高质量的词向量，并且要保持一个合适的向量维度。2、使用了一种评估词向量精度的技术，期望不仅相似的单词可以趋向接近，同时单词间能具有更多维的相似度。3、使用单词偏移技术对词向量做简单的代数运算，以更好地挖掘词向量间的相似性规则。4、设计了一个综合测试集来探究句法和语义的规律性，并研究了词向量维度和训练数据量这两个因素对训练时间和模型精度的影响。 模型框架(Model Architectures)在本节中，作者使用了NNLM和RNNLM两种神经网络来学习连续的单词表示方法，并且对不同神经网络的训练复杂度进行了分析。 训练复杂度公式作者首先提出了分析训练复杂度的公式：\\(O=E\\times T\\times Q\\)，其中E为训练的趟数，T为训练集中单词的数量，Q为表征模型复杂度的变量，下文还会对Q具体分析。 前馈神经网络语言模型(NNLM)基本结构：整个网络分为输入层、映射层、隐含层和输出层，输入层将前N个单词编码为1-of-V的向量，V为词表大小，这N个单词共享相同的映射矩阵，阵映射到映射层，之后再从映射层转换到隐含层，经过一系列计算后输出最终结果。模型复杂度：\\(Q=N\\times D+N\\times D\\times H+H\\times V\\)，因为N是一个较小的量，因此\\(N\\times D\\)也比较小；另外对单词表用二叉树做优化，可使得\\(V\\)下降到\\(log_2(V)\\)，这样\\(H\\times V\\)也会减小，最终模型的复杂度主要就集中在\\(N\\times D\\times H\\)，即映射层-&gt;隐含层这部分。注：对于单词表的表示，还可以继续用哈夫曼树做优化，减少高频单词的编码长度，从而进一步降低输出层的计算量。 循环神经网络语言模型(RNNLM)模型特点：RNN最大的特点是其自连接性，即状态的更新不仅取决于输入，还取决于上一时刻自己本身的状态，这个特性就使得RNN具有了一种“短时”的记忆，可以更好地表示前后文本之间的关联。模型复杂度：RNNLM中没有映射层，因此模型复杂度简化为\\(Q=H\\times H+H\\times V\\)。和上文同理，\\(V\\)可以优化为\\(log_2(V)\\)，因此模型的复杂度主要集中在\\(H\\times H\\)。 神经网络的平行训练模型为了提升在大规模数据集上训练模型的效率，作者在DistBelief框架的基础上实现了一个分布式计算模型，允许多个副本并行地学习训练，而且所有副本会同步进行梯度更新，作者在下文会分析模型的具体效果。 新的对数线性模型(New Log-linear Models)在本节中，作者提出了两个连续词向量模型，希望能使用一种更简单的模型来训练更大量的数据，以通过增加训练量来提升训练效果。 连续词袋模型(Continuous Bag-of-Words Model)基本结构：模型与前馈NNLM比较相似，但是去掉了非线性隐含层，并且所有单词直接共享整个映射层，而非只是映射矩阵。通过这种方法，所有的单词被映射到同一位置，对这些向量进行平均后即为最终的映射结果。模型特点：1、所有的单词最终都被映射到同一位置，因此单词的顺序就不再起作用了；2、为了对单词进行分类，模型会同时使用上下文的一部分单词进行计算；3、模型的作用是根据上下文来推测中间可能出现的单词；4、与传统词袋模型的不同在于其对于上下文的表示是连续。模型复杂度：\\(Q=N\\times D+D\\times log_2(V)\\) 连续Skip-gram模型(Continuous Skip-gram Model)模型特点：1、模型的结构类似上述CBOW模型，可以说是“镜像对称”的；2、Skip-gram模型的作用也和CBOW模型相反，其是根据中间的单词，来推测单词的上下文信息；3、考虑到大部分距离较远的单词之间的关联性都较小，因此作者减少了远距离单词的训练样本数量，以降低其权重。模型复杂度：\\(Q=C\\times (D+D\\times log_2(V))\\)，C指单词最大化距离，使用模型时会随机选取\\([1,C]\\)中的一个值作为取词窗口的长度。 结果分析(Results) 核心思想考虑明显具有相同相似关系的两对单词，如”biggest”、”big”和”smallest”、”small”，计算\\(X=D(biggest)-D(big)+D(small)\\)，若词向量模型训练成功，应有\\(X\\)与\\(D(smallest)\\)是向量空间中距离最近的点。 实验设计作者从句法和语义的角度列出若干相似的类别，分别在每个类别中加入若干单词对，将这些单词对随机两两组合，基于上述公式，计算是否是距离最近的点，若是，即为一次正确的实验结果，最终统计总体正确率来评价模型的优劣。 提升模型精度作者研究了训练数据量和词向量维度两个因素对CBOW模型精度的影响，发现如果只单纯提升某一个因素，对模型精度的影响都是有限的，因此需要同时提升两个因素才能取得比较好的效果。 各模型的对比对比1：在相同训练量和向量维度的条件下，作者对比了RNNLM、NNLM、CBOW和Skip-gram四种模型的精确度，由Table 3可知，CBOW和Skip-gram两种模型的表现明显好于RNNLM、NNLM模型。对比2：作者研究了增大训练量和增大向量维度对CBOW和Skip-gram两种模型的影响，发现只将训练量增大两倍和只将向量维度增大两倍，取得的效果是差不多的，增加的训练时间也比较接近；同时可以发现，两倍数据训练一趟比单倍数据训练三趟的效果要好。对比3：作者将文中的模型与已公布的其他向量模型做了对比，综合表现最好的依旧是Skip-gram。对比4：作者使用了之前提到的分布式计算框架，将向量维度提升到了1000，使用谷歌新闻数据集进行训练，在这种情况下Skip-gram模型的精度依旧是最高的，而且达到了65.6%。对比5：介绍了微软的一个挑战赛，给定挖去一个词的句子和五个候选词，求哪个词和句子最匹配。作者将句子填词问题反向转化为了由词去预测句子的问题，预测出原句的概率最大的那个词，就是所求的词。作者利用Skip-gram+RNNLMs的组合模型，取得了所有模型中最好的效果。 个人感悟关于连续词向量模型 本文的工作主要围绕着连续词向量模型，因为传统的词向量表示是将单词视作一个个离散的符号，这样做的缺点是无法提供足够的信息来体现词语之间的关联，比如虽然Italy和Rome两个单词看起来一点也不像，但其实两者之间是有联系的(Rome是Italy的首都)，而如何研究出这种潜在的联系，便是本文的主要讨论内容。 作者的思路是通过词向量来表征这种潜在的联系，首先使用了两种神经网络来生成词向量，但因为隐含层的计算开销过大，使得模型无法训练大量数据集，也无法提升词向量的维度；因此作者从简化模型的角度，提出CBOW和Skip-gram两种模型，并且使用了分布式训练框架，这使得模型能够针对大量数据集进行训练，从而获得更好的训练效果。 训练出向量模型后，作者为了检测向量模型的效果，基于“相似度高的向量距离近”的思想，提出了一种检测算法，对向量进行代数运算并计算之间的距离，如果相似度高的向量计算出的距离确实小，就说明模型是合理的，作者即通过这个思路分析了各个模型的优劣。 关于词向量的线性运算 文中所用的检测词向量精度的方法是基于词向量的线性运算，即“意大利-罗马+巴黎=法国”这样的计算规则，通过这个算式，我们可以很明显地感受到词之间所具有的某种关联，利用这种关联就可以大大扩展词向量的应用范围。 但具体为什么会有这种性质呢？我认为可能的原因：词向量的假设是基于上下文的分布来推导词义，而“意大利-罗马+巴黎=法国”可以转换为“意大利+巴黎=法国+罗马”，而只有意大利和巴黎共同的上下文与法国和罗马共同的上下文是相似的，才会有这样的相等关系。而仔细考虑一下，这两对词的上下文确实是有可能比较像的，比如一篇介绍欧洲国家的文章，这些词所在的语境肯定是很相近的，这也就是我们把这些词作为相似词的原因。 关于训练数据量 本文还有一个比较重要的思想是：简化模型，提升学习效率，利用更大的训练量来求得更好的训练效果。作者一开始就是因为神经网络模型的计算量太大，因此舍弃了隐含层，简化模型，从而提出了CBOW和Skip-gram这两个模型。 这样做虽然可能会损失一部分隐含层所提升的精度，但计算开销大大降低了，结合分布式学习模型，可以极大地提升训练量和向量维度的上限，从而弥补因简化模型而损失的精度。实验结果证明了这样的方案是可行的，这也为我们今后如何改善模型精度提供了一个思路。 改进方案关于CBOW模型的语义问题 在CBOW模型中，所有的单词最终都会映射到同一位置，模型是不考虑单词顺序的。我认为这样做主要是因为CBOW模型的作用是从上下文中推测相关的单词，即模型关注的是文章中是否出现单词，并不关注单词出现的顺序，因此舍弃顺序也是合理的。 但这样做也会有一定问题，即一些语句虽然单词组成一样，但语义却有明显不同。如“李丽是谁的姐姐”和“李丽的姐姐是谁”，这两句话的词袋模型是完全一致的，但如果不考虑语法结构，我们很难得出正确的结果。因此在这种情况下，我们可以将词袋模型和句法分析相结合，来求出句子的真正含义。 CBOW模型和Skip-gram模型与神经网络相结合 文章最后提到神经网络词向量和其他技术的结合可能会有很好的效果，作者在微软的挑战赛中也通过Skip-gram+RNNLMs取得了很高的预测精度，说明这个结合思路是可行的。 因为首先CBOW和Skip-gram都未考虑单词的顺序，会带来一定的语义问题；同时RNN模型本身具有自连接性质，这可以使其对前后的单词的关联性有更好的“记忆”，因此两者结合可能会有互补的效果。关于实现，可以将两者的词向量模型以一定权重进行组合，得出新的词向量，以探究其在相关问题中的表现效果。","categories":[],"tags":[{"name":"Paper Notes","slug":"Paper-Notes","permalink":"https://renli1024.github.io/tags/Paper-Notes/"}]},{"title":"微机接口技术与应用","slug":"微机接口技术与应用","date":"2018-09-13T07:49:58.000Z","updated":"2018-06-24T03:40:34.000Z","comments":true,"path":"2018/09/13/微机接口技术与应用/","link":"","permalink":"https://renli1024.github.io/2018/09/13/微机接口技术与应用/","excerpt":"","text":"在微机系统中，微处理器的强大功能必须通过外部设备才能实现，而外设与微处理器之间的信息交换及通信又是靠接口实现的，所以，微机应用系统的研究和微机系统的产品的开发，从硬件角度来讲，就是接口技术的演进和开发。微机的应用随着外设的不断更新早已深入各个领域。 第一章 概述预备知识 CPU架构分类目前市面上的CPU分类主要分有两大阵营，一个是intel、AMD为首的复杂指令集CPU，另一个是以IBM、ARM为首的精简指令集CPU。Intel、AMD的CPU是X86、x64架构的，而IBM公司的CPU是PowerPC架构，ARM公司是ARM架构而对于Intelx86架构的CPU，最具代表性的就是1978年所推出的Intel 8086和之后推出的Intel 8088，被称为x86架构的鼻祖。8086：16位处理器芯片，内部总线和外部总线都为16位，本笔记中的接口都是基于8086架构的。8088：准16位处理器芯片，内部总线16位，外部总线8位 总线位数内部总线：CPU位数，CPU一次处理的数据总线宽度，通用寄存器长度，ALU运算字长。外部总线：系统总线位数，与内存交换数据的宽度，即数据总线。注：内、外都是相对CPU而言的。三总线：数据总线、地址总线、控制总线。8086中，数据总线16位，地址总线20位，寻址空间2^{20}=1MB。 主板芯片组CPU与周边设备沟通的桥梁，分为南桥和北桥。南桥：PCI桥，CPU与外设的I/O。北桥：HOST桥，离CPU更近，速率更快，用于CPU和内存、显卡、PCI桥交换数据。 接口概念接口指CPU与外设间信息交换的输入输出电路，CPU接口外设。接口实现了外设与微机间的信息交换。 三类接口芯片通用接口芯片：并行接口、串行接口等。面向微机专用接口芯片：不直接与外设连接，只是帮CPU分担工作，DMA控制器、中断控制器等。面向外设专用接口芯片：显示器接口、键盘接口等。 设立接口原因CPU与外设两者的工作速度不兼容CPU与外设两者的信号不兼容有利于外设的标准化 接口电路一般结构DB, AB, CB即数据总线、地址总线、控制总线。接口内主要有三类寄存器：命令口（CPU向其中写命令，只写）、状态口（CPU从其中读取接口的状态信息，只读）、数据口（CPU与外设间的交换信息，可读可写）。 CPU与接口交换数据方式程序控制方式：CPU主动。无条件传送方式（同步传送），外设一直是准备好的，传送前CPU不需要了解外设的状态，适合一些较简单的外设，如LED显示器；查询传送方式（条件传送），传数据前CPU先检测外设状态（状态字），外设没准备好，CPU就一直等待。中断方式：外设主动，CPU被动。外设做好准备时，主动向CPU发出中断请求，CPU响应中断。DMA方式：DMA控制外设与存储器间的数据传送，传送过程由特定硬件完成，无需CPU介入。 第二章 I/O端口地址译码技术端口地址I/O端口(Port)：指I/O接口电路中能被CPU直接访问的寄存器，CPU与外设间不能直接交换信息，必须通过端口。 端口编址方式采用小端模式，低字节在低地址，高字节在高地址。统一编址：端口地址和存储器地址是统一的，可直接用内存指令访问端口，无需专门的I/O指令。因此指令会比较长，且寻址速度慢。独立编址：端口地址和存储器地址独立，根据不同指令访问不同的地址（通过专门的I/O指令访问端口），8086中就是这种方式。 8086中端口地址分配地址空间：000-3FFH，A0-A9共10根地址线，可访问1024个端口。3FFH=15+15*16+3*16*16=1023。系统板上的I/O接口芯片：地址000-0FFH，单字节地址。较为简单的接口，定时器、中断控制器等。扩展槽上的I/O接口卡：地址100-3FFH，双字节地址。若干个集成电路合在一起，较为复杂，显卡、声卡、网卡等。 端口地址译码方式三种译码方式：全译码、部分译码和地址开关译码。全译码：所有I/O地址线A0~A9全部作为译码的输入参与译码。部分译码：将地址线分为两部分：端口地址=芯片地址（高位）+片内地址（低位），只有高位地址线参加译码，可分为片间寻址与片内端口寻址。片间寻址：高位地址信号与控制信号组合，经译码电路产生接口的片选信号\\(\\small \\overline{CS}\\)。控制信号如：读信号\\(\\small \\overline{IOR}\\)、写信号\\(\\small \\overline{IOW}\\)等。片内端口寻址：低位地址信号不参加译码，直接连到接口芯片中，进行端口寻址。地址开关译码：在部分译码方法的基础上，加上地址开关来改变端口地址。 地址译码电路设计固定式译码：接口中用到的端口地址不能更改，分为门电路译码和译码器译码。门电路译码：对单一端口地址进行译码，使用与门、与非门等各种门电路；译码器译码：对多个端口地址译码，使用各种译码器元件。可选式译码：采用开关式端口地址译码。通过开关改变接口卡的端口地址（无需改动线路）。如果要求端口地址能适应不同的地址分配场合，或为系统以后扩充留有余地，则采用开关式端口地址译码，电路可由地址开关、译码器、比较器或异或门几种元器件组合而成。地址译码电路设计原则如下： 接口I/O指令8086中通过AL寄存器与外设交换信息。 端口为单字节地址：可直接使用地址。in AL, 60H：将60H端口中的8位数据-&gt;AL；out 61H, AL：将AL中数据-&gt;61H端口。 端口为双字节地址：不能直接使用地址，通过DX寄存器承接。mov DX,300H in AL,DX：将300H端口中的8位数据-&gt;AL（地址为16位，数据还是8位）。mov DX,301H out DX,AL：将AL中数据-&gt;301H端口。注：in/out都是相对CPU而言的。 第三章 定时/计数技术 什么是定时与计数定时：确定时间间隔。计数：统计个数。在计算中定时就是对时钟脉冲(CLK)进行计数，定时和计数本质是一样的。 定时计数接口82C54 可编程定时计数器初值寄存器CR：设定计数初值计数执行单元CE：执行计数操作，CPU不能访问计数输出锁存器OL：CPU从中读取当前计数值控制寄存器：决定82C54工作方式CLK：CPU时钟信号信号GATE：门控信号，控制83C54是否工作OUT：输出端注：寄存器都是16位的，但因为数据线只有8位，所以一次只能读写8位数据。工作原理：对CLK信号进行减1计数1、将控制字写入控制寄存器，确定82C54工作方式2、将计数初始值写入初值寄存器。3、从计数初值开始，在GATE控制下，每当CLK信号出现一次，计数值减1。4、当计数值减到0，从OUT端输出规定的信号。注：CLK信号出现时，计数器是否减1，由门控信号GATE控制 定时计数接口82C5482C54具有三个独立的16位计数器（0#~2#通道），每个通道就是一个独立的可编程定时计数器。每个通道有6种工作方式；可以进行二进制或十进制计数，计数方式为减1计数。注：82C54、8254、8253都是一个意思 82C54内部结构 数据总线缓冲器：8位，双向，用于暂存数据。1、初始化时向其写入控制字；2、向某一通道写入计数初值；3、从某一通道读当前计数初值。 控制逻辑：接收CPU发来的RD、WR、CS、A1、A0信号，经过逻辑控制电路产生出对82C54要执行的操作。 控制字寄存器：接收8位的方式命令字（控制字） 82C54外部引脚\\(\\small \\rm \\textbf{D0}\\cdots \\textbf{D7}\\)：双向，8位数据线\\(\\small \\rm \\overline{\\textbf{WR}}\\)：输入，写信号\\(\\small \\rm \\overline{\\textbf{RD}}\\)：输入，读信号\\(\\small \\rm \\overline{\\textbf{CS}}\\)：输入，接口片选信号\\(\\small \\rm \\textbf{A0 A1}\\)：输入，片内地址选择00：通道001：通道110：通道211：方式命令字\\(\\small \\rm \\textbf{OUT}\\)：输出信号 82C54初始化编程 方式命令字格式 1234567891011121314151617D7 D6：控制字是针对哪个计数器的 00：计数器0 01：计数器1 10：计数器2 11：非法。D5 D4：设置读写格式，由计数初值的位数决定，8位-01，16位-11。 00：计数器锁存命令 01：只读写低字节 10：只读写高字节 11：先读写低字节，后读写高字节。D3 D2 D1：指定82C54的工作模式 000：方式0 ... 101：方式5。D0：指定计数模式 0：二进制 1：十进制，即BCD码，将每个十进制位转化为4位二进制，求和还是按十进制来算。 编程流程原则: 先写方式命令字、再写计数初值。 12345678910111213;端口地址为60H~63H，选择1#，工作方式2，计数初值33H，BCD码制。初始化程序段为：MOV AL,01010101B ;写入方式命令字OUT 63H,AL ;片内地址为11MOV AL,33H ;写入计数初值OUT 61H,AL ;片内地址为01（使用1号通道）;若计数初值为5533H，其他不变，则程序段为：MOV AL,01110101B ;写入控制命令字OUT 63H,AL MOV AL,33H ;写入计数初值低字节OUT 61H,AL MOV AL,55H ;写入计数初值高字节OUT 61H,AL 82C54六种工作方式方式0：计数结束产生中断方式1：可重复编程的单脉冲方式2：分频器方式3：方波发生器方式4：软件触发的选通信号发生器方式5：硬件触发的选通信号发生器重点是方式2和方式3 6种方式不同之处启动计数的触发方式不同。门控信号GATE对计数操作控制不同。是否有初值重装功能。OUT引脚输出波形不同 方式0（计数结束产生中断）触发方式：软启动。写入控制字后，立即启动，OUT-&gt;低电平，但写入初值后才开始计数。注：写入初值后要等下一个clk才开始计数，一低一高算一个clk。GATE信号：高电平时计数，低电平时暂停计数。初值重装：不具有OUT波形：只计数一次，计数时为低电平，计数结束输出持续的高电平，在写入初值\\((n+1)\\cdot T_{clk}\\)时间后发生0到1跳变。 方式1（可重复编程的单脉冲）触发方式：硬件启动，写入控制字后，OUT-&gt;高电平；检测到GATE上升沿，OUT-&gt;低电平，开始计数。GATE信号：可重复触发计数，检测到GATE上升后就重新计数。初值重装：不具有。OUT波形：宽度为\\(n\\cdot T_{clk}\\)的负脉冲。用途：单脉冲发生器，宽度由程序设置的n决定。 方式2 周期性负脉冲输出（分频器）触发方式：写入控制字后，OUT-&gt;高电平，但写入初值后才开始计数。GATE信号：高电平时计数，低电平时暂停计数。初值重装：具有，在计数过程中若重新写入计数初值，对正在进行的计数过程没有影响，但在计到1输出一个CLK宽度的负脉冲后，计数器将按新的计数初值开始计数。OUT波形：产生连续的负脉冲，宽度为\\(T_{clk}\\)，周期为\\(n\\cdot T_{clk}\\)。用途：分频器，放大\\(T_{clk} \\rightarrow n\\cdot T_{clk}\\)，可用来提供周期性脉冲信号/时终信号。注：分频器意思是高频-&gt;低频就行，波形不一定要相同。 方式3 方波发生器（和方式2类似，只不过输出的是方波）触发方式：写入控制字后，OUT-&gt;高电平，但写入初值后才开始计数。GATE信号：高电平时计数，低电平时暂停计数。初值重装：具有，和方式2原理一样。OUT波形：产生连续的负脉冲，宽度为\\(\\frac {n} {2}\\cdot T_{clk}\\)，周期为\\(n\\cdot T_{clk}\\)。注：当n是奇数时，输出不对称方波，前\\(\\frac {n+1} {2}\\)个计数期间，OUT输出高电平；后\\(\\frac {n-1} {2}\\)个计数期间，OUT输出低电平。用途：方波发生器，也可分频。 第四章 并行接口串/并接口指接口和外设间的连线是单根还是多根，接口和CPU间肯定是多根线。 并行接口特点通过多根信号线同时传送多位数据，且传送时一般不需要特定的数据传送格式；并行接口多用于距离短，数据量大，速率高的实时传输场合；并行接口布线成本高，且有线路间互相干扰、时钟同步等问题，因此并行传输技术发展受限。常用并行接口： 可编程并行接口8255上一章介绍的82C54属于非通道接口，其主要功能为驱动外设，而非在CPU和外设间传数据；本章介绍的8255是通道接口，主要功能就是在CPU和外设间传数据。 8255特点有三个输入输出端口：端口A，端口B，端口C。每个端口可编程设定为输入端口或输出端口，并可设定不同的工作方式。端口C可作为一个独立的端口使用，但常常是配合A口和B口工作，为A、B端口的提供联络信号。 8255的内部结构三个并行输入输出端口（A口、B口、C口）分为两组进行控制，分别对应一个控制寄存器：A组：A口、C口高4位B组：B口、C口低4位 8255的外部引脚片选地址A1 A0：00：A端口01：B端口10：C端口11：方式命令字 8255初始化编程8255A有两个控制字（方式命令字，C口按位复位/置位命令字）和一个状态字，设置方法也不同。 方式命令字D7：1时表示方式命令字，0时表示C口按位复位/置位命令字其余位按A、B组分为两组，进行不同的控制。 C口按位复位/置位命令字在方式1和方式2时要用到这个控制字，对C口的某一位置1/0，输出正/负脉冲。此控制字只对C口有效。它被写入控制口，不是写入C口。 编程流程和82C54编程原则相同：先写控制字，再写数据值。 8255工作方式8255有3种工作方式：方式0，方式1和方式2，方式0：无条件传送（外设始终做好了准备）方式1：单向应答式传送（查询、中断）方式2：双向应答式传送（查询、中断）重要是方式0和方式1 8255三个端口对工作方式的使用情况不同。A端口：可使用3种方式的任一种；B端口：只能使用方式0和方式1；C瑞口：一般作为控制信号使用，配合A端口和B端口的工作。 方式0最简单的连接方式，直接读写数据即可。2个8位的端口和2个4位的端口，都可以作为输入或输出。单向I/0，端口只能做输入或输出一项功能。系统没有指定C口的某些线作为专门的信号联络线和状态位，但是用户可以自定义C口的某些线作为信号联络线。端口信号线之间无固定的时序关系，由用户根据数据传送的要求决定输入输出的操作过程。不需要任何选通信号。 方式1（输入过程）各信号意义：\\(\\small \\rm \\overline{STB}\\)：选通信号，表示外设已经准备好数据。IBF：输入缓冲器满信号，表示端口已经接收数据完毕。INTR：中断请求信号，请求CPU接收数据。\\(\\small \\rm \\overline{RD}\\)：读数据信号，有效代表CPU在读取数据。在外设向CPU发出INTR信号后，什么时候CPU响应了中断，\\(\\small \\rm \\overline{RD}\\)即变为有效。 方式1（输出过程）各信号意义：INTR：中断请求信号，接口向CPU发出中断。\\(\\small \\rm \\overline{WR}\\)：写信号，表示CPU向接口在写数据。\\(\\small \\rm \\overline{OBF}\\)：输出缓冲器满信号，表示外设可以从接口中取数据了 。\\(\\small \\rm \\overline{ACK}\\)：外设应答信号，\\(\\small \\rm \\overline{ACK}=0\\)其实是一个负脉冲，表示外设已接收完数据，可以再发下一个数据，因此马上会回到高电平。CPU响应中断以后，向8255输出数据，写信号出现；写信号撤消，其上升沿一方面撤消中断请求信号INTR，另一方面使\\(\\small \\rm \\overline{OBF}\\)信号变为有效的低电平，通知外设可以接收数据。当外设接收完数据后，便发出一个\\(\\small \\rm \\overline{ACK}\\)信号，同时使\\(\\small \\rm \\overline{OBF}\\)变为无效，表示数据已经取走，当前缓冲器空。\\(\\small \\rm \\overline{ACK}\\)信号结束时使INTR信号变为有效的高电平，向CPU发出中断请求信号，从而开始新的数据输出过程。 方式1下的C口状态字INTE：中断使能状态，表示是否允许端口发出INTR信号。初始化时通过C口按位复位/置位命令字来设定，设定后，就会在状态字中反映出来。PC0-PC7：指C口的对应位，为A口和B口的提供辅助信号。A组：8位数据口+5位控制口(PC3-PC7)，B组：8位数据口+3位控制口(PC0-PC2)。状态字作用：状态字主要为查询方式提供了状态标志位，方式1下，CPU读取的C口某几位内容，主要有：\\(\\small \\rm \\overline{OBF}\\)、IBF、INTE、INTR，来判断下一步应该进行的操作。注1：A口、B口都有相应的状态字，实质是相互独立的两个数据口。注2：\\(\\small \\rm \\overline{STB}\\)、\\(\\small \\rm \\overline{ACK}\\)线的状态不能读取，因为是来自外设的信号，所以状态字中没有，CPU也不需要知道。注3：端口C状态字寄存器的值和对应的引脚信号不一定一样。如输入状态下，PC4寄存器值表示INTE，而引脚则接\\(\\small \\rm \\overline{STB}\\)信号。因为INTE是在初始化时设置的，而\\(\\small \\rm \\overline{STB}\\)信号又不写到寄存器中，所以两者并不冲突，这样可以提升端口利用率。 第五章 中断技术中断的基本概念中断的本质是程序转移：CPU响应中断请求，暂停现行的主程序，转去执行中断服务子程序，完成中断事件处理后，返回断点继续执行主程序的过程。 中断的分类中断的内、外是针对CPU而言的，外部中断即来自CPU外部的中断。 外部可屏蔽中断的一般流程1、中断请求：INTR，请求信号应保持到本次中断被响应2、中断识别及判优：通过类型号区分不同中断源，通过优先级进行中断判优3、中断响应：保护现场等操作（硬件完成）4、中断处理：执行中断服务子程序5、中断返回：恢复现场等操作（硬件完成） 中断向量与中断向量表中断类型号：8086微处理器支持256种中断，编号为0~255号。中断向量：中断服务程序的入口地址，CS:IP的形式存储，占4个字节的地址。中断向量表：系统中所有的中断向量集中起来放到存储器的某一区域内，即为中断向量表。在内存中用000~3FFH共1024(4*256)个地址作为中断向量表存储区。由中断号计算中断服务程序地址：先计算中断向量的地址(4*中断号)，再取出中断服务程序的地址。总共四个字节，低2字节为IP，高2字节为CS，都是小端存储。eg：计算中断类型号为4AH的中断服务程序入口地址 可编程中断控制器8259A作用：接收外设传来的中断，进行中断识别和判优，并将应该响应中断的中断号传给CPU。只传中断号，并不执行中断。8259A只是帮助系统管理外部可屏蔽中断，外部不可屏蔽中断及内部中断CPU自己处理。8259A具有8级优先权控制，通过级连可扩展至64级优先权控制。 8259A内部结构中断请求寄存器(IRR)：该寄存器8位(D0～D7)对应于IR0~IR7线上传来的中断请求，哪一根输入线有请求，哪位就置“1”，中断被响应后对应位就置0。中断屏蔽寄存器(IMR)：寄存器8位(D0～D7)对应8级中断屏蔽，IR0~IR7哪一个中断被屏蔽，哪位就写1。优先权分析器(PR)：PR将当前中断请求的优先级和“正在服务中的中断”进行比较，决定是否让这个中断请求送给处理器（低优先级就不送了）。ISR寄存器：寄存了正在服务的\\(\\small \\rm IR_{i}\\)中断源和被挂起的中断源，可根据优先级规则判断哪个中断源正在被服务。被挂起的含义：低优先级中断先响应了，之后来了高优先级中断，就挂起去执行高优先级（若高优先级先响应，低优先级压根就不会送到ISR）。如下图：若IR0中断优先级最高，IR7优先级最低，则当前被服务的是IR0，被挂起的是IR2和IR6。级联缓冲/比较器（CAS0~CAS2）：主控和从控芯片的CAS0~CAS2相互连接，进行级联；从控的INT引脚接到主控的IR上，传递中断号。如何区分主控和从控：SP/EN引脚接高电平为主控，接低电平为从控。 8259A外部引脚 8259A中断响应过程1、IRQ0~IRQ7有中断请求，IRR的相应位置12、IRR与IMR相应位进行比较，封锁或发送中断请求给PR3、PR分析后，把当前最高优先级的中断请求由INT送至CPU4、若IF=1，CPU执行完当前指令后，连续发出2个\\(\\small \\rm \\overline{INTA}\\)信号（IF=1表示开中断）5、接到第1个\\(\\small \\rm \\overline{INTA}\\)后，ISR对应位置1，IRR对应位清06、接到第2个\\(\\small \\rm \\overline{INTA}\\)后，8259A把中断类型号送上数据总线7、CPU根据收到的中断类型号，到中断向量表中取中断向量，执行中断子程序。 8259A工作方式因为其他部分都不太重要，因此接下来重点介绍优先级排队方式。 普通完全嵌套方式在该方式下，IR7～IR0的优先级顺序是IR0最高，IR7最低。且一个中断被响应，只有比它更高优先级的中断请求才会被响应。 特殊嵌套方式该方式一般用于8259A的级联方式与全嵌套方式基本相同，不同之处在于特殊嵌套不但响应比本级高的中断申请，而且响应同级的中断申请。如果当前正在执行的中断是由从片传来的，这是从片上更高级别的中断提出请求，从片会予以响应，向主片发INT信号，但主片分不出来，只将它们视为同一级别。若普通全嵌套方式，则主片不会响应，只有特殊全嵌套方式，主片才会响应。因此级联时主片必须采取特殊嵌套方式。 优先级循环方式指当某个中断源受到中断服务后，它的优先权就自动降为最低，而优先级较其低一级的升为最高。例如，IR4被服务后，相应的IR5的优先级升为最高，依次为IR6，IR7，IR0，IR1，IR2，IR3，IR4。根据初始优先级的不同又分为两种方式：普通循环方式：默认初始优先级最高为IR0，最低为IR7。特殊循环方式：用户自己决定初始优先级，如规定IR5最低，则相应的最高优先级为IR6，依次为IR7，IR0，IR1，IR2，IR3，IR4，IR5。 8259A初始化命令字8259A有4个初始化命令字ICW1~ICW4，在接口使用前进行设置。初始化命令字必须按ICW1~ICW4的顺序写入，中间不能被打断（关中断）。且ICW1、ICW2是必须写的，ICW3、ICW4需不需要写视工作方式而定。写入地址：ICW1要写到偶地址（A0=0），ICW2~ICW4写到奇地址（A0=1）。 ICW1（芯片控制命令字） 123456789101112D7 D6 D5：可任意设置，建议设为0D4：标志位，只能设为1D3：设置中断触发方式 1：电平触发方式 0：边沿触发方式 D2：任意设置，建议为0D1：规定单片还是级连方式 1：单片方式 0：级连方式D0：是否写入ICW4 1：要写入ICW4 0：不写入ICW4 ICW2（中断类型号命令字） 1234D7~D3：设置中断向量号的高5位，手动设置。D2~D0：中断向量号的低3位，8259A会自动确定。IR0为000、IR1为001...IR7为111写的时候只用写D7~D3即可，D2~D0自动设为0。 最终中断号=ICW2的高5位+\\(\\small \\rm IR_{i}\\)组合而成。 ICW3（级联控制命令字）ICW3是级联时才需写入的控制字，且对于主、从片的意义不同。 12345678910对于主片：Di=1表示IRi接有从片，否则IRi没有接从片。对于从片：D2~D0表明从片的INT引脚接到主片的哪个IR引脚。例：主控8259第IR3、IR6上联了从控。主控：ICW3=01001000B，从控A：ICW3=00000011B，从控B：ICW3=00000110B。如何区分主控和从控：SP/EN接高电平为主控，接低电平为从控。主控和从控的CAS0~CAS2相互连接，进行级联；从控的INT引脚接到主控的IR上，传递中断号。 ICW4（方式命令控制字） 12345678910111213141516D7 D6 D5：直接设0D4：设置嵌套方式 1：特殊嵌套方式 0：普通完全嵌套方式D3：数据线的缓冲方式 1：缓冲方式 0：非缓冲方式 D2：主片/从片选择 1：主片 0：从片D1：中断结束方式 1：自动中断结束 0：非自动中断结束D0：微处理器类型 1：16位80x86 0：8位8080/8085 8259A初始化流程 8259A操作命令字8259A有3个操作命令字OCW1~OCW3，负责对8259A的工作状态进行设置。在8259A工作期间，可以随时接受操作命令字，且对写入顺序没有要求，需要哪个OCW就写入那个OCW。写入地址：OCW1写到奇地址（A0=1），OCW2、OCW3写到偶地址（A0=0） OCW1（屏蔽命令字）内容写入中断屏蔽寄存器IMR，\\(\\small \\rm D_i\\)对应\\(\\small \\rm IR_i\\)1：禁止\\(\\small \\rm IR_i\\)中断0：允许\\(\\small \\rm IR_i\\)中断 OCW2OCW2用于设置优先级循环方式和中断结束方式 1234567891011D7 D6 D5：组合为设置编码D7：是否允许优先权循环D6：设置优先级方式 1：循环优先级（按D2~D0决定哪个引脚优先级最低） 0：固定优先级（IR7最低，IR0最高）D5：是否允许EOI，EOI：结束中断，结束D2~D0对应引脚的中断 1：允许 0：不允许D2 D1 D0：指定优先级循环时，初始的最低优先级的引脚eg：D2~D0为101，表明指定初始时最低优先级为IR5，则最高优先级为IR6。 OCW3OCW3用于设置和撤消特殊屏蔽方式、设置中断查询方式以及发出对8259A内部寄存器的读出命令。 如何区分初始化命令字和方式命令字8259A只有两个端口用来写命令字（一个奇地址一个偶地址），如何区分写到地址中的命令字？对于奇地址：ICW1、OCW2、OCW3都写到奇地址，通过命令字的D4 D3两位来区分。对于偶地址：ICW2~4、OCW1都写到偶地址，通过写入顺序来区分，系统规定只能按ICW2-&gt;ICW3-&gt;ICW4-&gt;OCW1的顺序写入。 第六章 A/D、D/A转换器接口在实际工业生产环境，都是连续变化的模拟量 ，如：压力、温度、流量等；而在计算机内部，则都是离散的数字量，二进制数、十进制数、十六进制等。因此需要对连续的模拟量和离散的数字量做转换，就出现了A/D(Analog to Digital)、D/A(Digital to Analog)转换器芯片。 D/A转换芯片DAC0832D/A转换器的功能是把二进制数字量电信号–&gt;与其数值成正比的模拟量电信号(电压、电流..)。如下图：横坐标为输入的数字信号量，纵坐标为输出的模拟信号量。 DAC0832主要有三项技术指标：分辨率、精度和建立时间。 分辨率分辨率是指输入数字量发生一个单位的变化时，输出模拟量的变化量，这个参数反映了DAC对模拟量的分辨能力eg：满刻度值电压为5V、10位DAC：能分辨的电压为\\(\\small 5/2^{10}=4.88(mV)\\)。满刻度值电压为5V、8位DAC：能分辨的电压为\\(\\small 5/2^8=19.53(mV)\\)。 精度精度表明了模拟输出实际值与理想值之间的偏差，可能工艺做的器件比较粗糙，导致实际用的时候有误差，反映的是“工艺”精度。 建立时间从数字输入端发生变化开始，到模拟输出稳定在理想值的\\(\\pm \\frac{1} {2}\\)\\(\\small LSB\\)时所需的时间（LSB指分辨率）。 DAC0832内部结构DAC0832内部有两个数据缓冲器，分别由两组控制信号控制：输入寄存器：存放外部输入的数据，当\\(\\small ILE=1\\cap \\overline{CS}=0\\cap \\overline{WR1}=0\\)时，\\(\\small LE1\\)端有效，DI7~DI0上的数据锁被写到输入寄存器中。DAC寄存器：存放要输出的数据（D/A转换器根据DAC寄存器中的值计算输出的模拟值），当\\(\\small \\overline{XFER}=0\\cap \\overline{WR2}=0\\)时，\\(\\small LE2\\)端有效，输入寄存器中的数据被写到DAC寄存器中。DAC0832外部引脚：\\(\\small DI0\\sim DI7\\)：8位数字输入端，DI0为最低端，DI7为最高端。\\(\\small ILE\\)：数据输入锁存允许，通常一直为高电平；\\(\\small \\overline{CS}\\)：片选信号1–&gt;输入寄存器。\\(\\small \\overline{XFER}\\)：片选信号2–&gt;DAC寄存器。\\(\\small \\overline{WR1}\\)：写信号1，输入寄存器写选通信号。\\(\\small \\overline{WR2}\\)：写信号2，DAC寄存器写选通信号。\\(\\small Iout1\\)：DAC电流输出端1，为数字输入端为1的位的输出电流之和。全1时最大，全0时最小。\\(\\small Iout2\\)：电流输出端2，\\(\\small Iout1+Iout2=常数\\) DAC0832工作时序 DAC0832工作方式DAC0832没有应答信号，有数据输入时，若已经选通了，即开始转换；也没有控制字信号，直接送数据即可。DAC0832有单缓冲模式、双缓冲模式、无缓冲模式三种工作方式，重点是单缓冲模式。缓冲的含义：缓冲即指锁存，锁存就是寄存器能否暂存数据（尽管有新的输入数据，但仍旧保持原有的值，直到某个信号的到来才更新寄存器的值）。如果没有锁存功能，就是寄存器值和输入值保持同步，输出会随着输入而变化。在DAC0832中，实现两个寄存器的缓冲功能，要通过寄存器对应的选通信号线：选通信号线处于无效状态，数据就写不进去，就实现了缓冲/锁存。若选通信号线恒有效，就没有缓冲功能。如何设置工作方式：0832没有命令字，根据选通信号引脚连线的不同来决定工作方式。 双缓冲方式输入寄存器、DAC寄存器都有缓冲功能。当把数据由输入寄存器写到DAC寄存器以后，输入寄存器就可以接受新数据而不影响模拟输出值，该结构便于多路DAC同时工作（可以时分复用，利用DAC寄存器中数据转换的时间读取数据）。 12345要分别对两个寄存器写数据MOV DX，200H ;DAC0832 的输入锁存器的地址为200H OUT DX，AL ;AL中数据DATA送输入寄存器MOV DX，201H ;DAC0832 的DAC锁存器的地址为201H OUT DX，AL ;数据DATA写入DAC锁存器并转换 单缓冲方式只有输入寄存器有缓冲功能。只需一次写操作，就开始转换，提高了D/A的数据吞吐量。适合在不要求多片D/A同时输出时。 12MOV DX，200H ;设DAC0832的地址为200HOUT DX，AL ;AL内数据送DAC转换 直通方式两寄存器都没有缓冲功能，输出随输入同步变化。 12MOV DX，200H ;8255的A口地址为200HOUT DX，AL ;AL中数据送A口锁存并转换 用DAC0832输出三角波 1234567891011121314151617181920;设输出初始值0L1: MOV AL, 0;输出数值递增，产生三角波上升沿UP: MOV DX, 300H ;单缓冲OUT DX, ALINC ALCALL DELAY;判断输出是否为0，JNZ：不为0跳转AND AL, ALJNZ UP;输出数值递减，产生三角波下降沿DOWN: DEC AL ;AL=0-1=255OUT DX, AL CALL DELAY;判断输出是否为0AND AL, ALJNZ DOWNLOOP L1 A/D转换芯片ADC0809将模拟信号转换为数字信号 A/D转换基本原理：采样：利用采样脉冲序列，从信号中抽取一系列离散值，使之成为采样信号；量化：把采样信号经过舍入变为只有有限个有效数字的数，使电流和数据有一一对应的关系；编码：将经过量化的值变为二进制数字。如何将十进制数值转换为二进制：使用逐次逼近的方法，具体原理如下图： ADC0809结构IN7~IN0：8路模拟信号输入。ADDC、ADDB、ADDA：8路模拟信号量的地址选择线，选择要接收的一路模拟信号量。ALE：地址锁存允许，其正跳变锁存地址选择线状态，经译码选通对应的模拟输入信号。START：启动信号，上升沿使片内所有寄存器清零，下降沿启动A/D转换（通常与ALE共用一根线）。EOC：AD转换结束信号，转换开始后，此引脚变为低电平，转换一结束，此引脚变为高电平；OE：输出允许，当有效时，D7~D0输出结果。D7~D0：8位数据输出线。 ADC0809输出数据的传送方式延时等待法：软件延时等待足够长的时间（大于转换时间），此时不用EOC信号，CPU效率最低。中断法：把EOC作为中断请求信号，在中断服务程序中读入转换结果，效率较高。查询法：软件查询EOC信号的状态。具体代码见PPT 第七章 串行接口串行通信方式基本概念串行通信方式：在一条传输线上，将多位数据从低位到高位顺序地进行传输。并行通信方式：在多条传输线上同时传输多位数据，且有专门的联络、控制信号线。 串行通信的数据传送方向 信号的调制和解调数据通信设备DCE：Modern数据终端设备DTC：主机、终端通讯设备。三种调制方式：振幅键控（ASK），频移键控（FSK）和相移键控（PSK） 数据的传输速度数字通信中，传输速率经常用波特率(baud)来表示。同时为提高发送/接收时钟对波特率的定位精度，发送/接收时钟的频率常定为波特率的整数倍（1、16、32、64），这个整数称为波特率因子。$$TxC=factor\\times baud$$ TxC为发送/接收时钟频率。波特率因子可理解为发送/接收1位数据所需要的时钟脉冲个数，即在发送端，需要多少个时钟脉冲才能移出1位数据。时钟脉冲多一些，可提高定位采样的精度。 串行通信的基本方式异步串行通信：以字符为单位发送数据，字符间间隔不定（异步），但字符内各位是同步的。适合数据量少、速率低，发送数据不连续的场合。同步串行通信：以数据块为单位发送数据，字符间、字符内都是同步的。适合速率高，连续传输大批量数据的场合。外同步：发送端发数据前先发送同步时钟信号，接收方用这一同步信号来锁定自己的时钟脉冲频率，来达到收发双方位同步的目的。自同步法：接收方利用包含有同步信号的特殊编码（如曼彻斯特编码）从信号自身提取同步信号来锁定自己的时钟脉冲频率，达到同步目的。 串行通信数据格式对于异步串行通信，因为字符间的间隙不固定，因此要有起始位和终止位。对于同步串行通信，要求有时钟来实现发送端与接收端之间的同步，因此有很多控制字符，因较为复杂就不列举了。 串行接口标准RS-232C 电气特性在TxD和RxD数据上：逻辑1(MARK) = -3 ~ -15V逻辑0(SPACE) = +3 ~ +15V在RTS、CTS、DSR、DTR和DCD等控制线上：信号有效（接通，ON状态）= +3 ~ +15V信号无效（断开，OFF状态）= -3 ~ -15V RS-232C的引脚信号线数据发送与接收线：TxD：发送数据，将串行数据发送到MODEM RxD：接收数据，从MODEM接收发来的串行数据状态线：DSR：表明MODEM可以使用。DTR：表明数据终端可以使用。信号联络线（modem之间建立通信链路）：RI：振铃指示，当MODEM收到交换台送来的振铃呼叫信号时，通知终端，表示交换台准备好了。DCD：数据载波检出线，表示MODEM已接通通信链路。信号联络线（modem与终端之间）：RTS：请求发送，表示DTE请求DCE发送数据。CTS：允许发送，表示DCE准备好了，DTE可以发数据，是对RTS的响应信号。地线：GND：地线 数据传输过程 微机间连线方式重点是不使用联络信号的3线相连方式，如下图所示：不使用Modem，TxD和RxD要交叉连接。 8251可编程通信接口8251是通用同步异步接收发送器USART(Univesal Synchronous Asynchronous Receiver and Transmitter)，适合作为异步起止式和同步面向字符式的接口。 第八章 存储器 内存的分类DRAM的特点：主要由电容构成，需要定时刷新DRAM芯片举例：intel 2164A，容量为\\(64k\\times 1\\) 存储器扩展技术存储器的存储容量等于：单元数(字节数)×每单元的位数(字长)，因此就有三种扩容方式：字扩展、位扩展、字位扩展。 位扩展地址线、片选线和读写信号线各芯片共用，数据线单独引出。eg：8片64K×1位的SRAM芯片构成容量为64KB的存储器 字扩展地址线、读写信号线和数据线各芯片共用，片选线单独引出。eg：4片16K×8位的SRAM芯片构成容量为64KB的存储器 字位扩展结合了上述两种方法的特点。eg：用8片16K×4位的存储器芯片组成64K×8位的存储器 第九章 人机接口 键盘接口的分类编码键盘：这种键盘内部能自动检测被按下的键，并提供与被按键对应的键码（如ASCII码），以并行或串行方式送给CPU。非编码键盘：这种键盘只提供键盘的行列矩阵，而按键的识别和键值的确定、输入等工作通过软件完成。这是目前可得到的最便宜的微机输入设备。 软件实现非编码键盘识别的方法扫描法：依次查询键盘矩阵的每一行线，然后读取列数据确定按键是否在本行，具体方法如下：首先使PA0=0，然后读取PB端口。若PB=0FFH则表示行0没有按键按下，再使PA1=0再读取PB判断行2有无按键按下，依次扫描全部的行线。当PB读取的数据不为0FFH，则表示该扫描行有按键按下，则再确定相应的按键序号。时间复杂度：\\(n^2\\)行列交换法：使CPU通过A口向各行线上全部送低电平，然后从B口读入列线的值。如果某按键按下，则必定会使某一列线值为0。然后，交换A口B口的输入输出方向，并将刚才读到的列线值从列线所接的并口输出。再读取行线上的输入值，在闭合键所在的行线上的值必定为0。这样，当一个按键被按下时，必定可以读取一对唯一的行值和列值。时间复杂度：\\(2n\\) 七段数码管七段数码管就是并行接口8255，7个段分别对应8255的一个引脚，通过设置引脚电平来控制亮灭，示意图如下：","categories":[],"tags":[{"name":"课程笔记","slug":"课程笔记","permalink":"https://renli1024.github.io/tags/课程笔记/"}]},{"title":"MOOC_C语言笔记","slug":"Algorithm/MOOC_C语言程序设计笔记","date":"2018-09-13T07:49:58.000Z","updated":"2018-06-13T07:41:45.000Z","comments":true,"path":"2018/09/13/Algorithm/MOOC_C语言程序设计笔记/","link":"","permalink":"https://renli1024.github.io/2018/09/13/Algorithm/MOOC_C语言程序设计笔记/","excerpt":"","text":"第一节_基础知识 STL：C++中的标准模板库 define和typedef 123#define MAXNUM 9999 //宏定义，多用来替代常量typedef multimap&lt;int,int&gt; MAP; //为复杂的类型定义取别名，简化程序，也便于修改。 类型取值范围 类型 字节数 取值范围 int 4 -2^31~2^31-1(-21亿~21亿) long long 8 -2^63~2^63-1(很大) float 4 3.4x10^-38~3.4x10^38(绝对值) double 8 1.7x10^-308~1.7x10^308(绝对值) char 1 -128~127 bool 1 true/false double类型比较相等：相减-&gt;是否小于一个很小的数(0.00001)。比大小：直接&gt; &lt; 比较即可。 求字节数：sizeof(int)/sizeof(n) 反斜杠\\，转义字符、win下地址路径；正斜杠/，网址路径。 字符型和整型数据可以相互转换，整型-&gt;字符型：只留最右边8位，再转成ASCII码。 常用ASCII码：‘0’-‘9’：48-57‘A’-‘Z’：65-90‘a’-‘z’：97-122 十六进制常量：0x打头,0xFFA，1个十六进制位对应4个二进制位。表示二进制：转化为16进制。00101011-&gt;0x2b 八进制整型常量：0打头，0677,1个八进制位对应3个二进制位。 位运算单独对某些比特进行操作与&amp;：将某些位置0、获取变量中的某一位eg：判断n的第7位是否为为0，n&amp;0x80==ox80？ 或|：将某些位置1 异或^：相同为0不同为1。将某些位按位取反，其他位不变：取反的与1异或，其他与0异或。 非~：按位取反。 左移&lt;&lt;：左移n位即乘2的n次方，但比乘法要快很多。 右移&gt;&gt;：除2的n次方，且向小取整。高位补符号位。 第二节_数据结构数组初始化：类型名 数组名[数量]={x1,x2,x3,x4..} 或 用for循环初始化。数组越界编译器不会报错，会根据内存地址去访问，数组名即相当于内存地址。编程技巧：可用数组取代复杂的switch case分支结构 字符串 字符串三种形式1、字符串常量，双引号括起来””。2、存放在char数组中，以’\\0’结尾，多占一个数组元素。3、string对象，c++标准模板库中的类。注：char数组比string快，但char数组没法传字符串值，只能传数组首地址。因此在一些需要传值的场合，用string更合适。 字符串在内存占的字节数等于字符数目加1(‘\\0’的存在 )读入字符串：cin或scanf，读到空格为止。空格后内容在下一次cin读入。读一行：cin.getline(char buf[],int bufSize)，读入不超过bufsize-1个字符 结构体struct1234567891011struct Student&#123; unsigned ID; char name[10]; float fGPA; Student* frd;//成员可以是结构体的指针&#125;;Student s1 = &#123;1234,\"TOM\",...&#125;;//初始化cout&lt;&lt;s1.ID;Student* s2;cout&lt;&lt;s2-&gt;ID; / cout&lt;&lt;(*s2).ID;指针访问成员 变量局部变量：定义在函数内部、语句块内部的变量。全局变量：定义在函数外部(main函数外)，在所有函数中均可使用。默认初始化为0.静态变量：全局变量和static定义的变量。生存期一直持续到整个程序结束。PS：若未初始化，静态变量默认赋值为0，非静态变量值为随机的。 switch case123456789switch(表达式)&#123; case x1: break; //有无中括号都可以 case x2: break; //... default: break&#125; 第三节_函数与输入输出函数1234567891011函数定义：int fun(int a, char c)&#123; //函数体 return xx ;&#125;函数声明：(无函数体，常写在开头)int fun(int a, char c);int fun2(int a[]);//一维数组作形参，不用写大小。int a[]与int *a等价。int fan3(int a[][3])//二维数组作形参，行数不用写，列数必须写 函数的形参是实参的拷贝，形参的改变不会影响实参。(除非形参是数组、引用或对象)string类型也是传值数组作形参传的是首地址，并非整个数组。 printf、scanf格式化输入输出比cin/cout效率高，尽量使用。%：类型占位符 格式字符 说明 %d int类型 %c char类型 %f float类型 %lf double类型 %.xlf 输出x位小数 1234567891011121314151617#include &lt;cstdio&gt; //头文件printf(\"这是字符型数据%c，这是int型数据%d\"，ch,i); //格式化输出scanf(\"%d%d\", &amp;n, &amp;m); //记得加&amp;，返回值是接收变量的个数char c[20];scanf(\"%s\",c); //读入字符串，检测到/0结束//返回值为EOF(-1)时说明输入结束while(scanf(xxx) != EOF)&#123; //循环读入数据&#125;cin.peek() //看一个字符不取走cin.putback(c) //把字符放回输入流头部scanf函数读空格和换行：如果是%d、%f数值类型，会自动跳过多余的空格和换行，如果是%c会读入空格和换行。 freopen重定向将输入由键盘重定向为文件(不用每次都输入测试数据)1234freopen(\"c:\\\\xxx.txt\"，\"r\",stdin);while(scanf(...)!=EOF)&#123; //从txt文件中输入&#125; cin函数cin &gt;&gt; n &gt;&gt; m;返回True(成功接收所有输入)或false()while(cin &gt;&gt; n){ //循环读入数据}注：cin读入的格式由后面的变量决定，若为char即读入一个字符，int则读入一个整数(遇到空格/换行为止) 第四节_指针 指针123456指针变量，4个字节，内容表示一个内存地址。int *p; //p类型：int *，*p的类型：intchar c1 = 'A';char *pc = &amp;c1; //pc指向变量c1//*：间接引用运算符。&amp;：取地址运算符。//&amp;x：变量x的地址，就是指向x的指针，类型是 T*。 指针的意义：不需要通过变量，即可自由访问内存空间。 指针互相赋值不同类型的指针，如果不经过强制类型转换，不能直接相互赋值。 (每个指针类型还代表着一次向内存读/写多少字节)char c = ‘A’;int p = (int )c; p=122; //此时’A’后面三个字节的值也会被改变。 指针的运算 指针比大小：比p1和p2地址的大小 指针相减：p1-p2=(地址p1-地址p2)/sizeof(T) p+n=p+n*sizeof(T)，结果还是指针。 p[n]=*(p+n) 空指针指向地址0的指针，int *pn=NULL; 指针和字符串字符串常量、字符数组的类型都是char*。 void指针 1234可以用任何类型的指针对void指针进行赋值int a = 3;void *p = &amp;a;但*p、P+n、p++等均无意义 void*自动匹配 123456789101112memset函数void* memset(void* dest,int ch,int n)：将dest开始的n个字节都设置为ch(取其最低位字节)，初始化数组。//对char数组赋值时，结尾要加'\\0'memcpy函数void* memcpy(void* dest,void* src,int n)：将n个字节拷贝src-&gt;dest。char a1[10]=\"\";char a2[10]=\"\";memset(a1, 'a', sizeof(a1)-1);memcpy(a2, a1, sizeof(a2));cout &lt;&lt; a2 &lt;&lt; endl; //输出aaaaaaaaaa 函数指针 123//指向函数入口地址的指针int (*Pf)(int,char)pf = fun_name; 第五节_基本STL 库函数和头文件库函数：编译器自带的函数头文件：包含许多库函数的声明 排序12345678910111213141516171819#include &lt;algorithm&gt;//排序//sort(数组名+n1,数组名+n2)，对数组[n1,n2)区间排序，默认从小到大int a[] = &#123;15,4,3,9,2,6&#125;sort(a,a+sizeof(int)/sizeof(int)) //从小到大排序//从大到小排序//#include &lt;functional&gt;头文件sort(a,a+7,greater&lt;T&gt;()) //自定义排序规则bool cmp(const int &amp; a1,const int &amp; a2) &#123; return a1 &gt; a2; //若a1应排在a2前面，则返回true。否则返回false&#125;int a[] = &#123;15,4,3,9,2,6&#125;sort(a,a+sizeof(a)/sizeof(int),cmp()); 二分查找 前提条件所有的二分查找，都是应用在有序列表中的。 binary_search函数两种使用方法：bool binary_search(数组名+n1,数组名+n2,值)bool binary_search(数组名+n1,数组名+n2,值,排序规则结构名())，查找时的规则必须和排序时的规则一致。对排好序的数组进行二分查找，返回值true：找到，false：没找到。查找的本质：查找x，即找到一个元素y，使得“x必须排在y前面”和“y必须排在x前面”都不成立（和 == 的含义不一样），这样就算找到了；没有找到元素y，就是没找到。所以不存在的元素同样有可能查的到（eg：按个位排序，查找的元素只要个位相等就能查到，十位/百位不一定会相等），因此查找的结果要视具体排序规则来分析。 lower_bound函数T* lower_bound(数组名+n1,数组名+n2,值)返回序号p，使得[n1,p)中元素都小于查找值。若比所有元素都小/大，则指向n1/n2。为避免返回序号为n1时的歧义，查前要确保值在数组范围内。 upper_bound函数T* upper_bound(数组名+n1,数组名+n2,值)返回指针p，使得[p,n2)中元素都大于查找值。 平衡二叉树在log(n)内快速添加、删除、查找元素应用了平衡二叉树的四种排序容器：multiset、set、multimap、map multiset容器 主要作用自动对集合内元素排序(默认从小到大)，且允许元素重复，在一些需要动态增加、删除元素的排序场景下使用很方便。 12345678910111213141516171819#include &lt;set&gt; //头文件multiset&lt;T&gt; st;T a[5] = &#123;1,2,3,4,5&#125;multiset&lt;T&gt; st2(a,a+5); //用数组初始化st.insert(a); //插入元素a，自动排序。插入的是复制值，并非引用。st.erase(a); //删除元素a//遍历集合，用迭代器multiset&lt;int&gt;::iterator it; //定义迭代器，类似指针for (it = st.begin(); it != st.end(); it++) &#123; cout &lt;&lt; *it &lt;&lt; \" \"; //end()为末尾指针，指向最后一个元素的后面&#125;it = st.find(a); //查找元素a，返回迭代器,没找到返回end()st.lower_bound(a); //返回迭代器it,使得[begin(),it)中元素都比a小，注意是前闭后开区间st.upper_bound(a) //返回迭代器it,使得[it,end())中元素都比a大 自定义排序规则的multiset1、自定义规则结构体Rule，实现bool operator()(const &amp; T,const &amp; T)函数2、定义容器multiset&lt;T,Rule&gt;3、定义迭代器muliset&lt;T,Rule&gt;::iterator 123456//自定义规则结构体Rule方法struct Rule&#123; bool operator()(const &amp; T,const &amp; T)&#123; //比较函数 &#125;&#125;; set容器与multiset容器区别：不能有重复元素，其他都一样。a和b重复的含义：a排在b前面、b排在a前面都不成立注：因为不能重复，所以插入元素有可能不成功。12pair&lt;set&lt;T&gt;::iterator,bool&gt; result = set.insert(n); //result.second==true，插入成功；否则失败。 multimap容器1234567891011121314键值对形式，multimap中的元素都是pair形式。按first进行排序，一般不自定义排序。pair模板：pair&lt;T1,T2&gt;等价于struct&#123; T1 first; //关键字 T2 second; //值 &#125;;#include &lt;map&gt;multimap&lt;T1,T2&gt; mp;mp.insert(make_pair(T1变量,T2变量)) //make_pair为转换pair模板的函数multima&lt;T1,T2&gt;::iterator it //迭代器 map容器和multimap区别：不能有关键字重复的元素可以使用[first]查找second值；若first不存在，则创建一个。插入可能失败(first重复)。 camath数学库 abs(int x)：整数绝对值 fabs(double x)：浮点数绝对值 sqrt(double x)：求平方根 ceil(double x)：不小于x的最小整数(上取整) sin(double x)/cos(double x)：x(弧度)的正/余弦 cstring字符串库函数都是根据’\\0’来判断字符串是否结束的。 形参常为char c[]，实参可以为char数组或字符串常量。 int strcmp(char c1[],char c2[])：比较字符串，相等返回0，c1小返回负数。 char* strcpy(char dest[],char src[])：拷贝字符串src-&gt;dest，返回dest首地址。 int strlen(char c[])：求字符串长度 char strchr(char str,char c)：str中查字符c是否在str中，返回指向位置的指针，未查到为NULL。 char strstr(char str1,char *str2)：str1中查子串str2位置，返回指向位置的指针，未查到为NULL。 cbar strtok(char str1,char* str2)：str1中抽取被str2分隔的子串。(将str1中的分隔符用’/0’代替了)12345char *p = strtok(str1, str2); while (p != NULL) &#123; cout &lt;&lt; p &lt;&lt; endl; p = strtok(NULL, str2); &#125; ctype.h字符库 bool isdigit(int c)：判断c是否是数字字符 bool isalpha(int c)：判断c是否是字母字符","categories":[],"tags":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://renli1024.github.io/tags/Algorithm/"}]},{"title":"Git操作","slug":"Git操作","date":"2018-09-13T07:49:58.000Z","updated":"2019-08-02T11:11:38.664Z","comments":true,"path":"2018/09/13/Git操作/","link":"","permalink":"https://renli1024.github.io/2018/09/13/Git操作/","excerpt":"本篇文章介绍了Git原理、基本命令、如何在常见开发平台中使用Git以及如何使用Github等。","text":"本篇文章介绍了Git原理、基本命令、如何在常见开发平台中使用Git以及如何使用Github等。 Git原理介绍Git是一个分布式版本控制系统，功能就像其名字一样，可以从两个方面来理解：一是版本控制，二是分布式。 所谓版本控制系统，其作用是可以记录文件的每一次修改（改了哪里，改了什么，什么时候改的），当人们知道这些信息后，就可以方便地进行版本控制（如查看自己之前改了什么，恢复以前的某个操作等）； 而所谓分布式，则是指Git将版本信息分布地进行保存（并没有集中存储在某台电脑上），每个参与项目的电脑上都会保有一个版本信息库，这样的好处是信息不容易丢失，且配合Git强大的分支管理功能，能极大地提升协同工作效率。 Git存储格式Git系统反映在文件上就是.git文件夹，储存在在项目的工程目录下，这个文件夹中存储了所有Git所需的信息（版本信息，分支信息，配置信息等），Git仓库本质上指的就是这个文件夹，这也是在克隆github库时后缀必须是.git的原因。注：但是在github repository中并不能找到对应的.git文件夹，个人猜测应该是github将这个文件夹隐藏了（实际在电脑文件系统中.git也是隐藏文件夹），github会自动对其进行维护，用户并不需要管这个文件夹。 Git文件状态 目录下的文件可分为tracked(已跟踪)和untracked(未跟踪)两种状态。 tracked：指处于Git控制下的文件，可以进行stage, commit等操作； untracked：指被Git系统忽略的文件，可通过配置.gitignore文件来设置忽略哪些文件。 而根据文件所在区域的不同，tracked文件又可分为三种状态：staged、committed和modified。为便于理解，首先引入Git系统的三个区域。 Git系统的三个区域包括Working Directory(工作目录), Staging Area（暂存区）, Repository(仓库)。 Working Directory：即为当前的工作目录； Staging Area：是一个虚拟区域（并没有实际的文件夹与之对应），其存储了所有暂存的文件； Repository：仓库区，也是一个虚拟的区域，所有已保存的文件都会存入这里。 三个区域的关系如下： tracked文件的三种状态staged：指已存入暂存区的文件，下次提交时会将暂存区中的文件提交到Git仓库。committed：指已经提交到Git仓库中的文件，也可理解为未修改的文件。modified：表示已修改，但还未提交到仓库中的文件。一个文件的状态周期如下： 暂存区存在的意义：主要是为了保证commit的干净。可以选择性要提交哪些文件，而不是一次性把文件全部提交了，这样能保证把一些意义相似的修改都放在暂存区在一个commit下一次提交，而不至于将一些不相关的、无意间的修改加进去，保证了commit的纯洁性，降低commit粒度（一个大commit可以拆成多个小commit）。因此暂存区并不是为了暂时存放某些文件，而是为了更好地整理当前要commit的文件，因此规范上来说不应该在暂存区里存文件（要commit的文件选好后直接提交了就行了） 如何在各个系统上使用GitLinux/Mac下：安装Git后，Git会被添加到环境变量中，可直接通过terminal来执行git指令；Windows下：安装Git后，可通过Git Bash（命令行）和Git GUI（图形界面）两种方式使用。注：目前IDE大多集成了Git的功能，直接在IDE里点一点就可以很方便地使用Git。但为了充分了解Git的工作方式和原理，还是需要学习一下Git的相关指令。 Git BashGit Bash是Git在Windows下模拟的Linux命令行环境，在这个环境下可以使用Git命令、常用的Linux命令等。注：在Git Bash中复制粘贴可以直接右键，也可以用快捷键（复制：ctrl+ins，粘贴：shift+ins），但不能ctrl+c/v。 ShellBash是Shell的一种，首先介绍一下Shell。Shell字面理解是“壳程序”（操作系统可以分为核心kernel和外壳Shell两部分），用于用户和系统内核间的交互。相当于是一个命令解析器，其接收用户命令，然后调用相应的内核指令，完成相应的功能。Shell有很多种，如Bourne SHell(sh)、Bourne Again SHell(bash)、C SHell(csh)等，这些Shell最大的区别就是命令集的不同。注1：在linux/mac中预设的Shell就是bash；在Windows中的Shell是cmd和PowerShell，cmd功能较为简单，PowerShell功能则非常强大，可以看作cmd的超集。注2：如何区分各种shell？可通过命令的开头字符，如果是$, #则为bash($为普通用户，#为管理员root超级用户)；如果是PS &lt;当前地址&gt;则为Powershell，如果直接是&lt;当前地址&gt;则为cmd。注3：同时Shell又是一种编程语言，可自动执行一连串的命令，并具有定义变量、循环/分支控制结构等特性。 Git基础操作从新建版本库-&gt;提交第一个文件以下从Git常用的使用流程出发来介绍相关命令 创建版本库：git init，将当前目录变为git可管理的仓库 添加追踪文件：git add &lt;文件名&gt;，用来跟踪新文件(tracked)；add .代表所有文件。 修改文件 暂存文件(stage)：git add &lt;文件名&gt;，这是一个多功能指令，也可用于将文件添加到暂存区。add指令可理解为“添加内容到下一次提交中”。 提交文件(commit)： git commit -m &quot;&lt;提交说明&gt;&quot;：将暂存区中的文件提交到仓库。 git commit -a -m &quot;&lt;提交说明&gt;&quot;：直接将文件提交到仓库（跳过暂存区）。 推送文件到远程库(push)：git push &lt;远程库名字&gt; &lt;要push的分支名&gt;。远程库名字一般为origin；如果推送的是主分支，分支名就为master。注：初次push可以使用git push -u &lt;远程库名字&gt; &lt;要push的分支名&gt;来设置默认关联的远程库和远程分支，之后再提交就可以直接git push，无需再指定参数。 如何使用远程库一般我们都是用Github作为远程库来使用的，因此下文远程库默认指的都是Github。 远程库与本地库关联如果想使用远程库，需要本地库与远程库关联，具体方法有二： 如果本地库是从远程库clone来的，那么直接就是关联的，无需任何操作； 如果本地库是自己建的，则需要手动关联远程库，命令为： git remote add &lt;name&gt; &lt;url&gt;name: 自己给远程库起个名字，直接origin即可；url: 远程库url。 远程库名字 &amp; url 远程库名字约定俗成为：origin； 远程库url有两种写法： SSH写法：git@github.com:lrStyle/rep_name.git HTTPS写法：https://lrStyle/rep_name.git推荐用SSH写法（有时HTTPS会拒绝访问），但是不管哪种写法后缀都要是.git。 git remote -v：查看远程仓库信息，-v参数为显示url地址。 克隆远程库git clone &lt;url&gt;：克隆远程库到当前目录下（会直接克隆整个文件夹，所以没必要新建一个文件夹）。 Git初始化设置必要的两个初始化配置：姓名和邮箱git config --global user.name &quot;&lt;name&gt;&quot;：设置姓名git config --global user.email &quot;&lt;email&gt;&quot;：设置邮箱git config --list：查看设置注1：加--global选项后，姓名和邮箱会保存到~\\.gitconfig账户下，对当前账户下的所有git仓库都有效；不加--global选项，config则只会保存到当前目录的.git目录下的.gitconfig文件中，只对当前git仓库有效。注2：Github会根据在Git中设置的邮箱来判断向它提交的用户，因此git的邮箱需要与github账号的邮箱保持一致。注3：也可通过直接修改.gitconfig文件的形式来指定用户名和邮箱。123[user] name = RenLi email = renli1024@outlook.com 查看提交历史git log：查看commit历史记录(出现END时按q退出)，只有当前版本之前的信息。git log --pretty=oneline：简略显示，在每一行显示一个提交，只包含提交说明。git reflog：简略显示所有的提交信息。 如何撤销已经push到远端上的commit如果发现push到github上的commit有错误，或者是有一点小修改没加不想再新开个push，可以选择撤销已push的commit，具体步骤如下： 先在本地回退到相应的版本：git reset --hard &lt;版本号&gt;。注1：通过git log查看历史版本号；而且版本号只写开头几位就行。注2：--hard参数意思是抛弃当前工作区的修改；如果希望保留工作区的更改，仅仅版本信息回退到之前的，可使用--soft参数（其实就相当于把之前的commit &amp; push撤销了）。 本地进行修改，重新commit。 重新向远端push：git push origin &lt;分支名&gt; --force。使用--force参数来强制覆盖掉远端的版本信息；普通的git push会提示本地版本落后远程版本，是交不上去的。 注：如果回退之后又后悔了，则可以用git reflog查找之前的commid id（直接git log是查不到的），然后reset到之前的版本。 多人协作中的Git开始工作前先同步，推送前先同步，保证你向远程库推送的修改不会与别人冲突。 分支操作查看分支：git branch创建分支：git branch xxx(分支名)切换分支：git checkout xxx(分支名)创建+切换分支：git checkout -b xxx(分支名)合并某分支到当前分支：git merge xxx(要合并的分支名)删除分支：git branch -d xxx(分支名)强制删除未合并的分支 ：git branch -D xxx(分支名)若合并分支时存在冲突，需要手动解决冲突再提交。git log –graph ：查看分支合并图 其他命令git status：查看工作区中的文件状态（是否有文件被修改过）git diff：查看文件具体的修改内容(默认是比较版本库中和工作目录中的文件)git rm --cached &lt;文件名&gt;：将某文件从tracked设为untracked，但硬盘上还会保留，只是不再Git不再跟踪了。git rm &lt;文件名&gt;：删除版本库中的文件。git checkout -- &lt;文件名&gt;：从版本库中恢复硬盘中被删除的文件。 设置.gitignore文件除了通过命令使得不再跟踪某个文件，还可以设置.gitignore文件来指定哪些文件不再跟踪，遵循glob模式（shell所使用的简化的正则表达式格式）。规则：/：匹配模式前加/表示是相对根目录下的位置；匹配模式最后加/表示要匹配的是目录（及目录下的文件），不匹配文件；*匹配任意个字符；[]匹配括号内任意单个字符；[0-9]使用短划线匹配一段范围内的字符，这个例子中是匹配0到9之间的任意数字；?匹配任意单个字符。#：注释eg:*.a：匹配所有.a类型的文件foo：匹配所有名为foo的目录和文件。foo/：只匹配名为foo的目录（不管是根目录下的/foo/目录，还是某个子目录下/child/foo/目录）；/foo/：只匹配根目录下的foo目录，而不匹配其他子目录下的foo目录；常用.gitignore模板 VS集成Git工具的使用更改：相当于提交commit，将修改提交到本地库同步：先将远程库拉取，再将本地库推送到远程库，即先Pull再Push推送：将所做的更改，存入远程版本库提取(Fetch)：从远程版本库获得最新版本拉取(Pull)：将远程版本库合并到本地版本库，相当于（Fetch+Merge）变基到(Switch)：切换分支（双击即可切换）VS右下角会有两个Git小图标，如上图所示。铅笔：commit；右边的数字：发生修改但还未commit的文件数。上箭头：点击后会跳到同步界面，这时可点击“推送”将更改推送到远程库；右边数字：commit了但还未Push的文件数。工作流程：开始工作前先同步，把别人的提交更新到你的本地库；提交前再同步一下，再将别人的提交更新到本地库（这两次同步也可用“拉取”Pull代替，主要保证和别人的commit不冲突，如果是自己的项目就不用这么做了。且一定要commit前做，而不是push前做！否则还是会冲突）；之后再提交、推送，更新远程库。 Git冲突（conflict）操作为何会出现冲突？ 出现冲突的原因：本地和远程的两条版本线不一致。 Git本质就是维护一条版本时间线（即master），理想情况下这条时间线在各个机器上都应该是一致的，这证明了大家的工作进度都是一致的。如果出现了冲突，即表明了大家机器上的commit线不完全一致，可能的情况： 本地修改了相同的文件，但没提交，这时候pull是pull不下来的，系统会提示“会覆盖本地文件”，因此合并被拒绝。这种情况其实不能算严格意义上的冲突，因为本地并没有commit，也就不存在版本线冲突，只是因为pull会覆盖当前的修改，因此系统无法pull。解决方法：1、暂时放弃本地的更新，pull后在新的commit上再更新；2、本地交一次commit，这样就可以pull下来了（会有conflict），之后merge conflict即可。 本地修改了相同的文件，且commit了，这样pull后就出现了冲突，出现冲突后git首先会自动先更新那些只有一方更改的部分，之后对于两方都修改的部分，需要手动合并，之后再commit。 git会自动标出哪些部分是冲突的，如123456789Git is a distributed version control system.Git is free software distributed under the GPL.Git has a mutable index called stage.Git tracks changes of files.&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEADCreating a new branch is quick &amp; simple.=======Creating a new branch is quick AND simple.&gt;&gt;&gt;&gt;&gt;&gt;&gt; branch1 HEAD和branch1分别是两个分支，冲突的部分已经被写出来，根据实际情况修改后，删掉HEAD、branch1、&lt;&lt; == &gt;&gt;等标号即可。注：修改后一定要再测试遍程序确认可以运行，因为git只会列出两者共同修改的部分，而对于那些只有一方修改的地方则会自动更新，因此就有可能出现前后不一致的情况（前边保存了HEAD版本的，后边只有branch1修改的部分被自动保存下来了），所以要再确认下git自动修改了哪些部分（IDE里一般都有这个功能）。 Git merge远程库后会自动覆盖掉我写的代码吗？先说结论：不会。git只会自动改一方没有改的文件，因此不存在你改了然后把你的修改覆盖了这种情况。大致列举几种git自动修改的情况：1、远程改了你没改-&gt;改你的，将远程修改添加到staged里。2、你改了远程没改-&gt;将你的修改添加到staged里（commit、pull后相当于改了远程的）。3、你改了、远程也改了，出现冲突，要手动merge conflict，合并完后再commit。 git文件丢失的情况：git只会修改没改的，因此唯一的丢失情况就是别人不小心把你的文件改了，且你自己没动这部分文件，因此git在更新时会自动将这部分文件与远程别人修改的版本同步，也就是丢失了。 但这种情况是可以在之前的版本信息中找回的（因为如果没有交到版本库里就根本就无法拉取远程库，只有交到版本库了才能拉取），因此可以认为git是没有丢失信息的风险的。 Github设置SSH加密watch：可理解为“观察”项目，对于一个项目，默认自己处于Not watching的状态，当你选择Watching，表示你以后会关注这个项目的所有动态，这个项目以后只要发生变动，如被别人提交了pull request、被别人发起了issue等等情况，你都会在自己的个人通知中心，收到一条通知消息，如果你设置了个人邮箱，那么你的邮箱也可能收到相应的邮件。因此watch只用来关注一些你特别在意的项目，若watch得太多通知可能会爆炸… Star：可理解为“关注”或“点赞”，表示喜欢这个项目。同时github会记录你所有Star的项目，因此Star还可以作为“收藏”功能来用。 fork：可理解为把项目“叉”过来，当选择fork，项目会拷贝到你的repositories中，你自己就有了一份原项目的拷贝，当然这个拷贝只是针对当时的项目文件，如果后续原项目文件发生改变，你必须通过其他的方式去同步。使用fork的场景：修改开源项目时使用fork，这样你就可以在原项目的基础上，对项目进行修改，并可通过pull request来将修改提交给原作者，如果作者merge了，你就成为这个项目的主人之一了~ clone： 团队协作流程：负责人创立一个组织（organization），其他人加入组织，分配权限，之后在这个组织下创建仓库（respository），所有人都向这个仓库提交代码。关于权限设置：可以在organization范围内设置权限，即设置成员的write/owner等的权限；也可以针对respository设置权限，即将成员的ssh key公钥(id_rsa.pub)，在res内保存公钥，成员即可对这个仓库提交代码。关于公钥和私钥：公钥是给外界的，私钥是只自己所有。公钥私钥的主要作用是验证身份，因为只有特定人有权限向仓库提交代码。你在提交时用你的私钥加密，别人用你的公钥就可以验证确实是你（因为私钥只有你自己有）。","categories":[],"tags":[{"name":"Git","slug":"Git","permalink":"https://renli1024.github.io/tags/Git/"}]},{"title":"数学基础知识","slug":"mathematics/数学基础知识","date":"2018-06-25T00:15:00.000Z","updated":"2019-07-31T09:28:48.017Z","comments":true,"path":"2018/06/25/mathematics/数学基础知识/","link":"","permalink":"https://renli1024.github.io/2018/06/25/mathematics/数学基础知识/","excerpt":"这篇博客的目的在于整理下大学前的数学预备知识，希望通过这次梳理对数学的基础能有更系统的认识，算是温故知新吧。let’s go!","text":"这篇博客的目的在于整理下大学前的数学预备知识，希望通过这次梳理对数学的基础能有更系统的认识，算是温故知新吧。let’s go! ## 函数、方程和不等式初等几何平面几何立体几何基础概率知识","categories":[],"tags":[{"name":"Mathematics","slug":"Mathematics","permalink":"https://renli1024.github.io/tags/Mathematics/"}]},{"title":"概率论与数理统计笔记","slug":"mathematics/概率论与数理统计笔记","date":"2018-06-25T00:14:00.000Z","updated":"2019-07-31T09:17:38.144Z","comments":true,"path":"2018/06/25/mathematics/概率论与数理统计笔记/","link":"","permalink":"https://renli1024.github.io/2018/06/25/mathematics/概率论与数理统计笔记/","excerpt":"最近在学习数据挖掘、机器学习的相关算法时，感到统计知识的应用还是非常广泛且重要的，因此决定从新温习一遍概率论和数理统计，为进一步学习数据挖掘打下基础。","text":"最近在学习数据挖掘、机器学习的相关算法时，感到统计知识的应用还是非常广泛且重要的，因此决定从新温习一遍概率论和数理统计，为进一步学习数据挖掘打下基础。 绪言 概率论数学的一个分支，研究如何定量描述随机现象及其规律。 数理统计以数据为研究对象，包括数据的收集、整理、分析和建模，从而对随机现象的某些规律进行预测或决策。 第一章_随机事件与概率 三个基本概念样本空间：随机试验中所有可能结果的集合称为样本空间，记为S。样本点：S中的单个元素称为样本点，也称为基本事件。随机事件：样本空间S的子集，称为随机事件，一个随机事件可以包含多个基本事件。 事件的相互关系（若有事件A和事件B） 名称 记法 含义 合事件 \\(A\\cup B\\) A、B至少有一个发生 积事件 \\(A\\cap B\\) 或简写为 \\(AB\\) A、B同时发生 差事件 \\(A-B\\) A发生且B不发生 互斥事件/不相容事件 \\(AB=\\phi\\) AB不能同时发生 对立事件/逆事件 \\(\\bar{A}\\) \\(A\\cup \\bar{A} = S\\)，\\(A\\cap \\bar{A} = \\phi\\) 注1：差事件有多种表示方法，如\\(A-B = A\\bar{B} = A-AB\\)注2：区分\\(\\overline{AB}\\)和\\(\\bar{A}\\bar{B}\\)，\\(\\overline{AB}\\)表示A、B不同时发生(可单独发生)，\\(\\bar{A}\\bar{B}\\)表示A、B都不发生 重要的事件运算定律结合律： \\(A\\cup (B\\cap C) = (A\\cup B)\\cap (A\\cup C)\\) \\(A\\cap (B\\cup C) = (A\\cap B)\\cup (A\\cap C)\\)德摩根律： \\(\\overline{A\\cup B} = \\bar{A}\\cap \\bar{B}\\) \\(\\overline{A\\cap B} = \\bar{A}\\cup \\bar{B}\\)注1：事件运算很多时候可通过画维恩图来表示注2：两个公式都可扩展到多事件的情况 频率与概率频率\\(f_n(A)\\)：表示事件A发生的次数占试验总次数的比例。$$f_n(A) = \\frac {n_A} {n}$$概率\\(P(A)\\)：当实验次数增加时，频率的稳定值称为概率。$$P(A) = lim_{n \\rightarrow \\infty} f_n(A)$$ 概率的性质对事件A和事件B(1). \\(P(B-A) = P(B)-P(AB)\\)。若\\(A \\subset B\\)，则有\\(P(B-A) = P(B)-P(A)\\)(2). \\(P(A \\cup B) = P(A)+P(B)-P(AB)\\)(3). \\(P(\\bar{A}) = 1-P(A)\\) 古典概型两个特征：样本空间S中样本点有限(有限性) &amp; 每一个样本点的概率相等(等可能性)。因此计算概率有：$$P(A) = (A所包含的样本点数)/(S中的样本点总数)$$注1：古典概率只需要计算不同事件对应的样本点个数即可。注2：因为样本点个数有限，所有情况可枚举，因此古典概型经常转化为排列组合的问题求解。 补充排列组合公式排列：$$A_n^m = n(n-1)\\cdots(n-m+1)$$组合：$$C_n^m = A_n^m/m!$$$$C_n^m = C_n^{n-m}$$ 条件概率P(B|A)表示在事件A发生的前提下，事件B发生的概率。计算方法：\\(P(B|A) = \\frac {P(AB)} {P(A)} \\)，事件A的发生改变了样本空间。注：注意区分P(AB)和P(B|A)，前者是在整个样本空间下计算，是“原始”的概率；后者是在A的样本空间下计算，是“二次影响”后的概率，条件概率即表征一种影响程度。 乘法公式(计算多个事件同时发生的概率)$$P(AB) = P(A)\\cdot P(B|A) = P(B)\\cdot P(A|B)$$$$P(ABC) = P(A)\\cdot P(B|A)\\cdot P(C|AB)$$ 全概率公式定义划分：若有(1). \\(B_1\\cup B_2\\cup \\cdots\\cup B_n = S\\)(2). \\(B_iB_j = \\phi,i\\not=j\\)则称\\(B_1,B_2,\\cdots,B_n \\)为S的一个划分。计算A事件概率就有：$$P(A) = \\sum_{j=1}^n P(AB_j) = \\sum_{j=1}^n P(B_j)P(A|B_j)$$公式的直观理解：“由因求果”，B1,B2…代表引起事件A发生的各种原因，因此事件A发生的总概率就是各种原因下发生概率的加和。 贝叶斯公式\\(B_1,B_2,\\cdots,B_n \\)为S的一个划分，$$P(B_i|A) = \\frac {P(B_iA)} {P(A)} = \\frac {P(A|B_i)P(B_i)} {\\sum_{j=1}^n P(A|B_j)P(B_j)}$$P(B)称为先验概率，代表根据以往经验得到的引起某件事发生的原因的概率。P(B|A)称为后验概率，代表事情已经发生，求这件事发生是由某个因素引起的可能性的大小。公式的直观理解：“执果寻因”，观测某事件已经发生，求导致该事件发生的各种原因的概率。影响后验概率的有两个因素，一个是原因本身的概率P(B)，另一个是原因引起结果的概率P(A|B)，只有当各原因引起结果的概率有差别时，贝叶斯公式才有意义，否则计算出的仅仅就是各原因概率的比例而已。两个影响因素对结果的共同作用大，求出的后验概率P(B|A)就会大，这也是符合直观认知的。此外，后验概率还代表着根据实际情况对先验概率的“修正”：通常情况下，依照经验求得的先验概率不会太准确，这时就需从实际中寻找相关事实对其进行修正。更多贝叶斯公式的讲解：贝叶斯公式的直观理解(先验概率/后验概率) 事件的独立性定义：满足\\(P(AB) = P(A)P(B)\\)，则称事件A与事件B相互独立。若\\(P(A)&gt;0,P(B)&gt;0\\)，则有\\(P(B|A) = P(B)\\)（这个公式理解起来更直观些）。直观理解：在一次实验中，一个事件的发生不会影响到另一个事件发生的概率。注1：事件的独立性\\(\\not=\\)互斥性。互斥性指事件不可能同时发生，即\\(P(AB)=0\\)；独立性指一个事件的发生不会影响到另一个事件发生的概率，即\\(P(AB)=P(A)P(B)\\)。在维恩图中，互斥事件没有交集，而独立事件则可以有交集，只是交集占B圈的概率与A圈占总体的概率相等罢了。注2：若多个事件相互独立，则有\\(P(ABC) = P(A)P(B)P(C)\\)，但注意$$\\left.\\begin{align}P(AB)=P(A)P(B) \\\\P(AC)=P(A)P(C) \\\\P(BC)=P(B)P(C)\\end{align}\\right\\rbrace\\not\\Rightarrow P(ABC)=P(A)P(B)P(C)$$即两两独立不能推出相互独立，因为相互独立还要求满足\\(P(ABC)=P(A)P(BC)\\)。 第二章_离散型随机变量 随机变量定义：样本空间S，样本点e，若\\(X=X(e)\\)为定义在S上的实值单值函数，则称\\(X(e)\\)为随机变量，简写为\\(X\\)。注1：随机变量虽然叫变量，但实际是一个函数，是样本点到实数的一种映射。注2：引入随机变量的原因，是为了将无法量化的随机事件用具有实际意义的数值来表示，便于量化研究随机现象的规律。如在抛硬币实验中，可将实验结果用“正面出现的次数”来表示。注3：随机变量本质是函数，也要满足函数的性质，可以多个样本点对一个实数值，但不能一对多。注4：随机变量一般用大写字母\\(X,Y,Z\\)或希腊字母\\(\\eta,\\xi\\)来表示，且都将\\(X(e)\\)简写为\\(X\\)，直接用\\(X\\)来表示映射后的实数值。 离散型随机变量若随机变量X的取值为有限个或可数个，则称X为离散型随机变量。“可数”指其中的元素可以被一一数到。(元素数可以是无限个，如整数集、正奇数集等，都是可数的)离散型随机变量的分布律：所有随机变量对应的概率，叫做分布律。需要满足两个条件：非负性 &amp; 加和为1。三种常见的离散分布：0-1分布、二项分布、泊松分布、几何分布。 0-1分布若X的分布律满足就称X服从参数为p的0-1分布(或两点分布)，即为\\(X\\sim 0-1(p)\\)或\\(X\\sim B(1,p)\\)其分布律可写为：$$P(X=k)=p^k(1-p)^{1-k},k=0,1$$ 伯努利实验(Bernoulli)设A是一随机事件，且\\(P(A)=p(0&lt; p &lt;1)\\)。若仅考虑事件A发生与否，就可定义一个服从参数p的0-1分布的随机变量X：$$ X=\\left\\{\\begin{align}0 &amp; , &amp; 若A发生 \\\\1 &amp; , &amp; 若A不发生(即\\bar{A}发生)\\end{align}\\right.$$来描述这个随机实验的结果。这种只有两个可能结果的实验，称为伯努利实验。注1：将伯努利实验独立重复地进行n次，就称为n重伯努利实验。注2：设X表示n重伯努利实验中事件A发生的次数，则X的可能取值为0,1,…,n，概率为\\(P\\{X=k\\}=C_n^kp^k(1-p)^{n-k}\\)。 二项分布(Binomial)定义：若随机变量X的概率分布律为$$P\\{X=k\\}=C_n^kp^k(1-p)^{n-k},k=0,1,\\cdots,n$$即称X服从参数为n,p的二项分布，记为\\(X\\sim B(n,p)\\)。n代表进行伯努利实验的次数，p代表一次实验中事件A发生的概率。二项分布作用：描述n重伯努利实验中，事件发生的次数。注：0-1分布也是一种特殊的二项分布，即只进行一次伯努利实验。 泊松分布(Poisson)设随机变量\\(X\\)的取值为0,1,2,…，而取各个值的概率为$$P\\{X=k\\}=\\frac {\\lambda^ke^{-\\lambda}} {k!},k=0,1,2,…$$其中\\(\\lambda&gt;0\\)且是常数，则称\\(X\\)服从参数为\\(\\lambda\\)的泊松分布，记为\\(X\\sim \\pi (\\lambda)\\)证明其满足分布律的两条件：对于非负性，明显满足；对于加和为1性质，有：$$\\sum_{k=0}^\\infty P\\{X=k\\}=\\sum_{k=0}^\\infty \\frac {\\lambda^ke^{-\\lambda}} {k!}=e^{-\\lambda}\\sum_{k=0}^\\infty \\frac {\\lambda^k} {k!}=e^{-\\lambda}\\cdot e^\\lambda = 1$$注1：上式证明所涉及定理：$$e^x=1+x+\\frac {x^2} {2!}+\\cdots+\\frac {x^k} {k!}+\\cdots$$注2：若某事件以固定强度\\(\\lambda\\)，随机且独立地出现，该事件在单位时间内出现的次数可认为服从泊松分布。如公共汽车站到达的乘客数，一本书一页中的印刷错误数等。注3：不同参数\\(\\lambda\\)的泊松分布概率图，横坐标为k值，纵坐标为概率值更多泊松分布的解释见：泊松分布的现实意义是什么？注4：二项分布与泊松分布的近似关系：当\\(n&gt;10,p&lt;0.1\\)时，$$C_n^k(1-p)^{n-k}\\approx \\frac {e^{-\\lambda}\\lambda^k} {k!}, \\lambda=np. $$即当\\(n\\)很大而\\(p\\)很小，且\\(np\\)大小适中时，可用泊松分布来近似二项分布。因为\\(n\\)很大时，二项分布公式中\\(C_n^kp^k(1-p)^{n-k}\\)计算次方和阶乘会很麻烦，因此用泊松来近似。 几何分布(Geometric)定义：若\\(X\\)的概率分布律为：$$P(X=k)=p(1-p)^{k-1},k=1,2,3,\\cdots$$则称\\(X\\)服从参数为\\(p\\)的几何分布，记为\\(X\\sim Grom(p)\\)。用处：在重复多次的伯努利实验中，实验进行到某种结果出现第一次为止，此时实验总次数服从几何分布。 第三章_连续型随机变量 分布函数如果随机变量不是离散型的，分布律就无法描述其取值规律了，因此引入分布函数，分布函数对所有类型的随机变量都适用。定义：随机变量X，对任意实数x，称函数\\(F(x)=P(X\\le x)\\)为X的概率分布函数，简称分布函数。几何意义：表示X落到\\((-\\infty , x)\\)区间上的概率。如何表示落到任意区间的概率：$$ \\begin{align}P(a&lt;X\\le b) &amp;=P(X\\le b)-P(X\\le a) \\\\&amp;=F(b)-F(a)\\end{align}$$ 概率密度对于随机变量\\(X\\)的分布函数\\(F(X)\\)，若存在非负函数\\(f(x)\\)，使对于任意实数\\(x\\)有：$$F(x)=\\int_{-\\infty}^x f(t)dt$$则称\\(X\\)为连续型随机变量，其中\\(f(x)\\)称为\\(X\\)的概率密度函数，简称概率密度。 概率密度的性质性质1：\\(f(x)\\ge 0\\)性质2：\\(\\int_{-\\infty}^{+\\infty} f(x)dx=F(+\\infty)=1 \\)性质3：概率密度函数的面积值表示概率（分布函数是y值表示概率）$$P(x_1 &lt; X\\le x_2)=\\int_{x_1}^{x_2} f(t)dt$$因此当\\(x_1,x_2\\)重合的时候，面积为0，概率也为0，因此连续型随机变量中任意单点概率都为0，但并非是不可能事件，即不可能事件\\(\\Rightarrow\\)概率为0，概率为0\\(\\not\\Rightarrow\\)不可能事件。性质4：若\\(f(x)\\)在点\\(x\\)连续，则有\\(f(x)=F’(x)\\)。$$\\begin{align}&amp;f(x)=F’(x)=\\lim_{\\Delta x \\rightarrow 0} \\frac {F(x+\\Delta x)-F(x)} {\\Delta x}=\\lim_{\\Delta x\\rightarrow 0} \\frac {P(x&lt;X\\le x+\\Delta x)} {\\Delta x}&amp;\\\\\\\\&amp;P(x&lt;X\\le x+\\Delta x)\\approx f(x)\\cdot \\Delta x\\end{align}$$表明\\(X\\)落在点\\(x\\)邻域附近的概率近似等于\\(f(x)\\cdot \\Delta x\\) 对性质4的说明：下图是某概率密度函数图中\\(f(x_2)&lt;f(x_1)\\)，但这并不表明\\(x_1\\)点的概率比\\(x_2\\)点的概率大(单点概率都为0)，其表明\\(f(x_2)\\cdot \\Delta x&lt;f(x_1)\\cdot \\Delta x\\)，即\\(X\\)落在\\(x_1\\)附近的概率比落在\\(x_2\\)附近的概率大。同理，在此图中，\\(X\\)落在\\(0\\)附近的概率是最大的。 均匀分布(Uniform)若\\(X\\)的概率密度函数为$$f(x)=\\left\\{ \\begin{align} &amp;\\frac {1} {b-a},&amp;x\\in (a,b)\\\\ &amp;0,&amp;其他 \\end{align}\\right.$$就称\\(X\\)服从\\((a,b)\\)上的均匀分布，记为\\(X\\sim U(a,b)\\)。概率密度函数图如下：注1：均匀分布的直观理解就是“均匀”的，具有等可能性，即对于任意的\\(a&lt;k&lt;k+l&lt;b\\)，有$$P(k&lt; X&lt; k+l)=\\int_{k}^{k+l} \\frac {1} {b-a}dt=\\frac {l} {b-a} $$\\(X\\)落入\\((a,b)\\)中任意子区间上的概率，只与区间长度有关，与区间位置无关。注2：均匀分布的分布函数为：$$F(x)=\\left\\{ \\begin{align} &amp;0, &amp;x&lt; a;\\\\ &amp;\\frac {x-a} {b-a}, &amp;a\\le x&lt; b;\\\\ &amp;1, &amp;x\\ge b. \\end{align}\\right.$$图像如下所示： 指数分布 高斯分布","categories":[],"tags":[{"name":"Mathematics","slug":"Mathematics","permalink":"https://renli1024.github.io/tags/Mathematics/"}]},{"title":"计算机网络笔记（第一部分）","slug":"Network/计算机网络1","date":"2018-05-28T00:14:00.000Z","updated":"2018-07-01T14:21:13.000Z","comments":true,"path":"2018/05/28/Network/计算机网络1/","link":"","permalink":"https://renli1024.github.io/2018/05/28/Network/计算机网络1/","excerpt":"","text":"本篇笔记主要包括概述、物理层和数据链路层这三章的内容。 概述 三类网络电信网络：向用户提供电话、电报、传真等服务；有限电视网络：向用户传送各种电视节目；计算机网络：使用户可以在计算机之间传数据，由若干结点(node)和连接这些结点的链路(link)组成。注：三类网络中起到核心作用是计算机网络，且有相互融合的趋势，即所谓的“三网融合”的概念。 互联网基本概念Internet的含义Internet指当前全球最大的、由众多网络相互连接而成的特定计算机网络，采用TCP/IP协议族作为通信规则，前身是美国的ARPANET。我们生活中的“上网”，即是指将某个电子设备连接到Internet。而关于Internet的译名，有以下两种：因特网：这是全国科学技术名词审定委员会推荐的译名，虽然准确，但未被广泛使用；互联网：使用最广泛的Internet译名，也更能体现出Internet的主要特征（连通性），因此《计算机网络》一书第七版之后都采用了这个译名，本笔记也是采用这种译名。注1：Internet是计算机网络的代表，但并不等于计算机网络(还有很多其他类型的网络)。注2：Internet相当于是“网络的网络”，其将全球众多的计算机网络相互连接起来。注3：小写的internet，指“互连网”，任意将若干计算机网络连接起来，可以通信就行；而大写的Internet是专有名词，特指全球最大的那个“互联网”。 互联网的架构当前互联网是多层次ISP的架构，ISP(Internet Service Provider)为互联网服务提供商，负责建造通信线路，从互联网管理机构申请IP地址并分配给用户，分为主干ISP、地区ISP和本地ISP（移动、联通、电信即国内三大主干ISP）。示意图如下：IXP：为了提升网络传输速率，出现了互联网交换点IXP(Internet eXchange Point)，使用数据链路层的网络交换机来实现。其主要作用是允许两个网络直接相连传输数据，而无需再通过ISP转发（如上图两个地区ISP之间的IXP），这样可使得互联网的数据流量分布更合理，减少传输时延。 互联网的组成虽然互联网的拓扑结构非常复杂，但总体可以分为两大块：边缘部分：由所有连接在互联网上的主机(host)组成，这部分是用户可以直接接触到的，用来进行数据传输。核心部分：由大量网络和连接这些网络的路由器组成，这部分是为边缘部分提供服务的。边缘部分主机的通信方式：可分为两大类：客户-服务器方式(C/S方式)和点对点方式（P2P方式）。C/S方式中，客户端是服务请求方，主动向服务器发起通信，因此必须知道服务端的地址；而服务端是服务提供方，被动地等待各地的客户端的请求，因此服务端无需知道客户端的地址。P2P方式中，只要两台主机都运行了对等连接软件（P2P软件），它们就可以平等地进行通信，没有客户端和服务端的区分，也可理解为每台主机既是客户端也是服务端。 互联网核心部分的数据交换方式互联网核心部分主要作用是交换、传输数据，有三种交换方式。电路交换：电话的连接方式，两台电话要进行通信，必须经过“建立连接（占用通信资源）-&gt;通话（一直占用通信资源）-&gt;释放连接（归还通信资源）”三个阶段，两台电话间会建立一条专用的物理线路，通信时会一直占用，通信线路的利用较低。报文交换：运用了存储转发的原理，整个数据报文先传送到相邻结点，全部存储下来后查找转发表，再转发到下一个结点。分组交换：同样运用了存储转发(stroe and forward)的原理，将数据报文分成多个小的分组，每个分组在首部加上必要的控制信息，单独地在互联网中进行传输。当路由器收到一个分组后，先暂时存储一下，检查其首部，查找转发表，按照首部中的目的地址，找到合适的接口转发出去(路由算法得出)，把分组交给下一个路由器，分组就这样一步步地到达目的地。 三种交换方式的比较：1、对于电路交换，是整个比特流连续地从原点直达终点，因此需要建立专用传输线路，如果要传送大量连续数据（传送时间远大于连接建立时间），则电路交换的效率较高；2、对于报文交换和分组交换，不需要预先分配传输资源，因此非常适合传输计算机网络这种突发性的数据。另外报文传输是直接传输整个报文，因此时延比分组交换大，且如果报文中出了一点错，整个报文都要重传，开销会很大。3、分组交换的优点：高效，对通信线路是逐段占用的，可以充分利用通信资源；灵活，每一个分组都可选择最适合的路由线路进行转发；可靠，当链路中某一结点出现故障，路由算法会自动选择合适的线路。4、分组交换的缺点：使用存储转发(stroe and forward)的方式，分组在各个路由结点会有排队问题，产生一定的时延；分组必须携带的首部会产生一定的开销。 计算机网络分类按网络的作用范围分： 广域网WAN(Wide Area Network)：作用范围为几十到几千公里； 城域网MAN(Metropolitan Area Networl)：城域网的作用范围一般是一个城市； 局域网LAN(Local Area Network)：局域网在地理上局限在较小的范围内(1km左右)； 个人区域网PAN(Personal Area Network)：在个人工作的地方把个人使用的电子设备（如笔记本电脑）用无线技术连接起来，如蓝牙技术。按网络使用者分： 分为公用网(public network)和专用网(private network)。用来把用户加入到互联网的网络： 这种网络叫接入网AN(Access Network)，处于从用户到互联网中第一个路由器之间的一种网络。在互联网初期，用户用电话线拨号接入互联网，速率很低，目前使用了接入网技术来连接，速率了有很大的提升。 计算机网络的性能指标速率：指比特率(bit/s)，并非Byte，而且多指额定速率。带宽：传统的带宽指的是频带宽度，单位是HZ。而在计算机网络中，带宽指网络的最高发送速率。吞吐量：单位时间内通过网络的实际数据量，指实际速率。注：在存储领域，1k=1024；而在通信领域，1k=1000。往返时间：往返时间RTT(Round-Trip Time)表示双向交互一次所需要的时间。信道利用率：指信道有多长时间是被利用的（有数据通过），空闲的信道利用率为0。注：信道利用率并非越大越好，利用率增大，时延也会增加。 网络时延时延是指数据从网络的一端传送到另一端所花费的时间，网络时延由以下几部分组成：发送时延：主机或路由器发送数据帧所花费的时间，发生在网卡中。$$发送时延=\\frac {数据帧长度(bit)} {发送速率(bit/s)}$$传播时延：电磁波在信道中传播所花费的时间，发生在信道中。$$传播时延=\\frac {信道长度(m)} {电磁波在信道中的传播速率(m/s)}$$信号传播速率与信道有很大关系，如光纤、铜线等等。处理时延：在交换结点分组转发所需的时间，如分析首部、进行差错检验等，没有具体的计算公式。排队时延：分组在路由器的缓存队列中排队等待的时间，同样没有具体的计算公式。因此网络总时延就是以上四种时延之和：$$总时延=发送时延+传播时延+处理时延+排队时延$$注：高速网络链路，提高的是发送速率(带宽)，并不能提高传输速率。如我们所说的光纤传输速率高，是指可以用很高的速率向光纤信道发送数据，而光纤信道的传播速率实际上比铜线还要低。时延带宽积：时延带宽积=传播时延 X 带宽，如时延带宽积为\\(2\\times 10^5bit\\)，相当于当发送的第一个比特到达终点时，发送端已经发送了20万个比特，而这20万个比特都未还在传输过程中，因此时延带宽积也表示从发送端发出的但尚未到达接收端的比特数。 计算机网络体系结构无论哪种网络体系结构，都采用了“分层”的思想，目前主要有两种体系：OSI和TCP/IP，OSI非常权威，但因为过于复杂，更多被当作一种理论参考，工程上未广泛应用；运用最广泛的是TCP/IP协议，也是事实上的“国际标准”。OSI协议为7层，TCP/IP协议有4层，谢书中采用的是两者的结合版，即一种5层的网络结构。 五层协议结构应用层：应用层协议定义的是进程间的交互规则，因为主机间通信的本质是主机上进程的通信（进程即为正在运行的程序）。具体的应用层协议有DNS、HTTP等。应用层数据单位：报文(message)。运输层：运输层负责为主机进程间的通信提供通用的数据传输服务，目前主要有两种协议：传输控制协议TCP和用户数据报协议UDP，TCP提供面向连接、可靠的数据传输服务，UDP提供无连接的、尽最大努力的数据传输服务。运输层数据单位：TCP为报文段(segment)，UDP为用户数据报。网络层：网络层负责分组交换网的数据传输服务，使用IP协议。与运输层的不同在于：运输层针对互联网的边缘部分，网络层针对互联网的核心部分，路由器在转发时最高就涉及到网络层，不涉及运输层和应用层。网络层数据单位：IP数据报（就是之前所说的分组）。数据链路层：数据链路层负责分组交换网中相邻结点的数据传输，与网络层的不同在于：网络层是源结点到目的结点(中间可能有多个结点)，而数据链路层是相邻结点。数据链路层数据单位：帧(framing)。物理层：负责物理硬件层面的数据传输，物理层数据单位：比特(bit)。注：数据从上层到下层需要加首部，加上相关控制信息。另外，从网络层-&gt;链路层还要加尾部（做差错校验的工作）。 物理层 物理层的主要任务物理层研究的是如何在各种传输媒体上传输比特流，如各个物理接口的尺寸、接口电缆上电压的范围、各种编码方式等，而不是具体的传输媒体（这属于通信领域的范畴）。 物理层传输媒介导引型(有线)：双绞线、同轴电缆、光纤非导引型(无线)：自由空间 信道 信道的基本概念信道指向某一个方向传送信息的媒体，是单向的，因此一条通信线路往往包含一条发送信道和一条接收信道。单工通信（单向通信）：只能有一个方向通信，如收音机。半双工通信（双向交替通信）：通信双方都可以发送信息，但不能同时发送，如对讲机。全双工通信（双向同时通信）：通信双方可以同时发送/接收信息。注：单工通信只需一条信道，半双工和全双工通信需要两条信道。 调制为什么要进行调制：来自信源的信号不适合进行长距离传输。基带调制：数字信号-&gt;另一种数字信号（没有变为模拟信号），也称为编码。具体有如下几种：不归零编码：正电平代表1，负电平代表0。归零编码：正脉冲代表1，负脉冲代表0。曼彻斯特编码：位周期中心向上跳变代表0，位周期中心向下跳变代表1。差分曼彻斯特编码：位开始边界有跳变代表0，位开始边界没有跳变代表1。带通调制：数字信号-&gt;模拟信号（加到载波上）。具体有如下几种：调幅(AM)：载波的振幅随基带数字信号变化。调频(FM)：载波的频率随基带数字信号变化。调相(PM)：载波的初始相位随基带数字信号变化。 信道的极限传输速率如何提高数据在信道上的传输速率是一个被广泛关注的问题，大致可从以下几个方面来考虑：信道能通过的频率范围：由奈氏准则可知，在任何信道中，码元传输的速率都是有上限的，传输速率超过此上限，就会出现严重的码间串扰问题，因此可通过拓宽频带，来提高码元传输速率的上限。奈氏准则公式：$$极限波特率(baud/s)=2W\\times log_2n$$\\(W\\)为频带宽度，\\(n\\)为一个码元可表示几种值，\\(log_2n\\)即为一个码元携带的信息量。注意区分码元和比特的区别，1码元可以由多个bit位表示。信噪比：$$信噪比(dB)=10\\times log_{10}(S/N)$$\\(S\\)为信号的平均功率，\\(N\\)为噪声的平均功率。香农公式：信道的极限信息传输速率C为：$$C=W\\times log_2(1+S/N)$$C为比特率bit/s，W为信道的带宽(Hz)。由公式可知，信道带宽越大，信噪比越高，信息的极限传输速率就越高。比特率和波特率换算：$$比特率(bit/s)=波特率(baud/s)\\times 码元信息量$$ $$码元信息量=log_2n$$\\(n\\)为一个码元可表示几种值。奈氏准则的具体表示？奈氏准则和香农公式的换算？ 信道复用技术频分复用(FDM)：在同一时间占用不同的频带资源。时分复用(TDM)：在不同时间占用相同的频带资源，类似时间片轮转。统计时分复用(STDM)：与TDM的不同在于，其并非固定顺序分配时间，而是按需动态分配。波分复用(WDM)：光的频分复用，用一根光纤同时传输多个光载波信号。码分多址(CDMA)：具体介绍如下。 码分多址(CDMA)各个用户使用经过挑选的不同码型，相互之间不会造成干扰，因此用户可在同一时间使用同样的频带进行通信。具体原理如下：码片：在CDMA中，每个用户被分配一个m位的码片序列(由+1和-1组成)，用户若要发送比特1，则直接发送这个m位码片序列；若要发送0，则发送该码片序列的反码。如码片序列为(-1-1-1+1+1-1+1+1)，则1对应的就是(-1-1-1+1+1-1+1+1)，0对应的就是(+1+1+1-1-1+1-1-1)，这个m位序列才是最终的发送结果。码片正交：码片的一个重要特点是，各个用户所分配的码片是正交的，如S代表某用户的码片，T代表其他用户的码片，两个码片正交，则有：$$S\\cdot T = \\frac {1} {m} \\sum_{i=1}^m S_iT_i=0$$即两码片按位相乘最后结果为0。信号处理：不同用户码片合到一起发出去，若想从中分离出用户X的信号，则首先拿到X的码片，和收到的信号做内积运算(按位乘法)，结果为1：比特为1，结果为-1：比特为0，结果为0：其他用户的信号。按照这个方法即可把其他用户的信号剔除掉。 宽带接入技术用户要连接到互联网，必须先连接到ISP，以便获得上网所需的IP地址，因此即出现了宽带接入技术。我国之前多采用电话线+调制解调器(Modern，猫)的方式拨号上网，因速度有限而被逐渐淘汰，目前主流宽带接入方式的有三种。ADSL技术：ADSL(Asymmetric Digital Subscriber Line)，非对称数字用户线路，可直接利用原有的电话线路，无需从新布线，用户使用专门的Modern即可上网，且为电信专线，网速较稳定。光纤同轴混合网(HFC网)：基于有线电视网开发的宽带接入网，在传送电视节目的同时提供宽带服务。将原先有线电视网中的同轴电缆主干部分改换为光纤，一直延申到相应光纤结点后，光信号转换为电信号，再通过同轴电缆将信号传送到用户家庭。要使现有的模拟计算机能够接收数字电视信号，需要使用一个称为机顶盒(set-top box)的设备，同时机顶盒大多内嵌了一个叫电缆调制解调器的设备，通过此设备用户即可接入宽带。FTTx技术：最理想的宽带接入方式是光纤到户FTTH(Fiber To The Home)，将光纤一直铺设到用户家庭，只有在光纤进入家门后，才把光信号转换为电信号，这样做就可使用户获得最高的上网速率。但限于价格和用户需求等问题，光纤到户目前还未被广泛使用，但其衍生出了很多宽带光纤接入方式，称为FTTx，即Fiber To The…，x代表不同的光纤接入地点，即光电转换的地方。目前大中城市较普及的是光纤接入到楼（FTTB）或小区（FTTZ），再通过网线接入用户家，从而为整幢楼或小区提供共享带宽。 数据链路层 数据链路层两种信道类型点对点信道：点对点通信方式（一对一），最常用的协议是PPP协议，多用于住宅主机的拨号上网。广播信道：广播通信方式（一对多），因为主机数较多，必须用专用的共享信道协议(CSMA/CD)来协调主机间的数据发送，多用于局域网。 链路和数据链路链路：无源的点到点的物理线路段，中间没有任何其他的交换结点。数据链路：物理链路+通信协议，即硬件+软件。 数据链路层的三个基本问题 封装成帧(framing) 透明传输 差错检测 封装成帧概念：在一段数据的前后分别添加首部和尾部，就构成了一个帧。首部和尾部的作用是进行帧定界，即确定帧的开始和结束。具体实现：用控制字符完成帧定界，将控制字符SOH(Start Of Header)放在帧的首部表示帧的开始，将控制字符EOT(End Of Transmission)表示帧的结束。 透明传输“封装成帧”的问题：如果数据中的某个字节的二进制代码恰好和SOH或EOT一样，帧就会错误地开始或结束。因此要对帧的数据部分出现的控制字符进行处理。处理方法：字符填充(也称字节填充)，在帧数据部分的SOH/EOT前插入一个转义字符，这样接收时就不会把其当作控制字符来处理（防止帧提前结束掉），最后在数据送向网络层时删去转义字符即可。注：如果转义字符也出现在数据当中，就在转义字符前也加一个转义字符。 差错检测问题背景：数据传输中可能会产生比特差错：1变成0或0变成1，因此要采用差错检测措施。循环冗余码CRC：重点！具体算法见《计算机网络》P74注1：使用循环冗余码只能做到无比特差错，但还做不到可靠传输（CRC只能做到接受的帧都没有错误）。注2：可靠传输包括两部分：无比特差错 &amp; 无传输差错。传输差错指帧丢失、帧重复和帧失序，要做到无传输差错，则必须要有确认和重传机制（由上层协议完成）。 MAC层为了制订一个通用的协议模型，IEEE802委员会将数据链路层又拆分成了两个子层：介质访问控制子层(MAC)：MAC层，负责与传输介质相关的部分，将相关操作封装好共LLC透明调用。逻辑链路控制子层(LLC)：LLC层，负责逻辑控制，与传输介质无关，不管采用何种协议对LLC层都是透明的。 MAC层地址在局域网中，每个网络适配器（网卡）都会有一个唯一的硬件地址，称为MAC地址。MAC地址位数是48位，高24位为IEEE向网卡厂商分配，低24位为厂商自行指派。在局域网外部传输，使用IP地址查找主机；进入局域网后，即是查找MAC地址。 MAC帧格式MAC帧数据部分长度范围：46-1500。整个MAC帧长度范围：64-1518，首部和尾部总共18字节。最大传送单元MTU：指MAC帧中数据部分的最大长度，为1500。 以太网 局域网和以太网的区别以太网是一种局域网，而局域网却不一定是以太网，只是由于目前大多数的局域网是以太网，所以一般说局域网，大家都默认为以太网。所谓以太网，是一种总线型局域网，局域网的拓扑结构有很多实现方式，还有有星型、环形等，但目前应用最广泛的局域网标准还是以太网。 以太网的通信特点 和其他种类局域网中的传播方式相同，采用广播的方式。 无连接的工作方式，也没有确认和重传机制，因为局域网的通信质量较好，发生错误的几率较小。 收到有差错的数据帧就丢弃，但不做纠错，纠错工作交给上层协议。因此以太网提供的服务是不可靠的交付。 发送的数据使用的是曼彻斯特编码，位周期中心向上跳变代表0，位周期中心向下跳变代表1 CSMA/CD定义：载波监听多点接入/碰撞检测(Carrier Sense Multiple Access with Collision Detection) ，是以太网上的一种通信协议。多点接入：一根总线上解入多个计算机。载波监听：指发送数据之前要先检测总线上是否有其他计算机在发送数据，如果有，则暂时不要发送数据，以免发生碰撞。碰撞检测：检测信道上数据是否发生了碰撞。若发生碰撞，信号就会产生严重的失真，因此一旦检测出碰撞，计算机就会立即停止发送数据，等待一段随机时间后再重新发送。而且也因为信号会发生碰撞，所以以太网只能进行半双工通信，而不能全双工。 CSMA/CD中的碰撞检测因为电磁波在信道上传播的速率是有限的，因此当监听到总线是空闲的时，总线可能并非真正的空闲（对方的信号正在信道上传输，还没传过来），因此不仅是在发数据前要检测碰撞，在发送数据的期间也要进行检测。由图可知，先发送数据的计算机，在发送后至多经过\\(2\\tau\\)时间（两倍的端到端往返时延），就可知道发送的数据帧是否遭受了碰撞。所以\\(2\\tau\\)就称为争用期，只有经过争用期这段时间还没有检测到碰撞，才能肯定此次发送不会发生碰撞。以太网取\\(51.2\\mu s\\)为争用期长度，对于10Mbit/s以太网，在争用期内可发送 512 bit，即64字节。因此若发生冲突，一定是在发送的前64字节之内。所以以太网规定最短有效帧长为64字节，凡长度小于64字节的帧都是由于冲突而异常中止的无效帧。 二进制指数退避算法发生碰撞的站在停止发送数据后，要推迟（退避）一个随机时间才能再发送数据。基本的退避时间为\\(2\\tau\\)，之后从集合\\([0, 1, … , (2^k-1)]\\)中随机取一个数，记为r，重传所需的时延就是r倍的基本退避时间。参数\\(k\\)的计算：\\(k=Min[重传次数, 10]\\)。当重传达16次仍不能成功时即丢弃该帧，并向上层报告。 强化碰撞检测到碰撞后，立即停止发送数据，之后继续发送若干比特的人为干扰信号，以便让所有用户都知道现在已经发生了碰撞。 扩展以太网集线器：用集线器将多个碰撞域组合成一个碰撞域。网桥：用网桥将各网段隔离为单独的碰撞域，网桥工作在数据链路层，其根据MAC地址对收到的帧进行转发。以太网交换机：相当于多接口网桥。 连接不同网络的中间设备物理层：集线器Hub，会扩大碰撞域，而且没法抑制广播风暴。数据链路层：交换机。网络层：路由器，由于历史的原因，许多有关 TCP/IP 的文献将网络层使用的路由器称为网关。交换机和路由器的不同：交换机连接的是主机，路由器连接的是网络。","categories":[],"tags":[{"name":"Network","slug":"Network","permalink":"https://renli1024.github.io/tags/Network/"}]},{"title":"计算机网络笔记（第二部分）","slug":"Network/计算机网络2","date":"2018-05-28T00:13:00.000Z","updated":"2018-07-01T13:45:49.000Z","comments":true,"path":"2018/05/28/Network/计算机网络2/","link":"","permalink":"https://renli1024.github.io/2018/05/28/Network/计算机网络2/","excerpt":"","text":"本笔记是基于学校所教授的课程和谢希仁《计算机网络》(第七版)整理的，包括概述、物理层和数据链路层这三章的内容。 第一章 概述第二章 物理层第三章 数据链路层第四章 网络层 网络层的主要任务网络层承担着主机找主机的任务(跨越多个链路节点)，向运输层提供无连接的、尽最大努力交付的数据报服务。网络层及以下提供的都是无连接、不可靠的传输服务，通信的可靠性由运输层来保证。因此网络层中的路由器可以做得比较简单，大大降低了网络造价。本章主要包括IP及其配套协议、路由选择协议两大块内容。 网际协议IP网际协议IP是TCP/IP体系中两个最主要的协议之一，与IP协议配套使用的还有三个协议： 地址解析协议 ARP(Address Resolution Protocol) 网际控制报文协议 ICMP(Internet Control Message Protocol) 网际组管理协议 IGMP(Internet Group Management Protocol) IP地址及其编址方法IP地址概念：为每个连接在互联网上的主机（或路由器）分配一个在全世界范围是唯一的32位的标识符。IP地址三种编址方法：分类IP地址、划分子网、构成超网。 分类IP地址将IP地址划分为若干类，每一类IP地址都由网络号(net-id)和主机号(host-id)两部分组成，网络号标志着所连接到的网络，主机号即标志着主机，同一个网络中的主机网络号都相等。整个IP地址采用点分十进制表示法，每８位为一组。常用的三类IP地址：A类地址，网络数\\(2^7-2\\)，0号表示“本网络”，127号作测试用；主机数\\(2^{24}-2\\)，扣除全0和全1的主机号，全0表示网络地址，比如一台主机的IP地址为5.6.7.8，那么该主机所在的网络地址就是5.0.0.0；全1表示表示该网络上的所有主机，多在广播时使用。B类地址，网络数\\(2^{14}-1\\)，保留128.0.0.0，不指派；主机数\\(2^{16}-2\\)，扣除全0和全1。C类地址，网络数\\(2^{21}-1\\)，保留192.0.0.0，不指派；主机数\\(2^8-2\\)，扣除全0和全1。IP地址的重要特性： 路由器转发分组时仅依据目的主机所连接的网络号，不考虑主机号，这样做可大大减少路由表的大小。 IP地址实质是标志主机/路由器和链路的接口，因此当一个主机同时连接到两个网络上时，该主机就必须同时具有两个相应的IP地址。由于一个路由器至少应当连接两个网络，因此一个路由器至少有两个IP地址。 IP地址和硬件地址硬件地址：即MAC地址，数据链路层和物理层使用的地址。IP地址：网络层和以上各层使用的地址，是一种逻辑地址（称IP地址是逻辑地址是因为IP地址是用软件实现的）。注：路由器是根据目的主机的IP地址进行转发的，因此路由器的IP地址并不会出现在IP数据报中，路由器之间使用的是MAC地址。 地址解析协议ARP作用：将IP地址解析为MAC地址。ARP Cache：ARP高速缓存，存储IP地址和MAC地址的映射关系。当主机A欲向同一局域网中某个主机B发送IP数据报时，先在其ARP高速缓存中查看有无主机B的MAC地址。如有，就将此硬件地址写入MAC帧，然后通过局域网将该MAC帧发往此硬件地址。如没有，主机A就在本局域网上广播发送一个ARP请求分组。收到ARP响应分组后，将B的硬件地址写入其ARP高速缓存中，再发送数据。注1：注意解析是单向的，并不能由MAC地址解析到IP地址。注2：解析只能在同一个局域网中进行，不同的局域网要先通过路由器把IP数据报发到下一个网络，由下一个网络再查找。 IP数据报格式IP数据报由首部和数据两部分组成。首部的前一部分是固定长度，共20字节，是所有IP数据报必须具有的。在固定部分的后面是一些可选字段，其长度是可变的，不经常使用。 字段名称&nbsp;&nbsp;&nbsp; 位数&nbsp;&nbsp;&nbsp; 含义 版本&nbsp;&nbsp;&nbsp; 4&nbsp;&nbsp;&nbsp; IP协议的版本，大部分为IPv4 首部长度&nbsp;&nbsp;&nbsp; 4&nbsp;&nbsp;&nbsp; 固定部分+可变部分的总长度，一个单位为4字节，因此首部最长为15*4=60字节 区分服务&nbsp;&nbsp;&nbsp; 8&nbsp;&nbsp;&nbsp; 一般不使用 总长度&nbsp;&nbsp;&nbsp; 16&nbsp;&nbsp;&nbsp; 首部+数据部分总长度，最大为65535字节 标识&nbsp;&nbsp;&nbsp; 16&nbsp;&nbsp;&nbsp; 标识一个IP数据报 标志&nbsp;&nbsp;&nbsp; 3&nbsp;&nbsp;&nbsp; 只有前两位有意义，第一位是MF(MF=1，后面还有分片；MF=0，最后一个分片)，第二位是DF(DF=0才允许分片) 片偏移&nbsp;&nbsp;&nbsp; 13&nbsp;&nbsp;&nbsp; 分片后某片在原分组中的相对位置 生存时间&nbsp;&nbsp;&nbsp; 8&nbsp;&nbsp;&nbsp; 记为TTL(Time To Live)，指示数据报在网络中可通过的路由器数的最大值 协议&nbsp;&nbsp;&nbsp; 8&nbsp;&nbsp;&nbsp; 指出此数据报使用的何种协议，指出应交给上层哪一个进程 首部检验和&nbsp;&nbsp;&nbsp; 16&nbsp;&nbsp;&nbsp; 只检验数据报的首部，不检验数据部分，采用二进制反码求和算法(考试不作要求) 注：片偏移是从数据部分开始计算的，且是以8个字节为单位，因此时要除以8。 路由器分组转发算法注1：整体思路，是否同网段-&gt;特定主机路由-&gt;是否有可到的路由-&gt;默认路由注2：路由表中指出的是到某个网络应当先到哪个某个路由器，即下一跳的路由器。 划分子网是对分类IP编址方法的改进，将IP地址由两级划分为三级，从主机号借用若干个位作为子网号subnet-id。划分子网的优点：减少了IP地址的浪费，使网络的组织更加灵活，更便于维护和管理。注：划分子网纯属一个单位内部的事情，对外透明，即仍表现为没有划分子网的一个网络。 子网掩码子网掩码的作用是找出IP地址中的子网部分，子网掩码中1对应着网络号/子网号，0对应着主机号。计算方法：将IP地址和子网掩码做与操作，即可得到网络号。注：子网中主机号全0用于表示子网本身，全1用于广播，因此子网可用主机数=总地址数-2。 无分类编址CIDR(构造超网)使用各种长度的网络前缀(network-prefix)来代替网络号和子网号。具体记法：128.14.32.0/20表示的地址块共有\\(2^{12}\\)个地址，最小地址为128.14.32.0，最大地址为128.14.47.255。注1：CIDR消除了传统A类、B类和C类地址以及划分子网的概念，因而可以更加有效地分配IPv4的地址空间。注2：CIDR中仍然使用掩码，网络前缀的值即为掩码中1的个数。 CIDR构造超网把多个小前缀的地址块合并成一个大前缀的地址块，这个合并过程叫路由聚合，由此产生的大地址块称为超网。 CIDR匹配规则最长前缀匹配：CIDR在查找路由表时可能会得到不止一个匹配结果，应选择具有最长网络前缀的那项。因为网络前缀越长，其地址块就越小，因而路由就越具体 。 网际控制报文协议ICMP由主机和路由器用于网络层面的信息通信，属于IP层协议，包括差错报告和回送请求和回答报文。差错报告：不可达主机，网络，端口，协议。询问报文：回送请求和回答报文 &amp; 时间戳请求和回答报文。ICMP应用：ping命令，负责测试两个主机间的连通性。属于应用层，但越过了传输层，直接调用网络层的ICMP协议。使用了ICMP询问报文中的回送请求和回答报文 路由选择协议内部网关协议：RIP和OSPF外部网关协议：BGP注：网关即可理解为路由器 内部网关协议RIP路由信息协议 RIP (Routing Information Protocol)是一种分布式的、基于距离向量的路由选择协议，要求网络中的每一个路由器都要维护从它自己到其他所有网络的距离信息。距离的定义：直接连接的网络距离为1，每经过一个路由器，距离数+1，即相当于拓扑图中的边数。 RIP的特点 RIP总是选择距离最短的路由线路，哪怕存在另一条距离长但低时延的线路。 RIP中距离最大只能为15，距离为16表示目的地不可达，因此其只适用小型网络。 路由器仅和相邻的路由器交换信息，且交换的是路由表的全部信息，交换遵循一个固定的时间间隔。(跟谁交换，交换什么，什么时候交换) RIP路由表建立过程具体的路由表更新算法如下： RIP存在的问题好消息传播得快，坏消息传播得慢，出了故障会要花较长的时间才能通知到全网。每次交换的是完整路由表，开销较大。最大距离的存在限制了网络的规模。 内部网关协议OSPF开放最短路径优先OSPF(Open Shortest Path First)路由表更新时：和网络中的所有路由器交换信息（洪泛法），交换的是相邻路由器的链路状态，有更新时才交换，全网广播的方式。（跟谁交换，交换什么，什么时候交换） 第五章 运输层 运输层协议概述运输层提供的是进程到进程间的通信服务因为一台主机经常有多个应用进程同时有通信需求，表明运输层有一个很重要的功能——复用和分用。运输层提供两种协议：TCP和UDP TCP和UDP的对比 特点 TCP UDP 全称 传输控制协议(Transmission Control Protocol) 用户数据报协议(User Datagram Protocol) 数据单位 TCP报文段 用户数据报 是否建立连接 面向连接 无连接 可靠性 可靠 不可靠，尽最大努力 与应用层的数据接口 面向字节流，不需规定特定的数据格式 面向报文，上层的报文加上首部就传出去了 开销 较大 较小 传输速率 不如UDP高 高 适用场景 可靠性要求高的场景，如文件传输 可靠性要求不高的场景，如视频会议、IP电话 端口号端口号标识了本计算机应用层中的各进程，通过IP地址+端口号就可以找到主机中的进程。 用户数据报协议UDPUDP只在IP数据报服务上增加了很少一点的功能：复用、分用和差错检测UDP主要特点： 无连接的，减少传输开销，因此也不需要使用套接字。 面向报文，对于应用层交下来的报文，加上UDP首部后即进行发送，不合并也不拆分。对于IP层传上来的报文，也是去掉首部后直接交给应用层，不做修改。 没有拥塞控制 支持一对一、一对多、多对一和多对多的交互通信。 首部只有8字节，开销很小 缺点：报文大小不容易控制，容易超长被拆分。 传输控制协议TCP 面向连接的传输，“连接”是TCP协议提供的一种抽象，连接的两端点被称为套接字，套接字由端口号和IP地址拼接而成。 只能一对一通信，提供全双工通信方式 面向字节流：虽然应用程序和TCP的交互是一次一个数据块，但TCP把应用层交下来的数据仅仅看成是一串无结构的字节流。而且TCP不保证接收方和发送方的数据块完全一致，但保证字节流序列是完全一致的，怎样对字节流进行分块传输由TCP试网络情况决定。 TCP可靠传输的工作原理停止等待协议连续 ARQ 协议 停止等待协议每发送完一个分组就停止发送，等待对方的确认，收到确认后再发送下一个分组。现假设A向B发送数据超时重传机制：A对每一个已发送的分组都设置了一个超时计时器，若在规定时间段内没有收到B的确认，就重新发送分组。像这种自动重传的机制称为自动重传请求ARQ。确认丢失：B收到了A的分组，但向A发送的确认在中途丢失了，因此A会向B重传分组，B此时要做的事：丢弃分组，重新发送确认。确认迟到：B向A发送的确认迟到了，A会重发分组，并收到重复的确认。因此A要丢弃重复的确认，B要丢弃重复的分组。 TCP流量控制TCP的流量控制是用滑动窗口机制实现的：接收方根据自己的容量的大小设置接收窗口大小，然后将设的值以“窗口”字段的形式发给发送方，发送方根据这个值设置发送窗口的大小，从而实现流量控制。具体窗口怎么动：发送窗口表示在没有得到对方确认的情况下，可以把窗口内的所有数据都发出去。收到确认后，窗口会向后移，具体移动的位置根据确认序号来确定。 报头8位UDP支持一对多，TCP只支持一对一为什么要三报文握手、为什么四报文握手，一定要会！防止失效链接报文突然传到，会导致错误。（简答题） 第六章 应用层 域名服务器 域名服务器DNS负责域名到IP地址的解析工作 最基本的管辖单位是“区”而非“域”，区可以等于域，也可以小于域。 每一个区设置相应的权限域名服务器，用来保存该区中的所有主机的域名到IP地址的映射。此外最下层还有本地域名服务器。 域名服务器解析过程 在本地域名服务器中查找，递归的方式，本地若查不到，本地服务器就会作为DNS客户，向根服务器发出查询请求。 本地服务器向根服务器发查询请求，分为两种：迭代和递归。迭代：根域名服务器不会什么都管，只负责告诉你去找谁；递归：所有的事情根服务器帮你搞定，帮你访问顶级域名服务器、权限域名服务器，最后把结果返回给你。递归方式用得较少，因为这样根域名服务器太累。具体图示见PPT FTP文件传输服务FTP采用客户端服务器模式，使用TCP的可靠运输服务，而且建立了两个TCP连接，一个是控制连接，一个是数据连接。控制连接控制各种FTP请求，数据连接负责数据传输服务。 邮件服务主要构成部分：用户代理(客户端软件)、邮件服务器、邮件协议。所用到的协议有：发邮件：SMTP简单邮件传送协议，收邮件：POP3(Post Office Protocol)和IMAP(Internet Message Access Protocol)网际报文存取协议 邮件发送步骤 发件人使用用户代理撰写要发送的邮件。 发件人的用户代理把邮件用SMTP协议发给发送方邮件服务器。 邮件服务器把邮件临时存放在邮件缓存队列中，等待发送。 发送邮件服务器与接收方邮件服务器建立连接，然后把邮件发出去。 接收方邮件服务器收到邮件后，把邮件放入收件人的用户邮箱中，等待收件人进行读取。 收件人在打算收信时，就运行PC机中的用户代理，使用POP3或IMAP协议读取邮件。 基于万维网的邮件服务：用浏览器发送，用户和邮件服务器之间是HTTP协议，邮件服务器之间是SMTP。 第七章 网络安全层 网络攻击的类别被动攻击：主要是截获，即从网络上窃听他人的通信内容，又称为流量攻击。主动攻击：主要包括： 篡改：故意篡改网络上传送的报文。 恶意程序：包括计算机病毒、计算机蠕虫、特洛伊木马和逻辑炸弹、后门入侵等。 拒绝服务：如分布式拒绝服务。指攻击者向互联网的某个服务器不停发送大量分组而导致该服务器无法正常工作。在信息的安全领域中，对付被动攻击的重要措施是加密，而对付主动攻击中的篡改和伪造则要用鉴别。 两类加密体制对称密钥密码体制和公钥密码体制。 对称密码体制加密和解密的密钥是相等的，用同一把钥匙加密和解密，密钥是保密的，但加密算法是公开的。因为两边密钥都是一样的，无法确定改了之后是谁改的。虽然安全性不高，但加密效率高。 公钥密码体制加密密钥和解密密钥不一样，公钥、算法都公开，只有收信方的私钥是保密的。为保证以下三点：(1) 报文鉴别——接收者能够核实发送者对报文的签名；(2) 报文的完整性——发送者事后不能抵赖对报文的签名；(3) 不可否认——接收者不能伪造对报文的签名。出台了数字签名的概念。 数字签名 数字签名的工作原理：(1) 因为除A外没有别人具有私钥，所以除A外没有别人能产生这个密文。因此B相信报文X是A签名发送的。(2) 若A要抵赖曾发送报文给B，B可将明文和对应的密文出示给第三者。第三者很容易用A的公钥证实A确实发送X给B。(3) 反之，若B将X伪造成X‘，则B不能在第三者前出示对应的密文，这样就证明了B伪造了报文。 鉴别体制对付主动攻击中的篡改和伪造要用鉴别，鉴别报文的真伪性，分为两类：实体鉴别和报文鉴别。实体鉴别：又称为端点鉴别，鉴别报文确实是对方发的。报文鉴别：包含端点鉴别和报文完整性鉴别，除了鉴别报文是否是对方发的，还要鉴别报文中途是否被篡改，即是可靠的消息源发出的可靠消息。","categories":[],"tags":[{"name":"Network","slug":"Network","permalink":"https://renli1024.github.io/tags/Network/"}]},{"title":"TCPIP笔记","slug":"Network/TCPIP","date":"2018-05-26T00:14:00.000Z","updated":"2018-06-18T07:57:42.000Z","comments":true,"path":"2018/05/26/Network/TCPIP/","link":"","permalink":"https://renli1024.github.io/2018/05/26/Network/TCPIP/","excerpt":"","text":"本笔记是主要是根据学校《TCP/IP和网络软件编程》课的课件整理的，因为部分内容与计算机网络课重合，因此笔记只记录了计算机网络课上没讲的内容，主要作补充之用，更详细的内容可见《计算机网络》笔记。 第一章 TCP/IP协议概述TCP/IP协议起源于ARPNET，ARPNET最初用于国防网络研究。随着连入ARPNET的电脑数量增加，就需要一种新的网络通信协议来管理，TCP/IP就出现了。TCP/IP协议主要分为两部分：检测网络中传输差错的传输控制协议TCP，负责对不同网络进行互连的协议IP。 TCP/IP的体系结构TCP/IP协议采用了分层的思想，将网络系统按功能分为四层，称为协议栈，每一层都向它的上层提供服务，并使用下层所提供的功能。从下到上为网络接口层、网络层、传输层、应用层。网络接口层：协议栈的最底层，表示能够传输数据的物理网络。网络层：主要功能是将源主机上的IP数据报发到另一台主机，端到端的通信，主要协议是IP协议。两大块内容：IP地址和路由选择。IP层提供的是一种“尽力而为”的传输服务，并不是可靠传输。传输层：应用进程间的通信应用层：提供面向用户的网络服务，如HTTP/DNS等。 Internet整体架构Internet整体可看成是由三个级别的网络组成，国家主干网-地区级网络-企业或校园网，三层网络通过路由器连接起来。 TCP/IP中的封装和解封传输数据时，从首部开始，由上到下依次通过协议栈的每一层，直到数据被当作一串比特流送入物理网络，其中每一层对收到的数据都会增加一些首部信息，称为封装/打包。接收数据时，从下到上通过协议栈的每一层，每一层会对数据首部进行提取和处理，称为解封/拆包。 OSI七层模型会话层：在传输层的基础上提供应用进程间的会话控制机制，包括建立和维持会话、同步会话等。表示层：不同的计算机体系结构所使用的数据表示法不同，表示层就为异构的计算机通信提供一种公共表示方法。应用层：面向用户，包含使用网络服务的各种应用程序。注：OSI强调严格的层次划分，因此灵活性较差；TCPIP更强调功能分布而非层次划分，因此其更为灵活，但也因此层次间的分界不是那么明晰。 网络与通信相关组织机构ISO：国际标准化组织(International Organization for Standard)，是目前最大的国际标准化组织。ITU：国际电信联盟(International Telecommunication Union)，研究电信领域的技术、业务和资费问题，并制定国际标准建议。IEEE：电子电气工程师协会(Institute of Electrical and Electronics Engineers)，是国际电子电信行业最大的专业学会，网络与通信中很多标准就是IEEE制订的，如IEEE 802.2：局域网中逻辑链路层的控制协议；IEEE 802.11系列：无线通信的系列协议标准。ELA：美国电子工业协会(Electronic Industries Association)，其制订的最著名的标准是目前在PC机和通信设备上广泛使用的RS-232接口。RFC文档：请求评价文档(Request for Comments)，针对一些协议和建议标准的征求意见稿。 第二章 网络接口层和网络层物理层 传输介质有线介质：同轴电缆、双绞线(使用RJ45接头)、光缆；无线介质：IEEE 802.11系列标准。 同步传输与异步传输同步传输：通信过程中发送方和接收方在时间上保持步调一致，如：何时检测跳变信号、上升沿还是下降沿、检测频率是多少等。同步传输在发数据前先发送一串同步字符SYN，接收方只要检测到两个以上的SYN，就可以确认已进入同步状态，双方即在同一时钟频率下工作了。这种方式仅在数据开始传送前添加控制字符SYN，因此传送连续、大量数据的效率比异步传输高。异步传输：把各个字符分开传输，字符与字符间插入起止信息，通信双方无需同步频率(依靠检测起止位来接收数据)，适合传送不连续的、突发的信息。 信道复用频分复用(FDM)：在同一时间占用不同的频带资源。时分复用(TDM)：在不同时间占用相同的频带资源，类似时间片轮转。统计时分复用(STDM)：与TDM的不同在于，其并非固定顺序分配时间，而是按需动态分配。波分复用(WDM)：光的频分复用，用一根光纤同时传输多个光载波信号。码分多址(CDMA)：根据不同编码方式来复用。 数据链路层 基本概念物理层上的第一层，提供基本的流量控制和差错校验功能，将不可靠的物理链路变为可靠的数据链路(无比特差错)。 局域网地理范围、互连设备有限的计算机网络，多由单一组织机构建。基本组成：服务器：为局域网提供服务，如资源共享服务。网路适配器/网卡：NIC(Network Interface Controller)，提供通信连接，发送和接受数据。相关协议软件、驱动程序 网络层 网络层的两种连接方式面向连接：在路由器上建立固定的线路，好像在通信的源和目标之间建立了一条逻辑通路，称为虚电路，接收端会收到顺序严格一致的数据分组。无连接：源端和目标端之间没有逻辑通路，但是送入网络的每一个分组都带有完整的目标主机地址，路由器会根据目标地址和当前网络状况选择合适的线路。IP协议实现了无连接的通信，TCP协议实现了面向连接的通信。为什么这样设计？IP无连接保证了网络层的简单和灵活、TCP面向连接保证了传输的质量。 网络互连技术网络互连主要通过路由器来实现，将异构网络连接起来，构成一个整体同一的互联网。路由转发算法：见《计算机网络》笔记。路由器实现的功能：1、为网际通信选择合适的路由线路；2、根据需要对数据包进行拆分和组装；3、将使用不同协议的网络连接起来，构成统一的互联网；4、网络安全，目前大部分路由器具备一定的防火墙功能。 IP协议IP互联网中的计算机没有主次之分，唯一标识主机的是IP地址，因此各主机地位平等。IP互联网没有确定的拓扑结构。每个接入互联网的设备都需要有IP地址，因此路由器、网关也会有IP地址，主机至少有一个IP地址（实质是一个网卡一个IP地址）。 IP数据报数据在内存中字节序：大端模式，高字节在低地址，低字节在高地址；小端模式：低字节在低地址，高字节在高地址。IP数据报传输的字节序：最高位在左记为第0位，最低位在右记为第31位。网络传输时，先传0-7位，再传24-31位。各标志字段具体作用见《计算机网络》笔记 IP数据报的分片和重组网络在进行数据传输时，对帧的最大长度会有限制，这个限制被称为最大传输单元MTU。不同网络的MTU值可能不同，如果主机通信要经过多个网络，通常取最小的MTU值，被称为路径MTU，以太网的MTU为1500（数据链路层帧加头加尾最长为1518）。若IP数据报的长度大于MTU，则IP层就需要对IP数据报分片，不同分片：标识字段相同，标志字段都是DF=0，MF=1后面还有分片，MF=0后面没有分片。 ICMP协议Internet控制报文协议(Internet Control Message Protocol)，介于网络层和传输层之间，作为IP协议的补充而存在。主要有两类消息：Error，错误信息；Informational，消息/咨询性质。ICMP报文封装在IP数据报中传输，但一般不认为其是高层协议，因为：ICMP仅传送差错与控制信息，且处理都需要IP层来执行，因此把它看作是IP层的补充协议。 ICMP报文的特点ICMP差错报文都是由路由器发送到源主机的（向源主机报告差错信息）。ICMP差错报文只负责报告，不负责对各类差错采取什么处理措施。ICMP差错报文是伴随着抛弃出错的IP数据报而产生的（如TTL减为0时，路由器将丢弃数据报，返回ICMP差错报文）。ICMP差错报文不享有任何优先权。 其他TCPIP课中IP地址没讲CIDR，其他和计算机网络课内容相同，具体内容参见计算机网络笔记 第三章 运输层 端口号的分配端口号：16位二进制数(0-65535)，分为保留端口号和自由端口号。保留端口号：0-1023，系统保留，用户一般不适用其中0-255为一些众所周知的服务，如21-FTP，23-Telnet，80-HTTP等。256-1023通常由Unix服务占用，提供一些特殊的Unix服务。1024以上为自由端口号，由程序进行通信之前动态地向系统申请。 TCP各字段作用建立连接为什么三报文握手？理论上三次是能够在不可靠信道上双方达成一致的最小值。 第四章 Socket编程Socket为一种网络编程规范，具体指网络通信的逻辑端点，由IP地址+端口号组成，位于传输层与应用层之间。通信时应用程序将数据写入Socket中，Socket通过网卡将信息发送到另一台主机的Socket，再传到相应的接收方应用程序，即完成了通信。 TCP通信过程1234567891011121314151617181920212223242526272829#服务端#第一步：初始化Socketimport socketHOST = 'xxx.xxx.xxx.xxx'PORT = xxxs = socket.socket(socket.AF_INET, socket.SOCK_STREAM) # SOCK_STREAM表明是TCP模式#第二步：Socket与地址、端口号绑定s.bind((HOST, PORT))#第三步：监听请求消息s.listen(1)#第四步：接收请求消息conn,address = s.accept()#第五步：收发数据#从缓冲器获得数据,参数为最大读取数量raw = conn.recv(100)#第六步、关闭连接s.close()#客户端import socketHOST = 'xxx.xxx.xxx.xxx'PORT = xxxs = socket.socket(socket.AF_INET, socket.SOCK_STREAM)c.connect((HOST,PORT))# 发送数据, 必须是byte类型的的数据# 使用encode函数,将字符串通过UTF8编码为字节类型c.send('Hello World!'.encode())c.close() UDP通信过程1234567891011121314151617181920# 服务端import socket HOST = '127.0.0.1'sPORT = 9976cPORT = 9975s = socket.socket(socket.AF_INET,socket.SOCK_DGRAM) # SOCK_DGRAM表明是UDP模式s.bind((HOST,sPORT))# 此函数一直阻塞当前线程, 直到收到数据# 返回值：(b'Hello From UDP', ('127.0.0.1', 9975))，给出了收到的数据以及来源信息(IP地址和端口号)s.recvfrom(100)# 客户端import socket HOST = '127.0.0.1'sPORT = 9976cPORT = 9975c = socket.socket(socket.AF_INET,socket.SOCK_DGRAM)c.bind((HOST,cPORT))c.sendto('Hello By UDP'.encode(), (HOST,sPORT))Out[12]: 14 三种不同类型的Socket：1、流套接字(SOCK_STREAM)：使用TCP来实现，提供可靠的、面向连接的传输服务，适用于大批量的数据2、数据报套接字(SOCK_DGRAM)：使用UDP来实现，无连接、不可靠的数据传输服务，数据以独立报文的形式发送，效率高，适合出现差错可能性小的网络。3、原始套接字(SOCK_RAW)：可以读写内核没有处理的IP数据报。因为流套接字只针对TCP协议，数据报套接字只针对UDP协议，若要传输其他协议发送的数据必须用原始套接字。 阻塞和非阻塞通信模式对于发送端：都是阻塞模式，即如果底层协议没有足够的空间存放数据，则应用程序会一致等待。对于接收端：在阻塞模式下，若没有到达的数据，则I/O会一直阻塞等待着数据到达；在非阻塞模式下，应用程序定时查询或者有数据到达时通知程序处理。注：因为UDP没有发送缓冲，因此即使在阻塞模式下也不会发生阻塞，即UDP没有真正的阻塞模式。 关闭Socket在TCP中，关闭连接比建立连接更为关键，因为涉及到两方向数据传输的断开。如果一方直接调用.close()函数，会直接将所有数据都断掉，另一方若还有数据则无法发送。因此采用半关闭的方式，之关闭一部分数据交换中的流，如无法发送数据，但还可以接收数据。 TCP/IP网络应用 DNS地址信息查询实现域名-&gt;IP地址的转换，DNS服务由域名空间、域名服务器和解析器三部分组成。 Telnet远程登陆协议远程登陆系统需要具备的条件：一个本地系统、一个远程系统、本地系统和远程系统间可以相互通信、本地系统的用户在远程多用户系统中由用户账号、本地系统和远程系统可能是不同的操作系统，因此Telnet要能运行在不同的操作系统上。Telnet工作模式：Telnet采用C/S模式，通过TCP进行通信，服务端为23端口。1、本地客户提出远程登陆请求，通过三次握手与远程系统建立连接。2、客户端Telnet向远程Telnet发数据（通过TCP协议），远程Telnet收到数据后，并不直接处理数据，而是将数据转发给内核，由内核进行处理。3、同时远程Telnet也接收服务端要传送的数据，发给客户端。 Email服务采用了SMTP协议，通过TCP进行通信，服务端为25端口。客户端邮件服务器和接收端邮件服务器建立TCP连接后，通过各种命令实现邮件服务。 FTP文件传输协议FTP用来把一台主机上的文件传到另一台主机上，基于C/S模式，通过TCP进行通信。 www服务和http协议www和http的关系：www：www是World Wide Web的缩写，也可以简称为Web，中文为“万维网”。是一个由许多互相链接的超文本组成的系统，通过互联网传输数据，系统中的资源由URL地址来唯一标识和访问。www主要是提供基于浏览器的Web服务，并不等同互联网，万维网只是互联网所能提供的服务其中之一（还有很多其他服务如FTP、Telnet、邮件服务等等）。http：http是HyperText Transfer Protocol的缩写，译为超文本传输协议。其设计主要是为了提供一种传输HTML页面的标准（HTML：超文本标记语言，与HTTP超文本传输协议是对应的），用于浏览器和网页服务器之间交换数据，所有的www文件都必须遵守这个标准。如一般网址前https://www.baidu.com都会有http/https。https：安全套接字层超文本传输协议，数据不再是明文传输，更为安全。原理：在http的基础上加入了SSL协议，SSL依靠证书来验证服务器的身份，并为浏览器和服务器之间的通信加密。工作流程：1、用户在浏览器中输入网页的URL地址2、浏览器向DNS服务器发出请求，请求解析URL地址3、DNS服务器解析完成，向浏览器返回解析后的IP地址4、浏览器向对应IP地址的80端口（HTTP端口）发出建立TCP连接的请求，连接建立后即可进行数据传输。 IO复用与并行程序IO复用示例代码[转]1234567891011121314151617181920212223242526272829303132333435363738import socket, select s=socket.socket() print('s:',s) host=socket.gethostname() port= 4321s.bind((host,port)) s.listen(5) #设置监听对象，最初只有当前主机（还未与客户端建立连接） inputs=[s] while True: # select函数阻塞当前线程,直到监听列表的对象发生改变 # select输入参数：可读列表，可写列表，异常列表 # select返回参数：发生改变的对应列表 rs,ws,es=select.select(inputs,[],[]) for r in rs: # 如果服务器套接字被触发，表明是出现建立新连接的请求 # 第一次触发肯定是建立新连接的情况 if r is s: c, addr = s.accept() print('Got connection from', addr) # 将新建的socket加入监听列表 inputs.append(c) # 如果客户端套接字被触发，表明是有数据传来 else: try: data = r.recv(1024) # 接收数据 disconnected = not data except socket.error: disconnected = True if disconnected: # data为空，表明数据已传完，断开连接，将对象移除监听列表 print(r.getpeername(),'disconnected') inputs.remove(r) else: print(data) 进程和线程进程是资源分配的单位，线程是调度运行的单位，线程共享同一进程的资源。进程可理解为操作系统所完成的任务，线程表示完成该任务的许多可能的子任务。创建进程：fork()函数，只在Linux平台下有，Win下没有。创建当前进程的副本，函数之后的语句通过fork()函数返回的pid来判断是是父进程or子进程，子进程：0，父进程：子进程的进程号。在子进程中，gval复制为11，lval复制为25。最后输出结果为：Child Proc: 27, 13Parent Proc: 23, 9","categories":[],"tags":[{"name":"Network","slug":"Network","permalink":"https://renli1024.github.io/tags/Network/"}]},{"title":"Network & Data Center Management Revision","slug":"Network/N & DCM","date":"2018-05-26T00:13:00.000Z","updated":"2019-05-29T00:20:06.704Z","comments":true,"path":"2018/05/26/Network/N & DCM/","link":"","permalink":"https://renli1024.github.io/2018/05/26/Network/N & DCM/","excerpt":"","text":"本文介绍了计算机网络和数据中心管理的基础知识, 较偏重概念和理论讲解, 是本人在UWTSD Network &amp; Data Center Management module的课程总结, 也是考试的复习笔记。 ISO Network Model7 Application Layer6 Presentation Layer5 Session Layer4 Transport Layer3 Network Layer2 Data Link Layer1 Physical Layer 应用层：应用层协议定义的是进程间的交互规则，因为主机间通信的本质是主机上进程的通信（进程即为正在运行的程序）。具体的应用层协议有DNS、HTTP等。应用层数据单位：报文(message)。 运输层：运输层负责为主机进程间的通信提供通用的数据传输服务，目前主要有两种协议：传输控制协议TCP和用户数据报协议UDP，TCP提供面向连接、可靠的数据传输服务，UDP提供无连接的、尽最大努力的数据传输服务。运输层数据单位：TCP为报文段(segment)，UDP为用户数据报。 网络层：网络层负责分组交换网的数据传输服务，使用IP协议。与运输层的不同在于：运输层针对互联网的边缘部分，网络层针对互联网的核心部分，路由器在转发时最高就涉及到网络层，不涉及运输层和应用层。网络层数据单位：IP数据报（就是之前所说的分组）。 数据链路层：数据链路层负责分组交换网中相邻结点的数据传输，与网络层的不同在于：网络层是源结点到目的结点(中间可能有多个结点)，而数据链路层是相邻结点。数据链路层数据单位：帧(framing)。 物理层：负责物理硬件层面的数据传输，物理层数据单位：比特(bit)。注：数据从上层到下层需要加首部，加上相关控制信息。另外，从网络层-&gt;链路层还要加尾部（做差错校验的工作）。 Network ManagementFive functional areas of Network Management: Fault Management Configuration Management Security Management Performance Management Accounting Management Fault Management: detcting faults found on the network, isolating and correcting the faults. Preemptive approach is better than reducing downtime. The most widely implemented NM element. Performance Management Monitoring performance aspects of the network including:Downtime, Available Bandwidth, Latency and Broadcast storms. Metrics: Throughput, reponse time, utilization. Maintain them at a certain level, and notify system if level falling. Steps: gather data-&gt;analyze-&gt;set threshold-&gt;monitor. Configuration Management Monitoring network and system configuration, including configuration file, inventory, known naming conventions and so on. Steps: Create Standards-&gt;Implement-&gt;Maintain Documentation-&gt;Validate &amp; Audit-&gt;Review Standards Accounting Management Monitoring usage aspects of the network.(Such as: What services are used? When are the services used and who uses them?) Measuring utilization of all important network resources. Security Management Control access to the network resources(only authorized individuals) and monitor security aspects of the network. Notify administrator if anyone trying to breach security. Network Management ProtocolSNMP(Simple Network Management Protocol)IMPORTANTCMIP(Common Management Information Protocol)RMON(Remote Monitoring) SNMPAn application-layer protocol that provides a message format for communication between SNMP manager sandagents.And it is part of the TCP/IP protocol suite.Three parts of SNMP framework.1.SNMP manager2.SNMP agent3.MIB(Management Information Base) SNMP managerThe system to control and monitor the activities of network hosts. SNMP agentThe software component within the managed device that maintains the data for the device and reports these data.The agent and MIB reside on the routing device (router, access server, or switch). MIB(Management Information Base)The Management Information Base (MIB) is a virtual information storage area for network management information, which consists of collections of managed objects SNMPv3 Two main components: SNMPv3 engine and SNMPv3 applications. SNMPv3 engine: four subcomponentsDispatcher: handles message sending and receiving.Message subsystem: handles message processing.Security subsystem: handles security processing for security model.Access control subsystem: handles the granting/rejecting of access to specific managed objects. SNMPv3 applicationsCommand generators: create SNMP messages.Command responders: respond to SNMP messages.Notification originators, send trap or inform messages.Notification receivers: receive and process trap or inform messages.Proxy forwarders: forward messages between SNMP entity components. Network Management Software SystemTwo major Components: platform and application. Network Management PlatformGoal: To provide generic functionality for managing a variety of network devices. Basic features:Graphical User Interface(GUI)Network Map(discovers the devices on the network and their connectivity, and present overview of network visually)Database Management System(DBMS)Standard Method to Query DevicesCustomizable Menu SystemEvent Log Network Management Application Goals1.Effectively manage a specific set of devices.2.Avoid functionality overlap with the platform.3.Integrate with a platform through the API and menu system.4.Reside on multiple platforms. IPV4 &amp; IPV6Issues of IPV4 Internet routing table expansionInternet core routers require more processing power and overhead. Lack of true end-to-end modelIPv4 networks typically use NAT as the solution to address depletion. Features of IPV6 Larger address spaceIPv6 addresses are 128 bits, compared to IPv4’s 32 bits. Elimination of public-to-private NATEnd-to-end communication traceability is possible. Elimination of broadcast addressesIPv6 now includes unicast, multicast, and anycast addresses. Support for mobility and securityHelps ensure compliance with mobile IP and IPsec standards. Simplified header for improved router efficiency IPv6 routers no longer perform fragmentation.A discovery process is used to determine the optimum MTU (maximum transmission Unit) to use during a given session. Multiple addresses per interfaceAn IPv6 interface can have multiple addresses. Stateless autoconfiguration(IMPORTANT)DHCP is not required because an IPv6 device can automatically assign itself a unique IPv6 link-local address. IPv6 Address地址表示法 采用16进制, 16比特为一组, 总共8组(16*8=128)e.g. 2035:0001:2BC5:0000:0000:087C:0000:000A 省略规则:1.每组开头的0可以省略2.当有多个连0时可用“::”代替e.g. 3FFE:0501:0008:0000:0260:97FF:FE40:EFAB= 3FFE:501:8::260:97FF:FE40:EFAB 组成部分 IPv6包含两个部分: Subnet Prefix &amp; Interface ID, 且Interface ID通常固定为后64位, 前64位表示一些前缀码和子网号 IPv6 Address typesThree Types: Unicast, Multicast and AnycastThree destination scopes: Site-local address(deprecated, no longer supported), Link-Local address, Global unicast address. Link-Local addressUsed for trasmitting packets to the interface on the same local link, not routable off the link.Composed of a link-local prefix of FE80::/10 and a 64-bit interface identifier.tips: An interface can have multiple IPv6 addresses simultaneously configured and enabled on it.one link-local and one or more global unicast address. Global Unicast AddressUsed to transmit in Internet. Consists of a 48-bit global routing prefix, a 16-bit subnet ID and a 64-bit interface ID.The prefixes of addresses are from 2000::/3 (001) to E000::/3 (111) Multicast Addressa replacement for the broadcast address, defined by the prefix FF::/8, an interface can belong to any number of multicast groups.The second octet of the address contains the prefix and lifetime flags, and the scope of the multicast address. Solicited-Node Multicast Addressesdefined by FF02::1:FF and is used for Neighbor discovery (ND) process and Stateless address autoconfiguration. Neighbor Discovery used toDetermine the local-link address of the neighbor.Determine the routers on the link and default route.Actively keep track of neighbor reachability. four message types process examplesee slides Stateledss Autoconfiguration(IMPORTANT)see slidesDupicate Address Detection(DAD) IPv4 Header vs IPv6 Header Multiple extension headers (called a chain) may be included in an IPv6 packet.The number of extension headers is not fixed, so the total length of the extension header chain is variable.Extension headers make the handling of options more efficient.[More information can be found in slides] Wireless LANsBefore installing a wireless router, what are some of the management parameters to be considered? SSIDUnique identifier that wireless clients use to distinguish between multiple wireless networks in the same vicinity. PasswordRequired from the wireless client to authenticate to the AP. Sometimes called the security key. Network modeRefers to the 802.11a/b/g/n/ac/ad WLAN standards. APs and wireless routers can operate in a mixed mode; i.e., it can simultaneously use multiple standards. Security modeRefers to the security parameter settings, such as WEP, WPA, or WPA2. Channel settingsRefers to the frequency bands used to transmit wireless data. Wireless routers and AP can choose the channel setting or it can be manually set. When configuring a wireless router, what the Implemetation Plan steps consists of? Step 1Start the WLAN implementation process with a single AP and a single wireless client, without enabling wireless security. Step 2Verify that the client has received a DHCP IP address and can ping the local, wired default router, and then browse to the external Internet. Step 3Configure wireless security using WPA2/WPA Mixed Personal. Never use WEP unless no other options exist. Step 4Back up the configuration. What does the Smart Wi-Fi setteings enable you to do? Configure the router’s basic settings for the local network. Diagnose and troubleshoot connectivity issues on the network. Secure and personalize the wireless network. Configure the DMZ feature, view connected computers and devices on the network, and set up port forwarding. Name and explain some of the features of the Smart Wi-Fi Tools. Device ListLists who is connected to the WLAN. Personalize device names and icons. Connect devices. Guest AccessCreates a separate network for up to 50 guests at home while keeping network files safe with the Guest Access Tool. Parental ControlsProtects kids and family members by restricting access to potentially harmful websites Media PrioritizationPrioritizes bandwidth to specific devices and applications. Speed TestTests the upload and download speed of the Internet link. Useful for baselining. USB StorageControls access to shared files. Data Centre DesignData centres are designed to host critical computing resources in a centralized place. Multilayer Data Centre NetworkAggregation Layer: Multilayer switches, firewalss, load balancers…Access Layer: Layer2 switch, web and client facing servers… Three demands of data centrescalability(fast and seamless growth), flexibility(support of new service without major overhaul), high availability(predictable uptime) With aid of a diagram explain storage layer and transport layer of the data centre architecture Server FarmThere are three types server farm: Internet, Intranet and extranet. With aid of a diagram explain Internet Server FarmUsers use Internet to access the server farm and rely on the web interface and web browsers.Two types: Dedicated Internet Server Farm &amp; DMZ Server Farm Dedicated Internet Server FarmBuilt to support large-scale Internet-facing applications that support the core business functionBecause of users are located on the Internet and number of likely users is high, Security and scalability are a major concern in this type of server farm. DMZ Server FarmBuilt to support Internet-based applications in addition to Internet access from the enterprise.DMZ Server Farms locate in the demilitarized zone (DMZ) because they are part of the enterprise network yet are accessible from the Internet. Intranet Server FarmIntranet server farms resemble the Internet server farms in their ease of access, yet they are available only to the enterprise’s internal users.Intranet server farms include most of the enterprise-critical computing resources that support business processes and internal applications. Draw the topology diagram of extranet server farmExtranet server farms sit between Internet and intranet server farms, they are accessed only by a selected group of users(e.g. business partners) that are neither Internet- nor intranet-based.The main purpose for extranets is to improve business-to-business communication by allowing faster exchange of information in a user-friendly and secure environment. This reduces time to market and the cost of conducting business. Explain the functionality of server clusteringClustering consists of using multiple-server computers to provide a single application that is virtually running on a single server.The application runs effectively on multiple servers, but the end user thinks he is accessing a single server.Clustering provides both load distribution and high availability. Storage-area networkExplain a Storage-area networkA network whose primary purpose is the transfer of data between computer systems and storage elements and among storage elements.A SAN is a specialized, high-speed network that attaches servers and storage devices.Three key benefits: simplification of the infrastructure, information life-cycle management (ILS), and business continuity. Server Virtualisationserver virtualisation comprises several components working in synergy to deliver a holistic solution.With reference to this expalin the following: Type-1 and Type-2 Hypervisiors Type-1 HypervisorType-1 hypervisors run directly on top of the physical server hardware. Virtual machines run on top, and guest operating systems leverage virtual hardware exposed by the hypervisor.better performance characteristicsExamples: Microsoft Hyper-V, Vmware ESXi, XenServer, and KVM Type-2 HypervisorType-2 hypervisors run as an application on top of the server operating system. Type-2 hypervisors coordinate a call to the physical server resources through the host operating system installed on the server. The actual virtual machines run one level higher.easier implementation and maintenanceExamples: VMware Workstation, VMware Fusion, Oracle VM VirtualBox. Virtual machinesA virtual machine is a software on top of the hypervisor.Virtual machines emulate operation of the physical computing environment and rely on the hypervisor for access to the physical server resources.Guest operating system: The OS run in Virtual machine.Host operating system: the server operating system runs virtual machine. Virtual switchingVirtual switches take care of forwarding the network traffic between the virtual machines residing on the same or different physical hosts.When virtual machines move around the virtualisation layer, virtual switching will also be important to maintain configuration consistency for the virtual machine attachment points. Management toolsThe virtualisation management tool is also referred to as Virtual Machine Manager.They help create, edit, clone, start, stop, and move virtual machines.They help view performance characteristics and utilisation of the VMs, they also provide a programmatic way to interact with server virtualisation environment through APIs. Data Centre ManagementExplain the importance of Data Centre Infrastructure Management(DCIM)The outward expansion and increasing rack density of modern data centre have created serious space and energy consumptions concerns.So we should consolidate and construct large data centres driven by economy of scale benefits.Data Centre should be organised and operated to deliver quality of service reliably, securely and economically.So we need DCIM. State the domains for Data Centre(DC)Facilities: Physical space, power and coolingNetworking: Fiber optic and copper cable plants, LANs, SANs and WANsSystems: Mainframes, servers, virtual servers and storage Name the Data Centre Management(DCM) components and discuss their functions.see the last slides What are the key questions you would ask or the step to take before implemeting and improving a data centre?see the last slides left questions: 交换机, 路由器等设备的符号 总结 case study分析的要点(e.g. no single point failure, redundant components)","categories":[],"tags":[{"name":"Network","slug":"Network","permalink":"https://renli1024.github.io/tags/Network/"}]},{"title":"Cisco Packet Tracer Notes","slug":"Network/Cisco Packet Tracer","date":"2018-05-25T00:14:00.000Z","updated":"2019-01-27T16:21:34.590Z","comments":true,"path":"2018/05/25/Network/Cisco Packet Tracer/","link":"","permalink":"https://renli1024.github.io/2018/05/25/Network/Cisco Packet Tracer/","excerpt":"","text":"Cisco Packet Tracer是一款常用的网络模拟器, 在其中可以构造网路拓扑图, 配置网络设备并模拟网络运行, 本文对该软件的操作及常用的命令进行了介绍. 软件基本操作 左下角是设备栏, 可通过拖拽把相应设备配置到图中. 设备拖到图中后, 单击设备可进入配置界面.Phsical是物理配置, 可配置设备的零部件和端口, 把左栏中零件拖到右图中添加, 把右图中的零件拖到左栏中去除. (注: 必须关闭设备才能进行零件配置)CLI是命令行界面, 可输入命令对设备进行配置Config是软件配置界面, 可查看、配置设备名, 端口IP地址, 子网掩码等Attributes是属性界面, 可查看设备的基本属性. 常用命令新设备一开始会提示Would you like to enter the initial configuration dialog?[yes/no]: 输入no即可. 三种模式 普通模式 Router&gt;: 最开始的模式, 只能完成一些最基本命令. 执行模式 Router#: 普通模式下输入enable, 可以查看配置信息, 对设备执行一些操作(如ping) 配置模式 Router(config)#: 执行模式下输入config t, 对设备一些参数进行配置(如ACL过滤规则, NAT地址转换规则, VPN通道等, 但设置好后对这些配置的查看则是在执行模式下) 端口模式 Router(config-if)#: 执行模式下输入相应端口名进入, 对相应端口进行配置(如配置端口IP地址, 子网掩码). eg: 进入FastEthernet0/0端口: interface FastEthernet0/0, 或简写为int fa0/0.注: 上面这些模式是层层递进的, 要从上层模式退到下层模式, 输入exit命令即可. 设置IP地址 设置路由器IP地址: Router(config-if)# ip address IP地址 子网掩码 eg: ip address 192.168.0.1 255.255.255.0 查看ip地址: 直接将鼠标悬停到图标上即可 路由器设置路由表 设置路由表: Router(config)# ip route 目标网段 子网掩码 下一跳地址eg: ip route 192.168.88.0 255.255.255.0 172.168.0.4, 表示收到目的地址为192.168.88.0/24网段的数据包, 转发到172.168.0.4地址 设置默认路由地址: Router(config)# ip route 0.0.0.0 0.0.0.0 xxx 删除路由表对应项: Router(config)# no ip route 192.168.88.0 255.255.255.0 172.168.0.4 (删除配置信息大多是在原有命令前加no即可) 查看路由表: Router# show ip route 注: 转发的下一跳地址是和当前路由器相连的下一个端口的地址 网络之中PC可以通信的条件 相连的路由器端口ip地址在一个网段内; 正确配置路由表; 正确配置PC的ip地址和默认网关Gateway(ip地址要和相连的路由器端口在一个网段, 默认网关Gateway需要是相连的路由器端口) 访问控制列表ACL(Access Control List) 查看ACL列表: Router# show ip access-list 建立ACL列表: Router(config)# ip access-l extendes list_name 设置ACL列表:10 permit ip 192.168.0.0 0.0.255.255 192.168.55.0 0.0.0.255: 允许从192.168.0.0/16 到 192.168.55.0/16的数据20 permit ip 192.168.31.0 0.0.0.255 any: 允许192.168.31.0/24的数据注: 没有允许的默认为就是禁止 删除acl表/acl表中的某一项: 原有命令前加no具体教程参见: Access Control List Explained with Examples 配置IPsec VPN 用于端到端的通信, 两个作用: 1. 提供vpn通道; 2. 对通道传输的数据进行加密. 具体教程: Configure and Verify a Site-to-Site IPsec VPN Using CLI","categories":[],"tags":[{"name":"Network","slug":"Network","permalink":"https://renli1024.github.io/tags/Network/"}]},{"title":"MOOC_算法课程笔记","slug":"Algorithm/MOOC_算法课程","date":"2018-04-13T00:14:00.000Z","updated":"2018-05-16T09:00:12.000Z","comments":true,"path":"2018/04/13/Algorithm/MOOC_算法课程/","link":"","permalink":"https://renli1024.github.io/2018/04/13/Algorithm/MOOC_算法课程/","excerpt":"","text":"最近在MOOC上报名了北大郭炜老师的算法课程，感觉收获还是蛮大的，因此整理一下自己的学习心得，方便以后复习查阅。 第一章_枚举 逐个尝试答案的一种求解策略 遇到题，首先考虑枚举法，看数据量是否允许，是否有“剪枝”策略。 但枚举时也要考虑“减枝”：如何去掉明显不满足的解，加快枚举速度 转变枚举思路：从条件出发找解 -&gt; 从解出发去试是否满足条件，解比条件组合更容易遍历所有情况。自问：题目什么是结果，什么是条件。 局部枚举：可由局部来确定剩余部分的状态，这样只需枚举局部即可实现对全体的枚举。关键是找出局部-&gt;全体的推导关系。 第二章_递归 常用递归情况：1.解决用递归定义的问题(求解表达式问题)2.将问题分解为规模更小的子问题来求解(汉诺塔问题) 想明白递推关系(递推函数是干什么的、返回值是什么)、终止条件。 递归用于数据量较小的情况，数据量大用动态规划。 递归的本质也是分解子问题，思考怎样把问题缩小。 第三章_动态规划 解题思路 设计子问题，将原问题分解为子问题(满足最优子结构和无后效性两条件) 存放子问题解：一个解若由K个变量决定，就申请一个K维数组来保存。 确定初始子问题：问题的边界值(最小的子问题)。 确定递推函数：如何从子问题-&gt;父问题。多为一个单位一个单位使问题规模递增。可以先做一步，再看能不能划分为形式相同子问题。 可用动规解决的问题的特点 最优子结构：若父问题解是最优的，则子问题解也肯定是最优的。 无后效性：父问题的解只和子问题解的值有关，和子问题的解是如何求得的无关。 与递归的相同处：思路都是大问题分成相同形式子问题(递推函数)，小问题的解再组合为大问题解。 与递归的不同处：动归要保存中间结果(多用全局数组保存)，避免重复计算。 递归函数与递推函数：递推函数是用循环实现的：找好结束条件，确定从哪开始循环，在循环体里写递推函数就可以了。 递推函数开数组：数组若特别大，考虑用滚动数组，后项不断覆盖前项，可实现二维数组-&gt;一维数组的降维。 第四章_深度优先搜索 多为递归+剪枝来实现。剪枝分为可行性剪枝(能否求得解)和最优性剪枝(是否是最优解)，从这两个思路来想。 深搜的本质还是递归分解子问题，一层层地分解，用栈解决的问题用递归都都可以解决。 搜索问题其实就是遍历所有解找最优解的过程，枚举也是搜索的一种，深度/广度搜索只是枚举的策略不同而已。搜索和一般的枚举区别在于，搜索问题的点与点之间是有关系的(边表示这种关系)，因此从一个点可以按规则进入下一个点，而不是盲目的枚举。(如正则表达式问题，出现了’(‘即表示要递归进入新的节点，出现’)’即表示要结束当前问题，出现’|’即需要求左右两边最大值) 遍历图的伪代码流程 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556int main()&#123; 将所有点标记为新点 起点=xx; 重点=xx; cout&lt;&lt;Dfs(起点);&#125;//判断从V出发是否能走到终点bool Dfs(V)&#123; if(V是终点) return true; if(V是旧点) return false; 将V标记为旧点; 遍历V相邻的每个结点U&#123; if(Dfs(U)==true) return true; &#125; return false;&#125;//判断从V出发是否能走到终点，并记录路径Node path[MAX_LEN]; //全局数组，记录路径int depth=0; //记录深度bool Dfs(V)&#123; if(V是终点)&#123; path[depth]=V; return true; &#125; if(V是旧点)&#123; return false &#125; 将V标记为旧点; path[depth]=V; depth++; 遍历V相邻的每个结点U&#123; if(Dfs(U)==true) return true; &#125; depth--; //从V走不到终点，回退 return false;&#125;//遍历图中所有点int main()&#123; 将所有点标记为新点; while(在图中能找到能找到新点K) Dfs(K);&#125;Dfs(V)&#123; if(V是旧点) return; 将V标记为旧点; 对和V相邻的每个点U&#123; Dfs(U); &#125;&#125; 图的数据结构 邻接矩阵：二维数组，G[i][j]表示节点i和节点j之间边的情况。遍历复杂度O(n2) 邻接表：每个节点V设置一个一维数组，存放从V连出去的边。边稀疏时效率高，遍历复杂度O(n+e)。 1234//邻接表实现Vector&lt;Vector&lt;T&gt;&gt; v //变长二维数组，用法和数组一样v.push_back() //添加元素v[0].size() //vector长度 第五章_广度优先搜索 依层次顺序，从小到大扩展节点。把层次低的点全部扩展出来后，才会扩展层次高的点。 可确保找出最短路径解，因为是一层一层找的 深搜用栈(递归)存节点，广搜用队列存节点。 123456//队列操作queue&lt;T&gt; qq.empty() //是否为空q.front() //取队首元素 q.push(xx) //加入元素q.pop() //抛弃元素 广搜中若要输出路径，则就要自己实现队列，数组 + aad、tail指针，队头取数，队尾加数。 优先队列：priority_queue 12345678910//与multiset区别，pr_queue默认从大到小，multiset默认从小到大。//pr_queue重载'&lt;'运算符(直接写重载函数即可)，multiset重载'()'运算符(写在结构体中)。//重写operator&lt;比较符bool operator&lt;(const T &amp; t1,const T &amp; t2)&#123; return t1&lt;t2; //t1的优先级小于t2，则t2排在队首(优先级高的排队首)&#125;priority_queue&lt;T&gt; q; //自动按重写的&lt;对T排序q.top() //取队首q.push() //入队尾q.pop() //扔队首 深搜/广搜区别，深搜用递归，广搜用队列(空间需求会大一些)。广搜最先找到的一定是最优解，深搜则要全部搜完才能找到最优解。因此需要遍历所有节点的情况用深搜，要递归的情况用深搜。 第六章_贪心算法 每一步行动总是选取当前下一步的最优操作，并不考虑之后的影响。(要考虑当前的最优操作也是整体的最优操作) 大部分贪心都和排序相关，直接从排序结果中从高到低选择即可。 三类常见的区间贪心问题 线段覆盖n个开区间(ai,bi)，选择尽量多个区间，使得这些区间两两不相交右端点排序（&lt;）兼顾左端点（&gt;），再从左到右遇到不相交的就选 1234567//a[i].l、a[i].r为左、右端点sort(a,a+n,cmp);int num=1,now=a[0].r; for(int i=1; i&lt;n; i++) &#123; if(a[i].l&gt;=now) now=a[i].r,num++;&#125;printf(\"%d\", num); 区间选点n个闭区间[ai,bi]，选择尽量少的点，使得每个区间至少有一个点右端点排序（&lt;）兼顾左端点（&gt;），每次选择可选区间的最后一个点 123456sort(a,a+n,cmp);int num=1,now=a[0].r;for(int i=1; i&lt;n; i++) &#123; if(a[i].l&gt;now) now=a[i].r,num++; &#125;printf(\"%d\", num); 区间覆盖数轴上有n个闭区间[ai,bi]，选择尽量少的区间覆盖一条指定的线段[s,t]左端点排序（&lt;）兼顾右端点（&lt;），每次选择从当前起点能覆盖到的最长的区间 1234567sort(a,a+n,cmp);int num=0,now=s,to=-1;for(int i=1; i&lt;=n &amp;&amp; to&lt;=t; i++) &#123; if(a[i].l&lt;=now) to=max(to,a[i].r); else now=to,to=a[i].r,num++;&#125;printf(\"%d\", num); 一些基础知识 有关复杂度的估算：十亿级肯定超时，亿级较危险，最好千万以下 算法中的证明，很难从正面直接证明，多为反证法，要多考虑反面的不可能性。eg,证明两数不可能相等，就想两数什么时候会相等、若相等会有什么条件不满足等等… 算法三大能力：1.按步骤思考，大问题分为小问题，一步步解决问题的能力2.实际问题抽象为计算机表示的能力(列出问题涉及的元素，再依次表示为计算机的数据结构)3.编程实现的能力(按1.的步骤，对数据结构进行操作，即编写算法) 解题思路：数据量不大，先想枚举，再想递归。大数据量考虑动规。其次深搜、广搜。然后贪心。 C/C++不能动态申请数组，就一次申请最大量，空间-&gt;时间。 for循环中：++i比i++效率高(无需保存原先的变量)，尽量使用++i。 vector&lt;pair&lt;string, int&gt;&gt; word; gcc会报错”&gt;&gt;”，理解为输入符号。此时应加上空格：vector&lt;pair&lt;string, int&gt; &gt; 对于涉及到“选前n个数”的问题，下标统一从1开始，这样下标使用的时候可以统一，只用把存储信息的数组从1开始存就可以了。 好题记录： POJ 1222(灯泡、开关问题)，第一周4题 放苹果，第三周3题(递归、动态规划对比) 找n元素数组前m大的数，第五周3题(n+mlogm算法) 最佳加法表达式，第六周4题(怎样自底向上推导) 分蛋糕，第七周5题(怎样自底向上推导，循环的嵌套) 城市通路，第九周1题(深搜，怎样剪枝) 生日蛋糕，第九周3题(深搜，剪枝) 带限制的广搜：增加搜索状态的维度，判重时要考虑增加的维度。","categories":[],"tags":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://renli1024.github.io/tags/Algorithm/"}]},{"title":"JSP笔记","slug":"JSP","date":"2018-02-13T00:14:00.000Z","updated":"2019-05-29T01:19:25.251Z","comments":true,"path":"2018/02/13/JSP/","link":"","permalink":"https://renli1024.github.io/2018/02/13/JSP/","excerpt":"","text":"第一节_基础知识JSP(Java Server Page)是一种动态网页技术标准，在HTML中嵌入Java程序片段(Scriptlet)和JSP标签(tag)所构成。 Tomact服务器目录 Tomact目录 用途 /bin 存放启动和关闭Tomact的命令文件 /lib 存放所有应用程序都可以访问的JAR包 /conf 存放Tomact的配置文件，如server.xml，web.xml等 /logs 存放Tomact日志文件 /temp 存放临时文件 /webapps 存放应用程序的工程文件 /work 存放JSP生成的Servlet文件和字节码文件 Web项目中目录 WEB-INF目录：web.xml文件，配置文件； classes目录：存编译后的Java文件； lib目录：存Jar包。 JSP程序运行机制123456789101112131415服务端收到客户端的请求if(请求HTML/XML页面)&#123; 直接将页面相应代码发给客户端&#125;else if(请求JSP页面)&#123; if(页面第一次被请求 || 页面被修改过)&#123; 1.JSP文件(.jsp)转换成servlet文件(.java) 2.编译生成字节码文件(.class) 3.执行字节码文件，并将执行结果以HTML的形式返回给客户端。 &#125; else&#123; //页面之前已执行过且未被修改 直接执行已生成的字节码文件(.class)，并将执行结果以HTML的形式返回给客户端。 &#125;&#125; JSP基本元素 声明：&lt;%! int a; %&gt;，声明页面全局变量 表达式：&lt;%=...%&gt;，将结果转成字符串形式输出到页面中 代码片段(Scriptlet)：&lt;% ... %&gt;，java代码片段 JSP指令(静态)：&lt;%@ xxx %&gt;格式&lt;%@ page 属性1=&quot;xx&quot; 属性2=&quot;xx&quot;%&gt;，设置页面属性&lt;%@ include file=&quot;文件名&quot;%&gt;，将文件插入到当前页面中(静态插入) JSP动作(动态)：&lt;jsp:xxx /&gt;格式&lt;jsp:include page=&quot;文件名&quot;/&gt;，将文件的执行结果插入到当前页面(动态插入)&lt;jsp:forward page=&quot;文件名&quot;/&gt;，停止当前页面，转向指定HTML/JSP文件的页面(地址栏不变)&lt;jsp:param name=&quot;变量名&quot; value=&quot;变量值&quot;/&gt;，传递参数，作为include/forward的子标签使用，在其他页面中通过request.getParameter(“变量名”)接收参数。 第二节_JSP内置对象JSP内置对象无需创建就可以直接使用，具体有以下几种： 输出输入对象：request对象、response对象、out对象 通信控制对象：pageContext对象、session对象、application对象 Servlet对象：page对象、config对象 错误处理对象：exception对象 JSP内置对象作用域 作用域 说明 page 只能在当前页面中访问 request 整个请求周期，从发起请求到返回响应。(期间可能forward跳转了多个页面) session 整个当前会话，从打开浏览器开始，到关闭浏览器都算一个session application 整个应用期，从服务器启动应用，到应用结束(对象可被所有用户共享) request对象 当客户端通过HTTP请求JSP页面时，服务器会自动创建request对象，并将请求信息封装进去。处理完请求后，request对象即自动销毁。 常用方法：(注意区分参数和属性)String getParameter(String name)：获取客户端传送给服务器的参数值(如form表单中的内容)void setAttribute(String name,Object obj)：服务端自己设置request属性值(便于在页面间传数据)Object getAttribute(String name)：获取相应属性值(返回Obj类型，要进行强转) 传参数(parameter)的方式：客户端通过form表单(可设置get/post形式)、服务端通过include/forward动作(get形式)。但一般服务端页面间通过属性(Attribute)传信息较常用。 request还可获得客户端的IP地址、协议等信息。 response对象 服务器向客户端发数据时，自动创建response对象。response只负责设置响应的头部信息，响应体信息由其他对象设置。 重定向网页：response.sendRedirect(&quot;xxx&quot;)，与forward的区别：forward仅能站内跳转，重定向可跳转到任何网站；forward带request信息跳转，重定向不带request跳转。 页面定时刷新/跳转：response.setHeader(&quot;refresh&quot;,&quot;5&quot;)，每隔5s页面自动刷新一次。response.setHeader(&quot;refresh&quot;,&quot;5;url=www.baidu,com&quot;)，5s后自动跳转到百度页面。 session对象 会话(session)的含义：从用户第一次进入网站，到浏览器关闭期间，称为一次会话。用户第一次进入网站，服务器会生成session id标识不同用户，并将相关信息存储在浏览器，因此第二次访问(不关浏览器)还可识别出是同一用户。 session对象可用来传递信息、获取会话属性。 application对象每个Web程序一个application，只要不关闭服务器，application对象即一直存在。用于保存应用程序中的公有数据(所有的用户共享)。可用来记录访问网站的总人数。","categories":[],"tags":[{"name":"JSP","slug":"JSP","permalink":"https://renli1024.github.io/tags/JSP/"}]},{"title":"Swift笔记","slug":"Swift笔记","date":"2018-01-27T11:50:00.000Z","updated":"2019-05-29T01:12:30.391Z","comments":true,"path":"2018/01/27/Swift笔记/","link":"","permalink":"https://renli1024.github.io/2018/01/27/Swift笔记/","excerpt":"","text":"第一节_基本知识Mac和Xcode一些快捷键command键：win键，option键:alt键复制：com+c，粘贴：com+v，剪切：com+x保存：com+s，撤销：com+z运行程序：com+r注释、取消注释：com+/单步运行：F6 数据类型 共有数值类型、字符串类型、布尔类型、枚举类型、合集类型五种 Swift中不强制要求定义类型，强制定义的只有常量let、变量var，let常量初始化后即不能再更改值 数值类型有int、uint(无符号整数)、float、double四种基本数值类型123let n = 70 let m = 50.0 //等号两边空格数必须相等var n:Double = 50 //显示定义的类型 字符串类型1234567891011格式化字符串var n = 50var m = 60var str1 = &quot;I have \\(n + m) pencils&quot; // \\(表达式)为格式化字符串var str2 = &quot;I have &quot; + (String)(n + m) + &quot; pencils&quot; //效果相同字符串的下标是String.index类型，不是int类型，不能直接用int作下标startIndex：指向首字符；endIndex：指向末字符的后面；offsetby：偏移量。let index1 = str.index(str.startIndex, offsetBy:1) //指向首字符后一字符let index2 = str.index(str.endIndex, offsetBy:-1) //指向末字符str2 = str[index1..&lt;index2] //截取字符串，前闭后开区间 计算字符串长度：str2.count比较字符串是否相等：== 和 !=在Swift中字符串是值类型，复制传递的是字符串的值而非引用 布尔类型(Bool)true/false 枚举类型1234567891011121314151617enum DaysOfWeek&#123; //定义枚举类型 case Sunday case Monday case Tuesday dase Wednesday case Thursday&#125;var day = DaysOfWeek.Sunday //用句号引出枚举项day = .Monday //已确定day是DaysOfWeek类型，即不用再写，但句号必须写enum ea : String&#123; //若枚举项有rawvalue,则必须写类型值 case a1 = &quot;aa1&quot; case a2 = &quot;aa2&quot; case a3 = &quot;aa3&quot;&#125;let result = ea(rawValue:&quot;aa1&quot;) //由raw值查枚举项，返回Option(ea.a1)print(result!) //拆包，输出a1 合集类型(Collection) 数组和区间 字典(dict)：键值对 集合(set)：无序、不重复数组三种类型都可用xx.count表示元素数量123456789101112131415161718//数组var an1 = [1,2,3,4]var an2 : [Int]an2 = [1,2,3,4]//区间an1[1..&lt;3] //an[1],an[2]an1[1...3] //an[1],an[2],an[3]//字典var dic: [String : Int]dic = [&quot;Red&quot;:0,&quot;Green&quot;:1,&quot;Bule&quot;:2]dic[&quot;Red&quot;] //0//集合let s1 = Set([1,2,3])let s2 : Set&lt;Int&gt;s2 = [1,2,3] 可选值Optional类型后加?为可选值，代表声明的变量可能为空(nil)12345678910let dic = [0:&quot;Red&quot;,1:&quot;Blue&quot;,2:&quot;Yellow&quot;]var color = dic[0] //color为String?类型，可能会返回nil值print(color) //输出Optional(&quot;Red&quot;)，对&quot;Red&quot;封包了if color! = nil&#123; //color不为空才执行操作 let actualColor = color! //对Optional(&quot;Red&quot;)拆包&#125;else&#123; //统一在拆包阶段对nil进行处理，逻辑更清晰&#125; 第二节_语句for-in循环12345678910111213141516171819for index in 1...5&#123; print(i)&#125; //条件不用加括号，但语句体要加中括号//遍历数组var an = [1,4,7,22,5] for index in an&#123; print(index)&#125;//遍历字典let d = [0:&quot;Red&quot;,1:&quot;Green&quot;,2:&quot;Blue&quot;]for key in d.keys&#123; print(&quot;\\(key)-&gt;\\(d[key])&quot;) //输出的是可选值&#125; for(key,value) in d&#123; print(&quot;\\(key)-&gt;\\(value)&quot;) //输出正常值&#125; switch-case12345678910111213//没有break//一个case可对应多个选择值//最后必须加defaultlet x:Character = &quot;1&quot;switch x &#123;case &quot;a&quot;,&quot;b&quot;,&quot;d&quot;: print(&quot;1&quot;)case &quot;s&quot;,&quot;e&quot;,&quot;p&quot;: print(&quot;2&quot;)default: print(&quot;3&quot;)&#125; 函数12345678910111213141516函数定义func hello(name:String)-&gt;String&#123; return &quot;Hello, &quot; + name &#125;调用str=&quot;lrrr&quot;hello(name:str) //函数调用不能省略参数名称//多返回值函数，用元组作返回值func hello(n:Int)-&gt;(n1:Int,n2:Int)&#123; let n1 = n+1 let n2 = n+2 return (n1,n2)&#125;let total = hello(n:1)print(total) //输出“(n1: 2, n2: 3)” 第三节_IOS开发MVC模式Model-View-Controller(模型-视图-控制器)，面向对象的常用模式模型：保存数据的类视图：UI控件控制器：把模型和控制器绑定在一起的类，以及实现中间逻辑层。优点：可最大限度地分离这三类代码(数据、UI、逻辑)，每个类只实现专一的功能。 控制类的绑定1234567891011121314151617输出接口：@IBoutlet weak war myButton: UIButton! //可与控件绑定的变量(Button按钮)操作方法：IBAction func doSomething(sender: UIButton)&#123; //可响应控件所触发事件的函数，sender为控件类型&#125;绑定：在View视图上，(ctrl+左键)/右键拖住控件，拖向辅助编辑器中的viewControl.swift文件,新建一个接口/方法，或绑定已有代码。注：和已有代码绑定时，只有类型匹配才会出现绑定框。一般流程：控件A绑定Action，在绑定Action时指明响应什么Event，控件B绑定outlet,在Action中对outlet进行操作，相当于对控件B操作。Event触发时，执行Action，操作outlet，界面UI发生改变。 网络传输(HTTP协议)HTTP协议分为请求头和数据部分，请求头系统有内置属性，后台也是tomact服务器会自动处理数据部分则是和后台自己约定的，比如提交到哪个文件夹，提交的文件叫什么名字等等。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455//先把HTTP数据部分写好(Data形式)，方便后面传入request中//name是要提交到哪个文件夹，filename为文件上传后的文件名//7d4a661c433为分隔符，任意string串都可以。以'--'+分隔符开头，固定格式。//'\\r\\n'表示换行，属性间是否换行也是固定格式。//数据部分的开头，最后的要转成utf8格式var postdata:Data = \"--7d4a661c433\\r\\nContent-Disposition: form-data;name=\\\"uploadFile\\\";filename=\\\"lizec.jpg\\\"\\r\\nContent-Type:application/octet-stream\\r\\n\\r\\n\".data(using: String.Encoding.utf8)!//具体的数据部分，直接写入即可postdata.append(UIImagePNGRepresentation(faceImg.image!)!)//数据部分结尾postdata.append(\"\\r\\n\\r\\n--7d4a661c433--\\r\\n\".data(using: String.Encoding.utf8)!)//定义请求函数，写成函数形式便于之后写回调函数//postData为HTTP数据部分，webServerUrl为服务器的地址func requestfun(_ postData:Data,webServerUrl:String)&#123; let session:URLSession = URLSession.shared let url:URL = URL(string:webServerUrl)! //将String形式的服务器地址转为URL形式 //定义HTTP请求头及相关属性，这部分是HTTP固定的属性 //用url初始化request，NSMutableURLRequest形式 let request:NSMutableURLRequest = NSMutableURLRequest(url:url) request.timeoutInterval = 30 request.httpMethod = \"POST\" request.httpBody = postData request.setValue(\"UTF-8\", forHTTPHeaderField: \"Charsert\") //设置boundary，即分隔符 request.setValue(\"multipart/form-data;boundary=7d4a661c433\", forHTTPHeaderField: \"Content-Type\") //定义回调任务 //传入的request参数为NSMutableURLRequest形式的HTTP请求 //data为后端发来的数据(系统已自动将数据部分拆出来了) let task = session.dataTask(with: request as URLRequest)&#123; (data: Data?, response: URLResponse?, error: Error?) -&gt; Void in //有回调数据 if data != nil &#123; tempText = String(data:data!, encoding: String.Encoding.utf8)! //print(tempText!) sign = 1 //回调函数执行完 &#125; else &#123; print(\"发送请求出错:\\(String(describing: error?.localizedDescription))\") sign = 1 &#125; &#125; //执行回调任务 //系统定时查询后端有无response发过来，检测到response后即执行回调任务 //因此其他地方要等待回调函数执行才能更新，可while()循环检测标志位 task.resume() &#125;&#125;//最后调用请求函数即可requestfun(postdata, webServerUrl:\"http://123.207.30.222:8080/WebHello/UploadServlet\") 多线程操作在GUI中，默认操作都是在主线程中完成的(对控件的操作，以及与控件无关的操作)，因此如果有非常耗时的操作，就需要另开一个线程，放在其中执行，否则耗时的操作会使主线程阻塞，导致UI界面无法操作(点击按钮、输入文本等)。而在分线程中，如果涉及到对UI界面的操作，就要再手动回到主线程中去操作相应控件，在swift中对应为DispatchQueue.main.async {//code}。swift中的线程操作，可通过GCD(Grand Central Dispatch)的方式完成，其将代码以队列(先进先出)的形式放入其他线程中执行。123456789101112131415//...code1let queue = DispatchQueue.global(qos:.default) queue.async &#123; //code3 DispatchQueue.main.async &#123; //在分线程中回到主线成中操作UI upImgButton.isEnabled = false &#125; &#125;//...code2//代码说明：//code1执行完后，建立线程队列queue，系统将块内的代码放入队列中，但并不会立即执行//之后会执行code2，等当前线程时间片到了，才会去执行queue线程中的代码//若没有并行设置，queue线程中的代码默认是顺序执行的 IOS图像格式关于IOS的图像系统，有三种格式 - UIImage：在UIKit框架下显示的图像格式，用于UI显示，通过UIImageView.image调用或赋值 - CIImage：CoreImage框架操作的图像格式，CI框架的函数都是针对这个数据格式 - CGImage：位图格式，底层的图像存储格式，UI和CI本质都是对CGImage的封装 123456789//三种图像的互相转换,UI和CI图像的转换都是通过CG间接完成的UI-&gt;CG:UIImage.cgImageUI-&gt;CI:CIImage(cgImage: UIImage.cgImage)CG-&gt;UI:UIImage.init(cgImage: CGImage)CG-&gt;CI:CIImage(cgImage: CGImage)CI-&gt;UI:UIImage.init(cgImage: CIImage.cgImage)CI-&gt;CG:CIImage.cgImage 人脸识别(系统库)参考博文：https://www.jianshu.com/p/e371099f12bd123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119//IOS内置的图像处理库，用于处理一些复杂的图像操作import CoreImage//人脸识别函数的传入参数之一let imageOptions = NSDictionary(object: NSNumber(value: 5) as NSNumber, forKey: CIDetectorImageOrientation as NSString)//未识别的原始照片let personciImage = CIImage(cgImage: imageView.image!.cgImage!)//定义精确度，High为较高的精度let accuracy = [CIDetectorAccuracy: CIDetectorAccuracyHigh] //定义人脸识别器let faceDetector = CIDetector(ofType: CIDetectorTypeFace, context: nil, options: accuracy)//识别人脸，返回人脸数组let faces = faceDetector?.features(in: personciImage, options: imageOptions as? [String : AnyObject])//因为UI和CI两大框架的坐标系原点不相同//UI为左上角，CI为左下角，因此要进行坐标变化//否则人脸的位置坐标不对let ciImageSize = personciImage.extent.size//改变x，y延伸方向var transform = CGAffineTransform(scaleX: 1, y: -1)//改变原点位置transform = transform.translatedBy(x: 0, y: -ciImageSize.height)if let face = faces?.first as? CIFaceFeature &#123; //进行坐标系变换 //face.bounds返回识别的人脸CRect框，包括起点位置和图像宽、高 let faceImgBounds = face.bounds.applying(transform) let sourceImageRef: CGImage = imageView.image!.cgImage! //根据Rect截取人脸 let newCGImage = sourceImageRef.cropping(to: faceImgBounds) var tempImage = UIImage.init(cgImage: newCGImage!) //对截取的人脸图像进行压缩 let tempCGSize = CGSize(width:tempImage.size.width/4,height:tempImage.size.height/4) UIGraphicsBeginImageContext(tempCGSize) tempImage.draw(in: CGRect(x: 0, y: 0, width: tempCGSize.width, height: tempCGSize.height)) //因为图像会有向左旋转90度的bug，因此要进行修正 tempImage = UIGraphicsGetImageFromCurrentImageContext()! UIGraphicsEndImageContext() tempImage = tempImage.fixOrientation() //写入ImageView中 faceImg.image = tempImage&#125; else &#123; let alert = UIAlertController(title: \"提示\", message: \"未检测到人脸\", preferredStyle: UIAlertControllerStyle.alert) alert.addAction(UIAlertAction(title: \"确定\", style: UIAlertActionStyle.default, handler: nil)) self.present(alert, animated: true, completion: nil)&#125;// 修复图片旋转代码，扩展UIImage类//根据图像的imageOrientation属性值来进行旋转extension UIImage &#123; func fixOrientation() -&gt; UIImage &#123;// if self.imageOrientation == .up &#123;// return self// &#125; var transform = CGAffineTransform.identity switch self.imageOrientation &#123; case .down, .downMirrored: transform = transform.translatedBy(x: self.size.width, y: self.size.height) transform = transform.rotated(by: .pi) break case .left, .leftMirrored: transform = transform.translatedBy(x: self.size.width, y: 0) transform = transform.rotated(by: .pi / 2) break case .right, .rightMirrored,.up: transform = transform.translatedBy(x: 0, y: self.size.height) transform = transform.rotated(by: -.pi / 2) break default: break &#125; switch self.imageOrientation &#123; case .upMirrored, .downMirrored: transform = transform.translatedBy(x: self.size.width, y: 0) transform = transform.scaledBy(x: -1, y: 1) break case .leftMirrored, .rightMirrored: transform = transform.translatedBy(x: self.size.height, y: 0); transform = transform.scaledBy(x: -1, y: 1) break default: break &#125; let ctx = CGContext(data: nil, width: Int(self.size.width), height: Int(self.size.height), bitsPerComponent: self.cgImage!.bitsPerComponent, bytesPerRow: 0, space: self.cgImage!.colorSpace!, bitmapInfo: self.cgImage!.bitmapInfo.rawValue) ctx?.concatenate(transform) switch self.imageOrientation &#123; case .left, .leftMirrored, .right, .rightMirrored: ctx?.draw(self.cgImage!, in: CGRect(x: CGFloat(0), y: CGFloat(0), width: CGFloat(size.height), height: CGFloat(size.width))) break default: ctx?.draw(self.cgImage!, in: CGRect(x: CGFloat(0), y: CGFloat(0), width: CGFloat(size.width), height: CGFloat(size.height))) break &#125; let cgimg: CGImage = (ctx?.makeImage())! let img = UIImage(cgImage: cgimg) return img &#125;&#125;","categories":[],"tags":[{"name":"Swift","slug":"Swift","permalink":"https://renli1024.github.io/tags/Swift/"}]},{"title":"C#笔记","slug":"Csharp","date":"2018-01-26T11:50:00.000Z","updated":"2018-06-15T10:14:31.000Z","comments":true,"path":"2018/01/26/Csharp/","link":"","permalink":"https://renli1024.github.io/2018/01/26/Csharp/","excerpt":"","text":"第一章_基本语法C#概述 C#运行环境.NET框架，是生成和运行.NET应用程序和Web Service的组件库，包括.net framework类库和公共语言运行库(CLR).net framework类库：标准库。CLR：类似JAVA虚拟机，将C#编译为IL中间语言(Intermediate Language)。 C#可创建的程序C#可创建的程序：控制台应用程序，Windows窗体应用程序，Web应用程序 命名空间对类的一种划分形式，命名空间和类的关系类似于目录和文件的关系，引入方法using spacename; Main方法应用程序的入口点；声明为static void Main(string[] args)，返回值只能是void或者int；可以放在任何一个类中，一个应用程序中必须有一个类包含Main方法。 C#基本数据类型 数据类型分为值类型和引用类型，值类型存的是数据，在栈中；引用类型则存引用数据的指针，在堆中。值类型：简单类型、枚举类型、结构类型、可空类型，存储在栈(但若在类内定义，则存储在堆)。引用类型(对象)： 类、接口、数组，存储在堆，赋值时传的是引用，通常被称为对象。 整型和浮点型int：4字节有符号，short：2字节有符号，long：8字节有符号float：4字节浮点数。double：8字节浮点数。decimal：16字节浮点数，精度高，适用于金融、货币等领域 类型转换分为隐式类型转换和显示类型转换隐式类型转换：小范围类型-&gt;大范围类型，程序自动转换，不会丢失数据显示类型转换：大范围类型-&gt;小范围类型，要手动强转，可能会丢失精度。 装箱与拆箱主要作用是实现值类型和引用类型的相互转换，让值类型可以使用引用类型的一些方法。Object/object类型：所有类型的基类 123456//装箱：将值类型转换为object类型，会在堆上为其分配一个object对象的实例int i=5;object o = i;//拆箱：将object类型转换为值类型，必须先装箱再拆箱。int k = (int) o; 判断是否要强转：苹果是水果，水果不是苹果。 常量类型const：编译时初始化，所以不能用变量初始化赋值，且声明和初始化必须在一起。readonly：运行时初始化，声明和初始化可以分开，可用变量初始化赋值，但赋值后值就不能更改。 匿名类型var 123456//无需指定具体类型，常用于foreach语句//foreach语句多用于集合操作中int[] arr = new int[]&#123;1,2,3,4&#125;;foreach (var i in arr)&#123; Console.write(i); //输出1234&#125; 程序控制语句控制台输入输出12345678910111213141516//控制台输入String str = Console.ReadLine(); //读取一行字符。//控制台输出Console.Write(\"123\"); //不换行Console.WriteLine(\"3+&#123;0&#125;=&#123;1&#125;\", i, i+3); //换行，格式化输出，0、1表序号Console.WriteLine(\"&#123;0:F4&#125;\",x); //格式化输出，小数点后4位//tostring用法，将数字转化为一定格式的字符串int a = 12345;double b = 1.2345;String str1 = a.toString(\"d8\"); //转换为8位字符串，位数不够用0补String str2 = b.toString(\"f3\"); //四舍五入保留3位小数，不够时用0补//String转整型int a = Int32.Parse(str); 基本流程控制语句 switch case语句 1234567891011121314switch case语句int n = 3;switch (n)&#123; case (1): Console.WriteLine(\"1\"); //case后可以加&#123;&#125;，也可以不加 break; case (2): Console.WriteLine(\"2\"); break; default: Console.WriteLine(\"3\"); break;&#125; while语句 123456789while (条件)&#123; //语句序列&#125;do&#123; //语句序列&#125;while (条件); //注意分号 注：while和do whiley语句都是条件不满足时跳出循环，唯一的区别是do while语句至少会执行一次。 foreach语句12345int[] myInt=&#123;1,2,3&#125;;foreach(int i in myInt)&#123; Console.WriteLine(i);&#125; 注：循环变量i是只读的，不能更改值 try-catch语句123456789101112try&#123; //语句序列&#125;catch(Exception err)&#123; //异常处理&#125;finally&#123; //语句序列&#125; 注：finally语句块加不加都可以，如果加了，就是无论有没有捕获到异常，finally中的语句都会执行。 throw语句123456789//用法1，throw 异常表达式throw new Exception(\"方法中抛出的异常\");//用法2，直接 throw//只能用在catch块中，重新抛出当前由catch块处理的异常。catch(Exception err)&#123; throw;&#125; 第二章_常用数据类型的用法String类型12345678910111213141516171819202122//初始化String a = \"str\"; string b = a; //传值char c = b[1]; //取某字符String.Compare(string s1,string s2)//s1&gt;s2，结果为1；s1=s2，结果为0；s1&lt;s2，结果为-1。//字符串大小是一一比较字符，比较对应字符的ASCII码大小//判断字符串是否相等if(b==a)//判断字符串中是否包含指定的子字符串string str1 = \"this is a string\";bool b=str1.Contains(\"is\");//截取字符串//从startIndex开始，截取conut个字符//字符串的序号都是从0开始str.Subtring(int startIndex，int count) 注：C#中string是String的别名，两者等价，编译器编译时会将string转换为String。 数组类型 基本使用方法数组是一种引用类型，而非值类型。声明数组：int[] a = new int[10]123456789101112131415161718192021222324//数组是引用类型，而非值类型。//可动态申请int[] a = new int[30]; //一维数组int[,] ar = new int[3,2]; //二维数组，形式是括号内逗号分隔[,]for(int i = 0; i &lt; 3; ++i)&#123; for(int j = 0; j &lt; 2; ++j) &#123; ar[i,j] = i + j; &#125;&#125;//交错数组，数组的数组，每个一维数组元素也是一个数组，“数组的数组”。//形式为两个括号。int[][] ar = new int[5][]; //只指定行数即可for (int i = 0; i &lt; 5; ++i)&#123; ar[i] = new int[i + 1]; for (int j = 0; j &lt; i + 1; ++j) &#123; ar[i][j] = j+1; &#125;&#125; 注：二维数组和交错数组的区别，二维数组每行列数一样，交错数组不一定。 动态改变数组大小函数原型：public static void Resize&lt;T&gt;(ref T[ ] array, int newSize)使用了泛型的概念，T表示数组类型，array表示要调整的数组，newSize表示要调整为多大。若newSize&gt;array.Length，则分配一个新数组，并将所有元素复制到新数组。若newSize&lt;array.Length，则分配一个新数组，并将元素复制到新数组直至填满，剩余元素将被忽略。12int[] array = new int[5] &#123; 0, 1, 2, 3, 4 &#125;;Array.Resize&lt;int&gt;(ref array, 10); //ref为传引用关键字，必须显示传入 枚举类型枚举是一组命名常量的集合，为一组在逻辑上紧密联系的整数值提供便于记忆的符号，从而使代码更清晰。123456//手动赋值enum days &#123;Mon=0, Tue=1, Wed=2&#125;;//默认赋值(默认为int，从0开始)enum days &#123;Mon, Tue, Wed&#125;;//使用方法days d1 = days.Mon 注1：enum都是使用专门的类型名，名字对应的数值使用的不多。注2：enmu只能在类外部、namespace内部定义，不能在类里面定义 泛型 基本概念泛型可简单地理解为“广泛的数据类型”，就是说，泛型是数据类型的一种通用表示形式，可以表示任意一种数据类型。具体形式：泛型是具有占位符（类型参数）的类、结构、接口和方法，它与普通类的区别是泛型多了表示类型的占位符&lt;T&gt;，定义时无需指定具体类型，创建实例时才指定类型。1234567891011121314//定义public class MyClass&lt;T&gt;&#123; public T MyProp; //定义属性MyProp public void Print( ) &#123; Console.WriteLine(MyProp); &#125;&#125;//创建实例MyClass&lt;int&gt; c1 = new MyClass&lt;int&gt;();c1.MyProp = 15;MyClass&lt;String&gt; c2 = new MyClass&lt;String&gt;();c2.MyProp = \"1234\"; 常用泛型集合 泛型集合的特点非泛型集合如ArrayList、Stack等，无法在编译前确定数据类型，因此在运行时可能会进行频繁地进行数据类型转换，降低运行效率，因此推荐使用泛型集合类，尽量不要使用其对应的非泛型集合类。 列表List 基本特点List&lt;T&gt;可通过下标索引、允许重复元素、按插入顺序排序、可使用foreach语句遍历 具体用法 12345678List&lt;String&gt; li = new List&lt;String&gt;();li.Add(\"张三\"); //末尾插入元素li.Add(\"李四\");li.Insert(1,\"李大\"); //在指定位置插入元素Console.WriteLine(li[1]); //按下标索引foreach(var i in li)&#123; //处理程序&#125; 链表LinkedList 基本特点LinkedList&lt;T&gt;为双向链表，其中的每个节点都属于LinkedListNode类型，通过.Previous和.Next和属性指向其前后节点。不能通过下标索引，可以重复元素，可以foreach遍历 具体用法 1234567891011String[] word = &#123; \"a\", \"b\", \"c\" &#125;;LinkedList&lt;String&gt; list = new LinkedList&lt;string&gt;(word); //用数组初始化list.AddFirst(\"dog\");LinkedListNode&lt;String&gt; n1 = list.Find(\"a\"); //通过值来查找某个节点LinkedListNode&lt;String&gt; n2 = n1.Next; //.Next访问下一个节点Console.WriteLine(n2.Value); //输出bforeach(var i in list) //foreach遍历&#123; Console.Write(i);&#125;Console.WriteLine(); 队列Queue 基本特点Queue&lt;T&gt;表示先进先出集合，在按接收顺序存储消息的情况下非常有用，元素在一端插入，在另一端移除。允许重复元素、可以保存null值、不能下标索引 具体用法 12345678910Queue&lt;string&gt; q = new Queue&lt;string&gt;();q.Enqueue(\"one\"); //Enqueue方法在队列末尾添加元素q.Enqueue(\"two\");q.Enqueue(\"three\");q.Dequeue(); //Dequeue方法删除队列头部元素foreach(var i in q)&#123; Console.Write(i + \" \"); //输出 two three&#125;Console.WriteLine(); 堆栈Stack 基本特点Stack&lt;T&gt;表示后进先出集合，适用于递归的相关情况。允许重复元素、可以保存null值、不能下标索引 具体用法 12345678910Stack&lt;String&gt; st = new Stack&lt;string&gt;();st.Push(\"one\"); //元素入站st.Push(\"two\");st.Push(\"three\");st.Pop(); //栈顶元素出栈foreach(var i in st)&#123; Console.WriteLine(i + \" \"); //输出 one two&#125;Console.WriteLine(); 时间类型DateTimeDateTime：表示时间点；TimeSpan：表示时间间隔。12345678910DateTime now = DateTime.Now; //获取当前时间DateTime dt = new DateTime(2018,6,30); //手动构造时间Console.WriteLine(dt.toString(\"yyyy年M月d日\")); //格式化时间类型，输出2018年6月30日//时间计算DateTime dt = new DateTime(2010, 10, 3);DateTime dt2 = new DateTime(2009, 10, 3);TimeSpan times = now - dt2;Console.WriteLine(times);//输出为365.00:00:00，格式为TimeSpan，天.时:分:秒的格式 第三章_面向对象编程基础类 类和对象类：一组具有相同数据结构和相同操作的对象的集合，类声明默认为private。对象：类的实例化。 12345678//定义类的的格式，[]表示可省略[附加声明] [访问修饰符] class 类名称[：[基类] [，接口序列]]&#123; [字段声明] [构造函数] [方法] [事件]&#125; 访问修饰符Public：类的数据成员和方法可以在外部使用。private：默认访问修饰符，类中的所有方法和数据成员只能在此类中使用，外部无法使用。Protected：本身和继承此类的子类可以使用。Partial：局部类型，类的定义和实现可以分布在多个文件中，但都要使用partial标注。 构造函数构造函数是一个特殊的方法，用于在建立对象时进行初始化的动作。1、每个类至少有一个构造函数。2、一个构造函数总是和它的类名相同。3、构造函数的声明不写任何返回值，void都没有。4、构造函数总是public的。 默认构造函数若程序代码中没有构造函数则系统会自动提供一个默认的构造函数默认构造函数没有参数，会为非静态成员变量初始化，int/double-&gt;0，bool-&gt;false，引用类型-&gt;null（静态成员变量不赋值的话会默认初始化赋值为0）。 类的静态成员在类内被声明为Static的成员，被类的所有对象所共享。静态变量不是存储在某一个对象中的，其存储在专门的一片内存区域中，因此一个对象更改了它的值，其他对象会共享这个改变。必须通过类来访问，不能通过对象来访问。 字段、局部变量、属性字段：定义在类一级别，就是类的成员变量局部变量：定义在类的方法内部的变量属性：带有{get; set;}声明的字段。 结构(struct)struct是由一系列变量组织在一起而构成的数据表示形式，所有结构类型都隐式地从类型object继承。1234public struct Point&#123; public int x; public int y;&#125; 结构和类的区别：结构类型是值类型，类类型是引用类型。凡是定义为结构的，都可以用类来定义。创建轻量级对象时，可以使用结构。 方法 方法的定义因为其是属于类的函数，因此定义方法必须放在某个类中。 123访问修饰符 返回值类型 方法名称(参数列表)&#123; 程序&#125; 方法的参数传递1、传值：为形参申请新的内存空间，复制实参的值到形参中。在函数内操作的是形参，对实参没有影响。2、传引用：格式为fun(ref 参数类型 参数名)，需要加上ref(reference)关键字，这时不再为形参申请新的空间，形参相当于实参的别名，函数内操作的就是实参。3、输出多个引用类型的参数：有时方法的计算结果可能有多个，但return只能返回一个结果，这时就可以用out关键字，使用该参数来接收输出值。 12345678public static void MyMethod(out int a, out int b) &#123; a = 5; b = 6;&#125;static void Main()&#123; int x, y; MyMethod(out x, out y);&#125; 方法重载具有相同的方法名，但参数类型或参数个数不同的方法。重载方法的参数列表必须不同，不能只有返回值不同 属性和索引器属性带有{get; set;}声明的字段。作用：给外部提供读写private成员的途径。步骤：1、为private成员定义一个对应的public成员。2、为public成员定义get、set属性，并编写读写时的检查代码。3、通过访问public成员来读写私有成员。 123456789101112131415161718//具体用法private string name;public string Name&#123; //定义检查操作 get&#123; return name != null? name: string.Empty; //修改的是name的值 &#125; set&#123; name = value; &#125;&#125;//最后通过xx.Name来间接修改name的值，同时会执行检查操作//简化写法//意义将公有成员设为read-only或write-only public int a&#123;get; set;&#125; //可以这么写，但没什么意义public int b&#123;get; private set;&#125; //read-onlypublic int c&#123;private get; set;&#125; //write-only 类的继承 基本概念在C#中，用冒号:表示继承，被继承的类叫基类/父类，继承的类叫派生类/子类。若没有指定基类，则编译器就将System.Object作为基类。两种继承方式：类继承和接口继承。类继承只允许单一继承，多重继承通过接口来实现。继承的成员：子类只能继承父类的public, protected成员，不能继承private成员。关于构造函数：子类初始化时，会首先调用父类的构造函数（初始化继承自父类的数据成员），再调用自己的构造函数（初始化自身特有的数据成员）。在子类中访问父类的成员：通过base.xx来调用。基类和派生类的转换：1234567891011121314151617181920212223242526public class A&#123; public A() &#123; Console.WriteLine(\"A的构造函数\"); &#125;&#125;public class B: A&#123; public B() &#123; Console.WriteLine(\"B的构造函数\"); &#125;&#125;class Program&#123; static void Main(string[] args) &#123; A a = new B(); &#125;&#125;//最终输出：//A的构造函数//B的构造函数 类的多态性多态是指同一操作用于不同的类的实例，不同的类将会进行不同的解释，最后产生不同的执行结果。 三种实现多态的方法通过继承实现多态性。通过抽象类实现多态性。通过接口实现多态性。 通过继承实现多态可通过virtual和override关键字，基类中通过virtual关键字定义要被重写的方法，子类中通过override关键字重写方法。也可通过new关键字，在子类中隐藏父类的同名方法。override和new的区别： 123456789101112131415161718192021222324252627282930313233343536public class A&#123; public virtual void eat1() &#123; Console.WriteLine(\"A eat\"); &#125; public void eat2() &#123; Console.WriteLine(\"A eat\"); &#125;&#125;public class B: A&#123; public override void eat1() &#123; Console.WriteLine(\"B eat\"); &#125; public new void eat2() &#123; Console.WriteLine(\"B eat\"); &#125;&#125;class Program&#123; static void Main(string[] args) &#123; A a = new B(); a.eat1(); a.eat2(); &#125;&#125;//输出：//B eat//A eat 如果是override，父类方法是被覆盖的，因此在实例a中只有一个B重写后的eat()方法，因此调用的是B的eat()方法；而如果是new，父类方法是被隐藏，还是会有两个方法。而经过类型转换后，子类就会被限制为父类的数据成员和方法，因此调用的就是父类的eat()。 通过抽象类实现多态抽象类abstract表示类中的成员不一定全部实现，可以只有声明部分而没有实现部分，因此抽象类不能实例化。当抽象类派生非抽象类时，必须实现抽象类的所有抽象成员，通过override方法。 通过接口实现多态接口就是完全抽象的成员集合，只有声明没有实现，通过interface 接口名{ //接口体 }来声明一个接口，实现时直接重写相应方法即可。接口中所有的成员都是public的，因此不能再指定访问修饰符。接口中不能出现字段，只能出现方法声明和属性。当有继承了多个接口时，且继承的接口中有同名方法，可通过接口名.方法名来显示指定实现哪个接口。具体代码见书p91。 委托与事件委托委托是一种数据结构，类似C++中的函数指针，作用：可通过委托来调用相应的函数。委托定义格式：[访问修饰符] delegate 返回类型 委托名([参数序列]);编译器编译这行代码时，会自动为其生成一个继承自System.Delegate的委托类，因此委托的定义虽然像是函数，但本质还是类。委托的应用：回调机制、事件处理。123456789101112131415161718192021222324252627//使用委托的步骤//第一步：定义委托类的原型public delegate void MyDelegate(string name);public class Program&#123; //第二步：定义被委托调用的方法 public static void FunA(string name) &#123; Console.WriteLine(\"A \" + name); &#125; public static void FunB(string name) &#123; Console.WriteLine(\"B \" + name); &#125; public static void Main() &#123; //第三步：实例化委托对象，并关联相关方法(相当于让函数指针指向对应函数)。 MyDelegate da = new MyDelegate(FunA); MyDelegate db = new MyDelegate(FunB); //第四步：调用委托，即间接调用委托关联的方法 da(\"张三\"); db(\"张三\"); &#125;&#125;//输出//A 张三//B 张三 注1：因为调用委托就相当于调用其关联的方法，因此方法和委托的参数类型和返回类型要完全匹配。 事件事件是响应用户某个操作的行为，因此就涉及到两个问题：如何响应用户行为？响应后要干什么？如何响应：直接事件名()的格式调用即可，就相当于触发了这个事件。响应后干什么：一个事件对应一个委托类，通过这个委托类的多个实例就可调用多个方法，即完成响应后的操作。具体使用方法:1234567891011121314151617181920212223242526272829class TestEvent&#123; public delegate void MyDelegate(); //定义委托 public event MyDelegate MyEvent; //定义事件，并关联委托类 //定义被委托调用的方法 public void fun1() &#123; Console.WriteLine(\"Hello\"); &#125; public void fun2() &#123; Console.WriteLine(\"Bye\"); &#125; static void Main() &#123; TestEvent te = new TestEvent(); te.MyEvent += new MyDelegate(te.fun1); te.MyEvent += new MyDelegate(te.fun2); te.MyEvent(); te.MyEvent -= new MyDelegate(te.fun2); Console.WriteLine(\"去除一个委托\"); te.MyEvent(); &#125;&#125;//输出：//Hello//Bye//去除一个委托//Hello 注1：事件的声明方法public event 委托名 事件名，且事件必须在类内声明，并通过对象调用，不能脱离对象存在。注2：事件可通过+=, -=来添加、删除委托对象，事件添加的委托对象不同，事件触发后的行为也就不一样。注3：窗体控件中事件的实现也是这个原理，每个控件都有一个事件成员，编写的事件响应方法通过默认委托绑定到事件上，发生事件时，即触发相应的响应方法。 第四章_窗体和控件窗体 窗体程序的启动和停止使用Application类提供的静态方法来启动、停止窗体程序。Run方法：Application.Run(new Form1())，用于在当前线程上启动应用程序消息循环，并显示窗体。Exit方法：Application.Exit()，终止应用程序。注：在程序一开始必须用Run方法来启动Main窗体，不能用.show()方法，这样无法开启应用程序的消息循环，窗口会闪一下就结束了。 打开、关闭窗体 123456789//打开窗体Form fm = new Form();fm.Show();//关闭窗体fm.Close();//隐藏窗体this.Hide();//重新显示隐藏的窗体this.Show(); 窗体常用属性StartPostion：设置窗体的起始位置，一般在构造函数中设置，this.StartPosition = FormStartPosition.CenterScreen。Location：重新设置窗体的位置，this.Location = new Point(500,400)。MaximizeBox：设置是否允许窗口最大化，true/false。MinimizeBox：设置是否允许窗口最小化，true/false。 单文档和多文档窗体多文档窗体(Multi-Document Interface, MDI)是指在一个主窗体中可以包含一个或多个子窗体的窗体，主窗体称为MDI父窗体，子窗体称为MDI子窗体。 对话框对话框用于与用户交互信息，就是弹出的那个窗口，分为标准对话框和自定义对话框。 MessageBox对话框标准对话框，调用MessageBox类的静态Show方法来显示消息对话框，Show方法提供了多种重载方式。123public static DialogResult Show(string text)public static DialogResult Show(string text, string caption)public static DialogResult Show(string text, string caption, MessageBoxButtons buttons, MessageBoxIcon icon) Text：消息框主题显示的文本。caption：消息框的标题。buttons：指定在消息框中显示哪些按钮。MessageBoxButtons枚举值之一，有：OK、OKCancel、YesNoCancel、YesNo等。icon：指定在消息框中显示哪个图标。MessageBoxIcon枚举值之一，有：Question(问号)、Error(错误)、Warning(警告)等。Show方法返回值：DialogResult枚举值，有：None(消息框未返回值)、OK、Cancel、Yes、No等。 常用控件 基本属性(Name)：指定控件的名称，它是控件在当前应用程序中的唯一标识，代码通过该属性来访问控件。Enabled：决定控件是否可用，取值为true时可用，取值为false时不可用。Anchor属性：设置控件与窗体哪个边框的相对距离不变。Dock属性：设置控件始终紧靠窗体的某边框。 一些控件快捷操作1、设置控件对齐方式：按住Shift键选中多个控件，在工具栏中间偏右的位置会有各种控件对齐操作，以Shift键选中的第一个控件为标准。2、设置控件焦点顺序：视图-Tab键顺序，可设置各控件的焦点顺序。3、如何删除事件：在“设计”界面，右上角-属性-事件窗口(小闪电图标)，右键对应事件-重置，然后再在代码界面删除事件方法代码即可。不能直接删除事件方法代码，因为在Form.Designer.cs文件中控件会和事件方法绑定，直接删除事件方法绑定就会出错，因此要连绑定的代码也一起删掉，绑定代码：this.button1.Click += new System.EventHandler(this.button1_Click)。4、如何设置控件属性：不要写在InitializeComponent()函数中，写在构造函数中InitializeComponent()函数的后面。InitializeComponent()是根据“设计”界面自动生成的，每次“设计”界面改变都会重新生成，因此其中写的额外代码就会被删掉。 控件常用事件Click：单击鼠标左键时触发MouseDoubleClick：双击鼠标左键时触发MouseEnter：鼠标进入控件可见区域时触发MouseMove：鼠标在控件区域内移动时触发MouseLeave：鼠标离开控件可见区域时触发KeyDown：按下键盘上某个键时触发KeyUp：释放键盘上的按键时触发KeyPress：在KeyDown之后KeyUp之前触发，非字符键不会触发该事件。 分组控件GroupBox用于将多个控件组合到一起。 123456//遍历GroupBox中的所有控件foreach (Control con in groupBox1.Controls)&#123; CheckBox cb = con as CheckBox; //将循环变量转换为对应的控件类型，之后就可以调用相关属性了 //处理代码&#125; 文本操作控件Label：用于显示文字，通过.text属性设置文本内容。TextBox：用于接收用户的输入，通过.text属性读取用户输入的内容。TextBox常用属性和事件：PasswordChar属性：设置屏蔽密码时所用的字符，设置方法：textBox1.PasswordChar = &#39;*&#39;MaxLength属性：用户最多可输入的字符数，默认为32767个字符，因为使用的是Unicode字符，所以对中文和英文的字符计数方法是相同的，即一个英文字符的长度为1，一个汉字字符的长度也是1。TextChanged事件：表示文本框中的内容更改时触发的操作。RichTextBox：多行文本框，可进行较复杂的文本操作，属性、事件与TextBox类似。 ListBox和ComboBox控件ListBox（列表框）控件和ComboBox（下拉框）控件均用于显示一组条目，以便操作者从中选择一条或者多条信息。两个控件的用法基本一样，区别仅仅在于显示的外观不同，ListBox将所有选项同时显示在框内，ComboBox则是以下拉列表显示。ListBox和ComoBox常用属性：Items：获取控件中的所有项SelectedIndex：获取当前选定的条目在列表中的索引（从0开始），int类型SelectedItem：获取当前选定的条目在列表中的项，返回object，需要.ToString()转化为字符串Items.Add：向列表中添加一项，comboBox1.Items.Add(&quot;xxx&quot;)Items.AddRange：向列表中添加一组项，传入string数组。Items.Remove：移除选项，传入stringItems.RemoveAt：移除对应序号的选项，传入intItems.Clear：移除所有项注：ComboBox允许用户在下拉列表的顶部自己键入内容，通过.text属性访问。 CheckBox控件CheckBox为复选控件，有三种状态：选中、未选中、不确定。两个重要属性：Checked{get; set;}：表示复选框是否被选中，bool类型：true/false。CheckState{get; set;}：表示复选框状态，CheckState枚举类型，有：Checked, Unchecked, Indeterminate三个值，分别表示选中、未选中和不确定。text{get; set;}：表示与复选框相关联的文本。CheckedChanged事件：当复选框状态值改变时触发该事件 RadioButton控件RadioButton为单选按钮控件，一组RadioButton只能有一个处于选中状态。单选按钮是以其所在的容器来分组的，直接添加在窗体上的多个单选按钮默认属于同一组，此时窗体就是容器。若要对单选按钮分组，可以使用GroupBox控件。属性：Checked{get; set;}：表示单选框是否被选中，bool类型：true/false。text{get; set;}：表示与单选框相关联的文本。CheckedChanged事件：当单选框状态值改变时触发该事件 MenuStrip控件菜单控件 第五章_目录与文件管理三种对目录管理的类：Directory类、DirectoryInfo类、Path类，三个类的命名空间：System.IODirectory类的静态方法：Exists()：确定是否存在现有目录，返回bool类型。GetFiles(&quot;e:\\\\test&quot;)：返回指定目录中的文件名称，string数组GetDirectories()：返回指定目录中的子目录的名称CreateDirectory(&quot;e:\\\\test&quot;)：在磁盘指定位置创建目录。 第六章_数据库操作ADO：Active Data ObjectsADO.NET常用的对象模型：(1) SqlConnection对象：建立与数据库的连接(2) SqlCommand对象：执行SQL语句(3) SqlDataReader对象(4) SqlDataAdapter对象(5) DataTable对象：(6) DataSet对象：由表、关系、和约束的集合组成。","categories":[],"tags":[{"name":"C_Sharp","slug":"C-Sharp","permalink":"https://renli1024.github.io/tags/C-Sharp/"}]},{"title":"Computing machinery and Intelligence 阅读笔记","slug":"Paper Notes/图灵论文阅读笔记","date":"2018-01-22T00:22:00.000Z","updated":"2019-05-28T14:25:12.814Z","comments":true,"path":"2018/01/22/Paper Notes/图灵论文阅读笔记/","link":"","permalink":"https://renli1024.github.io/2018/01/22/Paper Notes/图灵论文阅读笔记/","excerpt":"","text":"图灵在1950年发表的这篇《计算机器与智能》的论文，被公认是人工智能领域的开山之作，图灵以其超前的思维、非凡的想象力和严密的逻辑，对“机器能否思考”这个问题进行了深入的阐释，向我们展现了机器的另一种可能。 在论文的前两部分“模仿游戏”和“对新问题的评析”中，图灵提出用一种模仿游戏来替代“机器能否思考”这个问题，即在隔开的情况下，测试者向一个人和一台机器，通过一些装置来随意提问，若超过30%的测试者不能区分出人和机器，即认为机器具有了智能。图灵假定机器的最优策略是努力提供和人一样的答案，从而成功地将“机器能否思考”这个抽象、模糊的问题简化为了一个具体的测试，这是非常合理的。 在论文的第三部分“游戏中的机器”，图灵针对参与游戏的机器进行了分析，他认为这个问题要研究的是“是否存在一台想象中的机器能通过游戏”，而非“是否所有的机器都能通过游戏”，因此只需给出一种可能性即可，之后图灵即针对这种可能性是否存在进行了论述。 接下来，在论文的“数字计算机”和“数字计算机的通用性”这两部分，图灵分析了数字计算机的基本组成和功能，说明了通过编程，数字计算机就可以执行复杂的操作；而且数字计算机具有通用性，并不会因为问题的不同而需要设计不同的数字计算机。因此图灵便将问题再一次简化，变成了“对一个数字计算机，其拥有足够大的存储空间，足够快的计算速度，并对它进行适当的编程，其是否可以通过测试？”。 之后图灵没有急于正面解答问题，而是针对了社会上的一些反对观点，如来自神学的反对、来自意识的观点、来自能力限制的观点等，一一进行了反驳，从而为下文更进一步的论证做出了铺垫。 在文章的最后一部分，为解决上文“数字计算机是否能通过测试”的问题，图灵提出了机器学习的观点，即考虑到为一台数字计算机编程使其能够模仿成人的思维需要花费的大量时间，我们可以从另一个角度来解决问题，即参考教育儿童的过程，对一台机器进行“教育”，同时引入奖励和惩罚机制，使机器自身能够“学习”。这样机器经过不断地训练和学习，终会达到成人思维的水平，从而通过图灵测试，机器即具有了智能。","categories":[],"tags":[{"name":"Paper Notes","slug":"Paper-Notes","permalink":"https://renli1024.github.io/tags/Paper-Notes/"}]},{"title":"算法知识点","slug":"Algorithm/算法","date":"2018-01-20T11:50:00.000Z","updated":"2018-05-13T13:50:00.000Z","comments":true,"path":"2018/01/20/Algorithm/算法/","link":"","permalink":"https://renli1024.github.io/2018/01/20/Algorithm/算法/","excerpt":"","text":"树、图的存储：链式前向星 123456789101112131415 Edge&#123;u,v,next,weight&#125;和head[]辅助数组。 head[]存Edge的序号，为以对应顶点为起点的边。 Edge中，u:起点，v:终点，next：以u为起点的下一条边的序号，无边返回为-1 初始化： edge[i].next=head[u] head[u]=i 遍历： for(int i = head[n];i!=-1;i=edge[i].next)&#123; //操作edge[i].v &#125; 注：无向图edge要开2倍的大小//图的其他数据结构：邻接矩阵(二维数组)、邻接表(Vector&lt;Vector&gt;) 图的遍历：DFS:递归实现，递归完要回退BFS:队列优化 单源点最短路径：SPFA算法(队列优化，不断松弛操作)，可有负边不能负环。或Dijkstra算法，不能负边or负环。一次将单源点到所有点的最小距离都生成了，不断选最小点，更新未选点。 图的最小生成树prim算法：边较少。(不断从所有已选点中选距离最短的相邻未选点)Kruskal算法：边较多。（所有边中不断找最小边，判断是否在一个连通分量中）判断连通分量用到路径优化后的并查集，注意更新parent[]数组一定要更新根节点。关于已选集合和未选集合的实现：可用visited数组来存储状态。 在一些树形动态规划问题中，可能会子结点对应多个父结点，所以开Edge数组要开2倍的大小，而且在前向星便利时要除去父结点的情况。 动态规划要点1.列状态转移方程，常分选择/不选择当前结点两种情况(用二维数组a[n][2]表示)2.一定要将每种情况的值存储下来，这样才能保证效率。用二维数组存↑3.程序上常常用递归或for循环实现 归并排序：【递归】的思想对数组进行排序，包括排序和合并两个步骤。先将数组分为左右两部分，分别排序，再将有序的两部分合并。可用一个辅助数组temp来临时保存数据来实现原数组排序。可用归并排序来求逆序数：一个数组的逆序数【左半部分逆序数】+【右半部分逆序数】+【左半部分比右半部分大的数的个数（在合并左、右时计算）】 二叉树的操作中注意可能会出现单根的情况，会导致树深度大大增加。此时考虑用二叉平衡树。平衡二叉树的简化版-&gt;splay树，伸展树。 一些技巧 若对循环设置一个判断的变量，要注意在每次循环前/后是否需要对变量置为初始值。防止上一次的判断结果影响这一次的判断。eg：&lt;完美的代价&gt;中n为奇数条件pos的使用。 日期的计算：计算从日期a到日期b的天数n最常见如果a算在内但不算b那就是n=b-a。eg:算天数差/经过了多少天/隔多少天如果a和b这两天也算在内就是n=b-a+1如果不算a和b这两天就是n=b-a-1 for()循环，满足一定条件才执行段内语句，要在段内用if语句，不能将条件写到for()内，否则会变成中止条件，而不是continue条件。 一些实际的应用题，可用模拟的方法来求解。确定一个最小的变化单元，不断模拟。eg：&lt;龟兔赛跑&gt;问题中时间一次+1s模拟 对于结束情形的判断，若判断各种结束情况很复杂且题目涉及总数量，可改为直接检测数量，会简化许多 在递归中，若表达式涉及传入递归函数的参数，要先写回传入的变量，再写递归式。防止下一次递归中改变了变量的值。 在进行按位操作时，输入、输出顺序和运算顺序是相反的。但输入输出可都用相反顺序(即正常读入读出顺序)，最后反反得正，结果不受影响。 关于输出空格/空行的控制，for循环下可对循环次数进行检测(首次/末次不输出)，while循环下可设标志位检测。 大while中套小while，小while每次的判断条件也要保证大while的条件，保证小while的循环不会使大while“循环越界”。","categories":[],"tags":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://renli1024.github.io/tags/Algorithm/"}]},{"title":"C++文件操作","slug":"C++输入输出","date":"2018-01-20T11:40:00.000Z","updated":"2018-04-03T09:12:26.000Z","comments":true,"path":"2018/01/20/C++输入输出/","link":"","permalink":"https://renli1024.github.io/2018/01/20/C++输入输出/","excerpt":"","text":"标准输入：cin&gt;&gt;：遇到空格或者换行(回车)停止并丢掉空格，后面的字符会留到下一次cin中读取getline：只有遇到换行才停止(空格会读入)，且回车丢弃掉不写到string中。一次读一行 c++文件IO：都为字节流(以char为载体)，操作单位为字节。读入：get()、read(char[],字节数)输出：put()、write(char[],字节数)get/put一次读一个char；read/write一次读一块，且要传入char数组首地址(char指针)。可直接读取结构体，将其地址转换为char指针。若要写二进制代码也只能用char来写，对char按位操作再后再读入。 文件打开方式：ios::binary与默认方式最主要区别在于对换行符\\n的处理。在Windows中\\n被解释为\\r\\n。binary：原封不动读入\\r\\n。(完全按二进制处理)默认方式：将\\r\\n转化为\\n读入。因此在处理txt等文本文件时，因为有明确的换行概念，所以用默认方式打开，防止多读入\\r。其他文件为保证读入代码的完全一致，要用binary方式打开。","categories":[],"tags":[{"name":"C++","slug":"C","permalink":"https://renli1024.github.io/tags/C/"}]},{"title":"Java笔记","slug":"Java","date":"2018-01-20T09:20:00.000Z","updated":"2019-05-29T01:24:11.754Z","comments":true,"path":"2018/01/20/Java/","link":"","permalink":"https://renli1024.github.io/2018/01/20/Java/","excerpt":"","text":"第一节_基础知识 第二节_String操作 第三节_输入输出 第四节_GUI 第一节_基础知识 api中查的都是类，函数查不到。查包的话直接在首页按字母顺序找即可。 不清楚数组长度的情况下遍历：for(String/int.. a : array ){} 控制double输出格式：decimalformat类DecimalFormat df = new DecimalFormat(“0.0000000”);df.format(xx);“#.#######”与”0.0000000”的区别，【开头位置】出现0时是否用0占位。#舍去0,0则占位。 测试代码执行时间long a=System.currentTimeMillis();//测试代码System.out.println((System.currentTimeMillis()-a)/1000f+” 秒 “); 基本数据类型从低级-&gt;高级为自动类型转换（因为不会丢失数据）高级-&gt;低级有丢失数据的风险，所以需要强制类型转换。但若低级-&gt;高级时有溢出可能，也需在右式强转，否则无法接收溢出的数据。eg：int n=xxx;double d = n n;【若n^2超出int范围，则无法接收溢出数据，在右式即截断了】应为double d = (double)n n; java各数值类型范围类型|字节数|取值范围:-:|:-:|:-:int|4|-2^31~2^31-1(-21亿~21亿)long|8|-2^63~2^63-1(很大)float|4|3.4x10^-38~3.4x10^38(绝对值)double|8|1.7x10^-308~1.7x10^308(绝对值)char|1|-128~127boolean|1|true/false 取绝对值函数：Math.abs(xx)开方函数：Math.sqrt(xx)Arrays.sort(a)：将数组a从小到大排序Arrays.fill(a,xx)：将数组a元素全部置为xx java不显示地支持2进制表示，可用16进制(0x开头)、8进制(0)来代替，直接int即可。但位运算符：&amp; | ^ ~等都是将数转化为二进制后运算。十进制数转二进制输出：Integer.toBinaryString(xx); 建立class数组Class[] c = new Class[n];for(int i = 0;i&lt;n;i++){ c[i] = new Class(); }还要逐个进行初始化 java自定义类比大小实现Comparable&lt;自定义类名&gt;接口并重写int compareTo(&lt;自定义类名&gt; xx)方法，this小于xx返回负值，等于返回零，大于返回正值。 多线程时：实现runnable接口的方式便于多重继承，但在类体内可能无法使用一些Threadl类的方法（如sleep）。继承Thread虽然只能单继承，但方便在类体内使用Thread方法。 第二节_String操作 访问字符串中的元素，返回charString.charAt(index) 0 ~ lenth-1 char[]转换为String：不能直接toString(),会乱码；正确方法为new String(char[]) 字符串string匹配要用equals函数，不能直接==；直接==比较的是内存地址但char可以直接==比较 搜索字符串str.indexOf(char ch,int index)：从index开始搜 分割字符串：str.split(“xx”)：以”xx”分隔str，返回String数组str.substring(int begin,int end)：返回begin~end-1，所以长度为end-begin。 制表符\\t，当它的前面有单词的时候，补的空格和单词长度加起来刚好能被 8 整除。效果：使制表符后面的字符对齐 int,double和string转换 123456int i = 10;double j=1.0;String str_i=Integer.toString(i);String str_j = Double.toString(j);double dd = Double.parseDouble(\"123.2\");String str_j = Double.toString(j); 第三节_输入输出 使用System.in来创建流时，不可关闭。否则会把其他流也一起关掉 关于输入输出中的next()函数：Scanner in的输入函数中：next()只接收有效字符，而nextLine()、nextInt()、nextDouble()等此类函数则会接收包括换行、空格在内的一切字符。所有【next类函数】后接in.nextLine()\\nextDouble()..函数会出错，会跳过in.nextLine()的输入语句。因为nextLine()接收到上一句next()最后的回车符后就结束了。next()不丢弃末尾的回车符，nextline()函数会丢弃。【解决】：(1).next()后单独跟一句nextLine()接收回车符;(2).都采用next()形式，只接收有效字符。另外，在同一个函数中，不管中间隔了多少语句，只要没有输入语句，nextLine()就还会接收next()的回车。 ObjectInputStream()和ObjectOutputStream()用什么顺序写进去的就用什么顺序读出来。而且Object流和其他流不能混用，必须用同类流输入输出。 运用缓冲流BufferedWriter写文件时，write()函数后一定要接flush()函数，缓冲流中的内容才会写到文件中，否则就一直在缓冲流中。 网络流read、writer读取时只有关闭后才能正常显示-1。最好用read(byte[])的方法而非一个一个byte read，因为函数的循环调用也会占用时间。 第四节_GUI 写jframe时，setvisible()函数要写到所有所有组件语句之后。否则一开始不会显示组件，拖动下窗口才会显示。 setvisible(true)目的是使控件可以显示出来,如果该控件已经被显示出来，那么该方法使控件显示在窗口的最前方。但其使用的位置需要注意。setVisible的对象一般是该对象的使用者调用的。如果setVisible在某个控件的内部，那么在setVisible函数后面添加的控件就显示不出来了。原因就在于，setVisible(true)并不是告诉JVM让该控件可见，而是在内部调用repaint方法把各个控件画出来进行显示。如果在控件还没完全添加完其他控件就setVisible(true)那么在方法后面添加的控件都不能显示。 keylistener中的方法是对所有键盘上的按键都会调用。若要针对某个特定的键，可以调用if()方法来判断。 key pressed是按下键，typed是键值传到电脑，released是按键完成释放按键。顺序pressed-&gt;typed-&gt;released。1).pressed和typed一般是紧接着的两个动作，中间不会插其他键的函数。而在typed和realesed间若同时按两个键可能会加另外一个键的函数。2).就是realesed时按键才算按成。3).长按键会有很多pressed和typed，但只有一个realesed。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://renli1024.github.io/tags/Java/"}]},{"title":"编程体会","slug":"Other/编程体会","date":"2018-01-20T09:10:00.000Z","updated":"2018-04-04T01:11:40.000Z","comments":true,"path":"2018/01/20/Other/编程体会/","link":"","permalink":"https://renli1024.github.io/2018/01/20/Other/编程体会/","excerpt":"","text":"先想架构再写程序，把架构写好再往里面填代码。确定好哪些可以重用，哪些可以继承。避免同一段代码写多遍。 一开始不要考虑太多限制(防止限制代码相互影响)，如输入非负/输入必须为数字等等最后再统一考虑限制","categories":[],"tags":[{"name":"Other","slug":"Other","permalink":"https://renli1024.github.io/tags/Other/"}]},{"title":"Matlab笔记","slug":"Matlab笔记","date":"2018-01-20T02:40:00.000Z","updated":"2019-05-29T01:38:16.142Z","comments":true,"path":"2018/01/20/Matlab笔记/","link":"","permalink":"https://renli1024.github.io/2018/01/20/Matlab笔记/","excerpt":"","text":"matlab基本操作 一些操作Tips: clear：清空Workspace clc：清空Command Window 批量修改变量名：shift+enter（只针对变量第一次出现时） 控制输出格式：formatformat short：小数点后4位，之后输出的数都按此格式 digits(4) vpa(x) 一起用控制x输出为4位有效数字。或者直接vpa(x,4) 批量注释：ctrl+R 取消注释：ctrl+T 单步调试：F10 查看变量：who(只列举) whos(附带变量空间大小、字节数等信息) 文件操作： save filename x1 x2 x3 (-append)存储变量值至filename.mat文件，默认存储至matlab.mat文件。-append追加存储，默认为覆盖存储 load filename x1 x2 x3：加载变量，默认为加载所有变量。会覆盖Workspace同名变量 函数.m文件定义function [y1,y2] = fun(x1,x2) y1,y2…是输出变量，直接在函数内参与运算，函数内不要写clear，会清掉输入变量 字符串操作：eval(‘xxx’)：执行字符串所对应的matlab语句str2num(‘xxx’)：将数字字符串转化为数字num2str(xxx)：将数字转化为数字字符串取字符串特定字符：str(2)字符串拼接：str=[str1,str2]abs(‘x’)函数：求字符x的ASCII码char(x)：求ASCII码为x的字符 matlab矩阵操作 矩阵的建立： a=[1 2 3;4 5 6;7 8 9]矩阵取元素： 下标：a(2,3)，行、列皆从1开始 序号：a(8)，按列计数 冒号表达式建立行向量 x=5:2:20 矩阵拼接：直接中括号拼接[ ] 矩阵拆分： b=a(2:4,5:6)，b为矩阵a2~4行5~6列的内容。用end来表示最后一行/列，用冒号：表示所有行/列b=a(:)，按矩阵a元素的【排列顺序】取元素，最终排成列向量 矩阵查找特定元素：num/[rows,cols,vals]=find(A&gt;10)，找矩阵A中所有&gt;10的数。一个返回值为序号，两个返回值即为下标，三个返回值加上值。 矩阵转置：B=A’ 删除矩阵元素，对矩阵整行/整列元素置空，后面元素序号前补 a(2,:)=[] 复制矩阵 repat(&lt;矩阵名&gt;,x,y)，以此矩阵为“一块”复制x行，y列 矩阵计算：直接+-//为右除 \\为左除 /即为乘矩阵的逆.和./为点乘点除，矩阵对应元素的乘除。注意：矩阵的幂^和矩阵元素的幂.^不一样 A(:)表示以一列的方式显示矩阵A中所有元素 size(A,1)矩阵的行数，size(A,2)矩阵的列数 特殊矩阵的建立zeros：零矩阵 zeros(x,y)：x行y列零矩阵ones：1矩阵eye：单位矩阵rand：随机矩阵，元素为0~1随机数的矩阵rand（a,b）表示产生a行b列随机数产生a到b之间的x行y列随机矩阵：a+(b-a) * rand(x,y)randn：均值为0，方差为1的标准正态分布的随机矩阵inv()：求方程组的逆矩阵diff()：计算差分（后项减前项）diag()：构建对角矩阵(输入向量)or从矩阵中取对角线(输入矩阵) matlab绘图 绘制函数图形标识符：legend(‘’,’’,’’)多个图例要依据添加对应数据的顺序依次加入 plot(x,y)最基本的绘图函数画多条函数plot(x,y1,x,y2,x,y3….) 设置线型和线的粗细：plot(x,y,’-.’,’linewidth’,1.5);可通过线型、点型和颜色改变线条外观，粗细设置尤为重要。更改坐标范围：axis([Xmin, Xmax, Ymin, Ymax])、xlim([Xmin, Xmax])、ylim([Ymin, Ymax])坐标轴名字(并设置字体)：xlabel(‘titke’,’fontsize’,12) loglog(),semilogx(),semilogy()函数分别以两坐标轴为log10刻度，x轴为log10刻度，y轴为log10刻度作函数图 plotyy(x,y1,x,y2)双y轴作图 errorbar(y,E)函数，E为1/2误差长度的向量在函数上标明误差(对应离散点作图，且x/y和E向量长度相等) fplot(‘&lt;M文件名&gt;’,[范围])调用M文件函数绘图，有范围限制 ezplot(‘函数表达式’,[x范围],[y范围])隐函数绘图。easy plot，直接写函数表达式即可绘图 polar(x,y)、ezpolar(‘函数表达式’)极坐标绘图，(ρ,Θ) hist(data,&lt;区间数&gt;)绘制频数分布直方图，频数总分数默认10份 对图形的修改可直接在figur面板上进行 解线性方程组 基本概念tol：误差rank(A)：返回矩阵A的秩size(A,1)：返回矩阵A的行数size(A,2)：返回矩阵A的列数null(A)：求齐次方程组的解det(A):求【方阵】的行列式diag(diag(A))：构造矩阵A的对角线矩阵norm(A):求向量A的范数（向量中各元素的平方和再开根号）可用来求两向量的的“差值”norm(A-B) 左除法：matlab一般用inv()&lt;方阵求逆&gt;、pinv()&lt;非方阵求伪逆&gt;来代替左除。左除法分三种情况：恰定方程组：rank(A) = rank([A,b]) = n，方程组有唯一解欠定方程组：rank(A) = rank([A,b]) &lt; n，方程组有无穷解，通解用”特解+对应齐次方程组解”来表示。超定方程组：rank(A) != rank([A,b])，方程组无解，求出的是最小二乘解。 [r]=eig(A)：求矩阵A的特征值r&lt;列向量形式&gt;[x,r]=eig[A]：求矩阵A的特征向量x和特征值r&lt;对角矩阵形式&gt;使Ax=xrmax(max(abs(r)))：找绝对值最大的特征值","categories":[],"tags":[{"name":"Matlab","slug":"Matlab","permalink":"https://renli1024.github.io/tags/Matlab/"}]},{"title":"Lingo笔记","slug":"Lingo笔记","date":"2018-01-20T02:34:00.000Z","updated":"2019-05-29T01:15:56.481Z","comments":true,"path":"2018/01/20/Lingo笔记/","link":"","permalink":"https://renli1024.github.io/2018/01/20/Lingo笔记/","excerpt":"","text":"语法基本语法 变量不区分大小写 语句以分号结尾 以感叹号！开头写注释，同样需要分号结尾 系统默认变量非负，除非用@free/@sub/@slb函数另行说明 lingo一次只能输出一组解，要检验是否有其他解，加额外的约束 Lingo程序结构12345678MODEL: SETS:定义集合和属性，即变量结构 ENDSETS DATA:声明常量, 属性=常数列表 ENDDATA 写目标函数:max=...../min=.... 约束条件END 集合sets和属性的概念QU/1,2,3/:x1,x2,x3,x4;/1..3/QU集合有三个元素，1~3每个元素都有x1~x4四个属性变量，另外x1~x4也都是大小为3的数组。集合就是一维数组，定义二维数组/矩阵：set3(set1,set2)，注意是括号不是/../ 函数集合循环函数FOR、MAX、MIN、SUM、PROD @SUM(setname(i)|对i 的约束 : x(i)表达式)若集合中所有元素都要进行求和，则可以省略下标 @FOR(setname(i)|对i 的约束 : x(i)表达式)若集合中所有元素相同，则可以省略下标 注：@SUM是遍历属性(横向)，@FOR是遍历集合(纵向)，遍历的方向不同 @PROD(s:e) 对集合s中的每个成员,分别得到 表达式e 的值,然后返回所有这些值的乘积 其他函数lingo中函数都以@开头 限定取整数：@gin(x) 0/1变量：@bin(x) @text(‘文件路径’)=’X为’x 输出集或属性的所有值 写在data块中，在model所有操作执行完后才执行 @rand(seed) 产生0~1之间的随机数，seed为种子，0~1随便取 模型类型LP 线性规划ILP 整数线性规划NLP 非线性规划INLP 整数非线性规划MILP 混合整数线性规划IP 二次规划IQP 整数二次规划","categories":[],"tags":[{"name":"Lingo","slug":"Lingo","permalink":"https://renli1024.github.io/tags/Lingo/"}]},{"title":"数据库SQL","slug":"数据库SQL","date":"2018-01-20T02:26:00.000Z","updated":"2018-05-31T02:43:12.000Z","comments":true,"path":"2018/01/20/数据库SQL/","link":"","permalink":"https://renli1024.github.io/2018/01/20/数据库SQL/","excerpt":"","text":"SQL语句 sql语句不区分大小写，且在语句末尾必须输分号。 创建、删除用户时，用户名、密码两边要用单引号括起来。当输入的值为字符串、日期时，也要用单引号括起来。（双引号也可以） 创建数据库：create database xxx;使用数据库：use xxx;mysql数据库相关操作 数据库授权：GRANT ALL PRIVILEGES ON . TO ‘root‘@’192.168.1.102’ IDENTIFIED BY ‘1234’ WITH GRANT OPTION; 防注入：要对用户直接输入的数据做一些处理再写数据库，防止注入。或者用preparedStatement语句防注入，但要注意% 的like查询注入。 清除table的所有数据：truncate table xxx； SQL中两种约束：列级约束(只作用于一列)、表级约束(可作用于多列)六种具体约束： 主键约束（primary key ） 外键约束（foreign） 唯一性约束（unique） 检查约束（check） 缺省约束（default） 只能列级约束 非空约束 (not null) 只能列级约束 数据库三级模式：外模式-模式-内模式模式：表，外模式：视图，内模式：物理结构和存储方式 MySQL数据库 mysql数据库目录：C:\\Program Files\\MySQL\\MySQL Server 8.0\\bindos下用cd C:\\Program Files\\MySQL\\MySQL Server 8.0\\bin 用命令行操作数据库要从dos里打开。找到安装路径下bin文件夹中的mysql.exe，再用登录命令。mysql -u 用户名 -p （回车-&gt;输密码） mysql数据库 “The server time zone value” 异常：mysql数据库时间与系统时间格式不匹配的问题解决：数据库的url后加”?serverTimezone=GMT”：String dburl = “jdbc:mysql://localhost:3306/bookstore?serverTimezone=GMT”;","categories":[],"tags":[{"name":"SQL","slug":"SQL","permalink":"https://renli1024.github.io/tags/SQL/"}]},{"title":"人工智能绪论","slug":"人工智能绪论","date":"2018-01-20T01:20:00.000Z","updated":"2019-05-29T00:15:00.687Z","comments":true,"path":"2018/01/20/人工智能绪论/","link":"","permalink":"https://renli1024.github.io/2018/01/20/人工智能绪论/","excerpt":"","text":"第一章 概论1. 智能的三类观点 思维理论：智能的核心是思维，可通过对思维规律和思维方法的研究来揭示智能本质。 知识阙值理论：智能取决于知识的数量及其可运用程度。 进化理论：智能取决于对外界环境的感知和适应。 2. 图灵测试：判断机器是否具有智能测试者向人和机器提问，若有超过30%的测试者不能区分任何机器，机器则通过图灵测试。存在的问题：仅涉及了结果的比较，没有涉及思维过程。 3. 人工智能的定义用人工的方法在机器上实现智能。研究如何构造智能机器，模拟、延伸和扩展人类智能。 4. 人工智能的发展 孕育期(1956年之前)：数理逻辑、电子计算机、神经网络模型和控制论的出现。 形成期(1956-1970)：达特茅斯会议正式定义Aritificial Intelligence这一术语。 知识应用期(1971-80年代末)：专家系统、自然语言理解、机器翻译等技术的出现。 从学派分离到综合(80年代末-本世纪初)：三大学派的综合集成。 符号主义学派：功能模拟，数理推理，逻辑理论机——数学定理证明程序LT。 连接主义学派：结构模拟，模拟大脑结构的神将网络系统。 行为主义学派：行为模拟，构造具有进化能力的智能系统。 智能科学技术的兴起(本世纪初以来)：自然智能、人工智能、集成智能的协同研究。 第二章 深度学习概论深度学习的起因 AI初期：专家系统AI发展初期，主要的思路是将人类总结的知识用一系列规范的、形式化的规则来表示，然后通过自动化的程序来代替人类处理问题，以知识为基础的专家系统（Knowledge-based expert system）就是这方面的典型代表。专家系统是将专家的经验写成规则，再依照规则推理的方式来模拟专家的思维。专家系统没有获得太大的成功，原因在于系统会明显受到规则数量的限制，规则是有限的，而问题发生时的状况是无限的，用有限的规则处理无限的可能，注定很容易失败。 专家系统-&gt;机器学习因此，“演绎法”的规则推理暂时行不通，“归纳法”就成了另一条出路，基于概率统计的机器学习（Machine Learning）逐渐成为了主流方法，其直接将大量真实世界产生的数据样本交给算法处理，让算法自己在数据中寻找和学习特定的规律，自己“归纳”知识。这种从数据中学习规律的过程也叫做“模式识别”。 机器学习-&gt;深度学习但这之后机器学习也遇到了一些问题，例如，对于朴素贝叶斯、逻辑回归等经典机器学习算法，本质是计算输入样本和输出目标之间的隐含规律/相关性，但计算相关性其实是一个后续问题，在这之前我们首先要确定各个影响因素，而如何表示各个影响因素会严重影响相关性的判断。如要辨别一段语言中演讲者是男人、女人还是小孩，简单机器学习算法的判断依据很可能是音量而非音色和音调。因此设计合适的特征表示在机器学习中是一项非常重要的工作，被称为特征工程。但长期以来，合适特征的选取都非常困难，不仅费事费力，更需要人们提供大量的先验知识以弥补对数据本身挖掘不足而产生的缺陷。因此若要拓展机器学习的适用范围，必须要降低对特征工程的依赖性。因此也就出现了深度学习。深度学习是一种表示学习（Representation Learning）方法，所谓表示学习，就是要让算法在少量人为先验知识的情况下，能够自己从数据中抽取合适的特征。而表示学习目前受到重视的另一个原因是对于人工智能，其目标就是让机器有能力理解我们所在的世界，只有当它学会如何感知和辨别数据背后的各种隐含因素时才能达到这个目标。深度学习最主要的模型是深度神经网络，其思想是通过一些列非线性变换操作把从原始数据中提取的简单特征进行组合，从而得到更高层、更抽象的特征表示，这也对应着我们思维理解的过程。如对于文本分析，先认识各个字母，再认识由字母组成的单词，其次是词组、句子、段落，逐渐由简单向抽象映射。一般有三个以上隐含层的神经网络就称为深度神经网络。","categories":[],"tags":[{"name":"MachineLearning","slug":"MachineLearning","permalink":"https://renli1024.github.io/tags/MachineLearning/"}]},{"title":"VSCode相关","slug":"VSCode","date":"2018-01-20T01:19:00.000Z","updated":"2019-08-02T08:11:18.875Z","comments":true,"path":"2018/01/20/VSCode/","link":"","permalink":"https://renli1024.github.io/2018/01/20/VSCode/","excerpt":"","text":"VSCode左边侧栏的文件颜色，红色：文件有错误，橘黄：文件有warning，土黄：文件被修改（对应git的状态，字母M，modified）文件的最右边有解释说明","categories":[],"tags":[{"name":"Other","slug":"Other","permalink":"https://renli1024.github.io/tags/Other/"}]},{"title":"VSCode_python环境配置","slug":"Python/VSCode_python环境配置","date":"2018-01-19T15:00:00.000Z","updated":"2019-05-29T01:38:46.953Z","comments":true,"path":"2018/01/19/Python/VSCode_python环境配置/","link":"","permalink":"https://renli1024.github.io/2018/01/19/Python/VSCode_python环境配置/","excerpt":"","text":"配置python调试环境1、新建一个项目文件夹，在文件夹中建一个.py文件，再在VSCode中打开文件夹。2、点开最左边侧栏”debug”项(小虫子图标)，再点左上角齿轮按钮配置launch.json即可。注1：launch.json为调试相关的设置，如调试时是否停在第一行，是否自动跳到终端等。注2：调试选项选Python: Terminal(integrated)，使用VSCode的内置环境调试。 关于调试F5调试(F5)不下断点的话和直接运行(ctrl+F5)没区别。调试时F10和F11的区别：F10一条条语句执行(不进入函数)，F11会进入函数内。不要被F10的翻译“单步跳过”所误导，语句还是会执行，并没有跳过。 调试(F5)时自动跳到“终端”而非“调试控制台”的解决办法：在launch.json文件中对应调试项中加 &quot;console&quot;: &quot;none&quot;, 不在最后一行的话句尾要加逗号 pylint对C扩展库报错对于VSCode中Pylint的报错：E1101: Module ‘xxx’ has no ‘xxx’ member’原因：Pylint默认只信任来自标准库stdlib的C扩展，而忽略其他的。模块’xxx’不是stdlib的一部分，因此需要手动将其添加到白名单。解决：1、在项目所在目录新建.pylintrc文件2、参照pylint.config模板，写上默认设置：https://github.com/robot527/python_primer/blob/master/pylint.conf3、文件最后输入extension-pkg-whitelist=xxx(xxx为模块名)注：直接建立.pylintrc文件会提示必须输入文件名，可先建一个空txt文件，再另存为.pylintrc文件即可。","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"https://renli1024.github.io/tags/Python/"}]},{"title":"一些快捷键","slug":"Other/一些快捷键","date":"2018-01-19T08:30:00.000Z","updated":"2018-10-02T21:00:36.380Z","comments":true,"path":"2018/01/19/Other/一些快捷键/","link":"","permalink":"https://renli1024.github.io/2018/01/19/Other/一些快捷键/","excerpt":"","text":"chrome删除记录的网址：windows: shift+delete键; mac: shift+fn+backspace. chrome恢复刚关闭的网页：ctrl+shift+t 输入覆盖后面文字：按insert键切换 Tab向后缩进，Shift+Tab向前缩进","categories":[],"tags":[{"name":"Other","slug":"Other","permalink":"https://renli1024.github.io/tags/Other/"}]},{"title":"Matlab函数文档","slug":"Matlab函数文档","date":"2018-01-19T02:40:00.000Z","updated":"2019-05-29T01:39:02.142Z","comments":true,"path":"2018/01/19/Matlab函数文档/","link":"","permalink":"https://renli1024.github.io/2018/01/19/Matlab函数文档/","excerpt":"本文记录了matlab中一些函数的用法，以便后期查阅。","text":"本文记录了matlab中一些函数的用法，以便后期查阅。 matlab一些函数用法求积分、求差分、求导数数值积分：integral(fun,xmin,xmax)符号积分：int()求差分、求导都是用的diff函数 解常微分方程 符号解：fun=dsolve(‘equ1’,’equ2’,’equ3’)，fun即为最终求得的微分方程，默认对自变量t求导 数值解：ode工具箱 解方程组solve：求方程组的符号解linsolve：求线性方程组数值解fsolve：求非线性方程组数值解 解不等式matlab中没有求解不等式的函数，只能先解对应的等式再画图判断normpdf(x,mu,sigma) x(向量)的正态分布概率密度函数 插值函数 一维插值函数：y=interp1(x0,y0,x,’spline’)，spline为三次样条插值，x0、y0为原始点，x为更密集的需求值点，y为求得的函数值，一般不推荐外插 二维插值函数：z = interp2(x0,y0,z0,x,y,’spline’) 多项式拟合[p]=polyfit(x,y,n) 和 y1=polyval(p,x1)，p为降幂排列的阶数matlab拟合工具箱：cftool 求线性规划问题linprog() 画散点图scatter() 求矩阵行列数size(A)：矩阵A的行、列数；size(A,1)：A的行数；size(A,2)：A的列数。 替换方程中的特定符号subs(fun,{‘a’,’b’},{3,5})对符号方程中特定符号进行替换,可替换为特定数值、其他符号变量；也可替换为数组：得到同阶数组。 设定有效数字位数vpa(xxx, 数字)四舍五入控制有效数字位数，xxx可以是数，也可是表达式。 poly2sym()poly2sym(系数行向量,x)系数行向量-&gt;多项式，各项次数由系数数量控制 一些统计学名词 SSE(残差平方和)：The sum of squares due to error，越接近0越好。点对点误差平方，再加和 MSE(残差平方和均值)：Mean squared error，SSE/n RMSE：MSE开根号 SSR(回归平方和)：预测数据与原始数据均值之差的平方，再加和。点对面 R-square(确定系数)：[0,1]，越接近1越好 Adjusted R-square(矫正后确定系数)：对复杂模型的惩罚 读excel读excel：A=xlsread(filename,sheet,’B3:C4’)，sheet为对应数字写excel：直接粘贴 Min-Max标准化将矩阵的【每一行】进行标准化处理12345A=[1,2,3];A=mapminmax(A,0,1); 标准化到0~1之间[Y,PS] = mapminmax(X,YMIN,YMAX)Y = mapminmax(&apos;apply&apos;,X,PS)X = mapminmax(&apos;reverse&apos;,Y,PS) legend加公式legend(‘样本’,[‘y = ‘,sprintf(‘%.3fx^2+%.3fx%.3f’,p(1),p(2),p(3))]); 产生随机数 rng(2)，设置随机数种子 之后rand()产生的随机数都是一定的","categories":[],"tags":[{"name":"Matlab","slug":"Matlab","permalink":"https://renli1024.github.io/tags/Matlab/"}]},{"title":"LaTex语法","slug":"Other/LaTex语法","date":"2018-01-19T00:15:00.000Z","updated":"2019-03-23T12:52:56.575Z","comments":true,"path":"2018/01/19/Other/LaTex语法/","link":"","permalink":"https://renli1024.github.io/2018/01/19/Other/LaTex语法/","excerpt":"","text":"本文记录了在Markdown中使用LaTex输入数学公式的方法，这样Markdown在一定程度上就可以完全替代office word了。 在markdown中使用LaTex公式1、导入MathJax引擎, 在文章的任意地方加入以下代码即可：&lt;script src=&#39;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML&#39; async&gt;&lt;/script&gt;2、使用LaTex语法写公式即可。注1：MathJax引擎本质是一个js脚本，把页面中的LaTex代码翻译成数学公式。注2：翻译LaTex的工作流程，Markdown先把代码按Markdown语法翻译一遍，因此一些\\和特殊字符的组合，要对反斜杠进行转义，如\\\\{；之后再由js脚本对翻译为数学公式。 公式表示$$公式$$：表示行间公式，单独居中成行\\\\(公式\\\\)：表示行内公式，只占一行。两个斜杠\\\\表示转义。 加减乘除 名称 语法 名称 语法 加 + 减 - 乘 \\times或直接用* 除 \\div 或直接用/ 注：乘除后要加一个空格，和后面的字母区分开 上标和下标使用^表示上标,使用_表示下标,默认将这两个符号后的一个符号作为上下标,如果需要多个符号,则使用{和}括起来.如：z_{i+2} = x^{k+2}+y_2$$z_{i+2} = x^{k+2}+y_2$$ 使用括号LaTex中[ ] (和)都不变，直接输入即可。对于{}，因为其默认作用是将多个元素组合成一个整体，因此需要用\\转义，但因为\\{在markdown中会被转义为单独一个{，因此要使用\\\\{对\\也进行转义如：$$(z) = \\\\{x\\\\}+[y]$$ $$(z) = \\{x\\}+[y]$$ 特殊符号 名称 LaTex语法 示例 分数 \\frac {a} {b} \\(\\frac {a} {b}\\) 平方根 \\sqrt{a*x+b} \\(\\sqrt{a*x+b}\\) n次方根 \\sqrt[n]{a*x+b} \\(\\sqrt[n]{a*x+b}\\) 积分 \\int_a^b f(x) dx \\(\\int_a^b f(x) dx\\) 极限 \\lim_{n \\rightarrow 0} (\\sin{x} / x) \\(\\lim_{n \\rightarrow 0} (\\sin{x} / x)\\) 求和 \\sum_{i=0}^n \\frac{1}{i^2} \\(\\sum_{i=0}^n \\frac{1}{i^2}\\) 求积 \\prod_{i=0}^n \\frac{1}{i^2} \\(\\prod_{i=0}^n \\frac{1}{i^2}\\) 梯度算子 \\nabla \\(\\nabla\\) 上划线 \\bar{A} \\(\\bar{A}\\) 长上划线 \\overline{A\\cup B} \\(\\overline{A\\cup B}\\) 希腊字母希腊字母直接用\\字母名即可，如\\alpha为\\(\\alpha\\)，\\beta为\\(\\beta\\)，\\theta为\\(\\theta\\)具体符号表可见：希腊字母维基百科，注意首字母要小写 矢量运算用\\vec{a}表示矢量符号\\(\\vec{a}\\)，\\cdot表示点乘\\(\\vec{a}\\cdot \\vec{b}\\)，\\times表示叉乘\\(\\vec{a}\\times \\vec{b}\\) 矩阵矩阵的基本语法为$$\\begin{matrix}…\\end{matrix}$$ 1234567$$ \\begin&#123;matrix&#125; 1 &amp; 2 &amp; 3 \\\\\\\\ 4 &amp; 5 &amp; 6 \\\\\\\\ 7 &amp; 8 &amp; 9 \\end&#123;matrix&#125; $$ $$ \\begin{matrix} 1 &amp; 2 &amp; 3 \\\\ 4 &amp; 5 &amp; 6 \\\\ 7 &amp; 8 &amp; 9 \\end{matrix}$$注：因为LaTex中\\表示换行，因此在Markdown中使用\\\\表示 怎样将矩阵用括号括起来使用\\left(和\\right)引入变长括号(当然，其他符号也是可以变长的)123456789$$ \\left( \\begin&#123;matrix&#125; 1 &amp; 2 &amp; 3 \\\\\\\\ 4 &amp; 5 &amp; 6 \\\\\\\\ 7 &amp; 8 &amp; 9 \\end&#123;matrix&#125; \\right)$$ \\( \\left( \\begin{matrix} 1 &amp; 2 &amp; 3 \\\\ 4 &amp; 5 &amp; 6 \\\\ 7 &amp; 8 &amp; 9 \\end{matrix} \\right)\\) \\(\\left|\\begin{matrix}1 &amp; 2 &amp; 3 \\\\4 &amp; 5 &amp; 6 \\\\7 &amp; 8 &amp; 9\\end{matrix}\\right|\\) 矩阵内怎样使用省略号与各种点代码结合可输入省略号，\\cdots横向点，\\vdots竖向点，\\ddtots斜向点12345678910$$\\left[\\begin&#123;matrix&#125; 1 &amp; 2 &amp; \\cdots &amp; 4 \\\\\\\\ 7 &amp; 6 &amp; \\cdots &amp; 5 \\\\\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\\\\\ 8 &amp; 9 &amp; \\cdots &amp; 0 \\\\\\\\\\end&#123;matrix&#125;\\right]$$ $$\\left[\\begin{matrix} 1 &amp; 2 &amp; \\cdots &amp; 4 \\\\ 7 &amp; 6 &amp; \\cdots &amp; 5 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 8 &amp; 9 &amp; \\cdots &amp; 0 \\\\\\end{matrix}\\right]$$ 如何输入多行公式12345678$$ f(x)=\\left\\\\&#123;\\begin&#123;align&#125;x &amp; =&amp; &amp;\\cos(t) + &amp;x\\\\\\\\y &amp; =&amp; &amp;\\sin(t) + &amp;y\\\\\\\\z &amp; =&amp; &amp;\\frac xy + &amp;z\\end&#123;align&#125;\\right.$$ 注1：align用来将多行公式括起来，&amp;用来分割各个对齐的单元注2：\\right.表示右括号不显示$$ f(x)=\\left\\{\\begin{align}x12 &amp; = &amp;\\cos(t) &amp;+1 &amp;x1 &amp;=1 \\\\y123 &amp; = &amp;\\sin(t) &amp;+12 &amp;y12 &amp;=12 \\\\z1234 &amp; = &amp;\\frac xy &amp;+123 &amp;z123 &amp;=123\\end{align}\\right.$$ 关于align中&amp;的对齐方式假设有n个&amp;，会将一行分为n+1列，从左向右两个列分为一组(如1、2列为一组，3、4列为一组…，若有奇数个列，则最后一列单独为一组)。每一行的&amp;数量要保证相同，否则对齐格式会乱。首先明确，LaTex对齐方式包括组内对齐和组间对齐。组内对齐：两列一组，在组内部，第一列向右对齐，第二列向左对齐，即两列在所在位置上向中间对齐。组间对齐：首先，不同行的对应组会根据组的中线进行对齐，因为每行组数是一样的，因此为保证组的中线在同一位置，会统一固定组的长度，因此若公式较短就会出现空白。其次在中线对齐的基础上，第一组会紧靠页左侧，最后一组则紧靠页右侧，紧靠页左/右侧就是将最长的一组紧靠上去，也就是说对于长度不一样的行，较短的那一行是靠不上去的(因为首先要保证组的中线对齐)。 字体选项字体大小：稍微小一点：\\small，再小一点：\\scriptsize，最小：\\tiny大一点：\\huge，最大：huge加粗：\\textbf{xx}，加粗和上划线混用：\\overline{\\textbf{xx}}将公式中的斜体转为正体：在\\\\( \\\\)和$$公式中的字母会自动为斜体，转为正体：\\rm hexo下使用LaTex，若使用了A_{xxx}这种复合下标(下划线和花括号连用)，且前面的公式还出现了下划线(后面公式有下划线没事…)，公式就会出错。原因：hexo下的markdown将两个下划线作为斜体符号进行了翻译，公式就无法正常解析了。解决：在两个下划线前分别加反斜杠，\\_，对下划线进行转义。注：只有这种情况公式中的下划线会被解析成斜体符号，其他情况下则没事，具体原因不很清楚。 更多符号，如逻辑运算、集合运算等可见博文MathJax使用LaTeX语法编写数学公式教程Latex所有常用数学符号整理","categories":[],"tags":[{"name":"Other","slug":"Other","permalink":"https://renli1024.github.io/tags/Other/"}]},{"title":"Markdown笔记","slug":"Other/markdown语法","date":"2018-01-19T00:14:00.000Z","updated":"2019-07-26T12:14:54.979Z","comments":true,"path":"2018/01/19/Other/markdown语法/","link":"","permalink":"https://renli1024.github.io/2018/01/19/Other/markdown语法/","excerpt":"本文主要包括Markdown的特殊语法，一些还与Hexo的特定Markdown渲染方式有关，在网上不是很方便查找，因此记录下来。","text":"本文主要包括Markdown的特殊语法，一些还与Hexo的特定Markdown渲染方式有关，在网上不是很方便查找，因此记录下来。 Markdown语法 md文件头设置1234title: 标题date: YYYY-MM-DD HH:mmtags: 分类标签toc: true 注1：toc为是否生成目录，默认不生成注2：Hexo默认按文章时间来排序 书写格式每一章的大标题用##二级标题，之后依次是###、####。 插入链接/图片 1234567891011121314151617插入链接[显示文本](链接地址)eg : [简书](http://www.jianshu.com)页面内跳转也是相同的语法：[显示文本](#相应目录名)插入图片![](/images/图片名.xxx)将图片直接放到images文件夹下即可。若要控制图片大小，使用HTML标签&lt;img src=&quot;/images/图片名.xxx&quot; width = &quot;300&quot; height = &quot;200&quot; alt=&quot;图片名称&quot; align=center /&gt;在chrome Markdown Preview plus 插件中无法使图片居中，可使用&lt;div&gt;标签&lt;div align=center&gt;&lt;img src=&quot;图片地址&quot; width = &quot;300&quot; height = &quot;300&quot;/&gt;&lt;br&gt;图x 图片名字&lt;/div&gt; 插入表格 123456| Tables | Are | Cool || ------------- |:-------------:| -----:|| col 3 is | right-aligned | $1600 || col 2 is | centered | $12 || zebra stripes | are neat | $1 |靠左对齐、居中、靠右对齐 效果： Tables Are Cool col 3 is right-aligned $1600 col 2 is centered $12 zebra stripes are neat $1 注1：hexo/github的markdown不支持列表list嵌套表格。注2：一级列表中写表格要空一行（否则表格解析不出来），二级列表中就不要写表格了。注3：表格内换行，使用html代码&lt;br&gt;注4：miho主题下表格各列的宽度是根据内容多少来动态决定的，因此最好保证各列内容差不多，多的列用&lt;br&gt;换行，少的列用&amp;nbsp;加空格（只用在某一行里加就行了） 转义符号要使用* _ #等符号，但不想被翻译为格式标识符，可在符号前加反斜杠，如\\_ \\*注1：* _为加粗/斜体格式注2：markdown中反斜杠和普通字母组合时，如\\abc，\\不起作用；但反斜杠和特殊字符组合时，如\\*，\\就会起到转义作用。 零碎记录 分隔线三个星号***表示分隔线 插入代码：行内代码为前后一个上点，插入代码块是前后三个上点，代码块第一个三点后加C进行语法高亮。 插入空格：半角英文空格：&amp;nbsp;全角中文空格：&amp;emsp;，注意单词后的分号。 语法高亮Hexo语法高亮支持C语言，其他语言也凑合着用C语言的语法高亮吧。 VSCode中快捷键ctrl+B添加****，对字体进行加粗","categories":[],"tags":[{"name":"Other","slug":"Other","permalink":"https://renli1024.github.io/tags/Other/"}]},{"title":"English Grammer","slug":"English/Grammer","date":"2018-01-14T00:15:00.000Z","updated":"2018-11-07T22:56:28.378Z","comments":true,"path":"2018/01/14/English/Grammer/","link":"","permalink":"https://renli1024.github.io/2018/01/14/English/Grammer/","excerpt":"","text":"英语语法就是英语组词、造句的规则，可大致分为两部分：词法和句法，因为写作、口语、阅读等部分都是以语法为基础展开的，因此掌握语法对提升整体英语水平是非常重要的。 动词动词是用来表示动作或状态的词汇，属于英语中最重要的词类，因此首先进行介绍。 动词的分类 系动词系动词也称联系动词(Link Verb)，虽然系动词本身有词义，但它不能单独用作谓语，后边必须跟表语（常为adj./adv.），构成系表结构来说明主语的状态、性质、特征。系动词可分为两类：完全系动词：am, is, are由实义动词转变来的系动词：seem, feel, sound, smell等 助动词助动词是用来辅助实义动词的，和实义动词一起构成各种时态、语态等形式，也用于构成否定句和疑问句。助动词有do, have, has等。 情态动词情态动词本身有一定的词义，但不能独立作谓语，只能和实义动词一起构成谓语。情态动词有can, must, may等，主要用法有：表达能力：I can read this section in English.表达态度或语气：You should obey the school rules.表示推测：He may know the answer to this question. 实义动词实义动词为表示具体动作含义的动词，又分为及物动词和不及物动词。 及物动词（vt.）及物动词后面必须跟宾语，主要有以下三种句型：主+谓+宾：最常见的形式。主+谓+间接宾语(sb)+直接宾语(sth)：这种形式也叫做“双宾语”，间接宾语通常是人，直接宾语通常是物，可简单理解为“给某人某物”。eg: He handed me the book over there.（他把那边的书递给我了）主+谓+宾+宾补：这种形式和双宾语的不同在于，宾补是用来补充说明宾语的，宾补和宾语之间具有密切的关系；而直接宾语和间接宾语间则没有什么联系。双宾语一般是v.+ sb.+ sth.，宾补则是v.+ sb./sth.+ adv./adj. (让某人做某事、使某人怎么样..)宾补eg: They asked me to go fishing with them. / I kept the room warm. 不及物动词（vi.）某些不及物动词本身意义完整，后面不需要跟宾语，主要用于主谓结构。eg: I will wait until you come back.若不及物动词后需要跟宾语，则必须在其后面加上介词，再接宾语。eg: I will wait for him until you come back. 动词的时态时态是指动词在各种时间条件下的形式，具体可分为“时”和“态”。“时”：动作发生的时间，可分为现在、过去、将来、过去将来。“态”：动作的状态，分为一般态、进行态、完成态、将来态。“时”和“态”两两组合，即构成了英语中的16种时态。 现在 过去 将来 过去将来 一般时 do, does, am, is, are did, was, were will/shall do, be going to do should/would do, was/were going to do 进行时 am/is/are doing was/were doing will/shall be doing should/would be doing 完成时 has/have done had done will/shall have done should/would have done 完成进行时 has/have been doing had been doing will/shall have been doing should/would have been doing 注1：在将来时中，shall只用于主语是第一人称的情况，will则可用于任何人称。注2：在过去将来时中，should只用于主语是第一人称的情况，would则可用于任何人称。注3：上表中加粗的是较为常用的时态，在写作和口语中需要能熟练运用，而其他的能够在阅读和听力中识别即可。 现在时 一般现在时do, does, am, is, are1、表示经常性、习惯性的动作。2、表示普遍真理和自然规律。3、用在格言警句中。Failuer is never quite so frightening as regret.（比失败更令人恐惧的是懊悔） 现在进行时am/is/are doing1、表示目前正在进行的动作。2、现在进行表将来，包括come, go, stay, arrive, leave等转移动词，以及fly, walk, ride, drive, take(a bus/a taxi)等表示交通工具、行程安排的动词。I’m going.（我要走了） / I’m coming.（我要来了） 现在完成时has/have done sth.1、表示截止到目前已经完成的动作。2、在时间状语从句中，现在完成时可以表将来。When you have rested, I’ll show you the garden.（等你休息好后，我带你去看看花园） 现在完成进行时have/has been doing sth.表示动作从过去某一时间开始，一直持续到现在，并有可能持续到将来。因为完成进行时更强调动作的持续性，所以其只能用于延续性动词，而不能用于瞬时性动词。和现在完成时的区别： 完成进行时强调动作持续的过程(emphasis on duration)，现在完成时则强调动作的结果或成就(emphasis on achievement)。具体来讲，现在完成进行时have been doing强调在一段时期内某项活动的持续性，强调的是动作本身。现在完成时have done则是强调动作产生的结果，而非动作本身。二者的这种区别可通过下面的例句来感受：a. My hands are very dirty. I’ve been painting the house.b. I have painted the house green. The house was white, but now it’s green. 过去时 一般过去时did, was, were1、表示过去某个时间点发生的动作或存在的状态；2、表示过去某个时间段经常性、习惯性的动作3、谈到已故的人的情况时4、用一般过去时表委婉语气，主要有两类情况：表示想要、希望等意义的词：want, hope, wonderedWe wanted to to paly on the playground.情态动词couled, wouldCould I ask about the pay? 过去进行时was/were doing sth.表示在过去某一时间正在进行的动作 过去完成时had done sth.1、表示截止到过去某一时间点已经完成的动作。2、在定语从句中，如果叙述的是过去的事，先发生的动作用过去完成时。 将来时 will do表将来最普通、最自然（spontaneous）的表达方式：对将来的情况作一般说明；表示意愿、保证等。It will help you a lot.I will buy it.注：shall一般用的很少，只在疑问句中和I/we连用：shall + ? + I/weIt looks heavy. Shall I help you? （不能用Will I） be going to do1、表示已经计划好的事I’m going to have a meet with Tom.2、表示基于当前情况、不久就会发生的事情Look at the black clouds! It’s going to rain.I feel bad and I am going to be sick. be doing表将来（现进表将来）与be going to do类似，同样表示已计划好的事。I’m meeting him for lunch on the 17th.“We are meeting tomorrow anyway” -by Tim注：be doing常和特定的日期/时间点连用，因为比be going to do短，所以与日期连用不会说太多单词，表达起来更方便。 Present simple（一般现在时表将来）用于timeables（时刻表），表示一种regualar的意思。（用will do也没错，但用一般现在时更好）The film starts at 10pm. will be doing（将来进行时）将来某个时间点正在进行的动作，强调一种正在进行的状态。 will have done（将来完成式）将来某个时间点前已经完成的动作，强调完成。 will have been doing（将来完成进行时）很少用，基本不会用 一般过去将来时should/would do sth., was/were going to do sth.1、表示在过去来看将要发生的动作He thought books with cartoon illustrations would be more accessible to pupils.（他认为带有卡通图画的课本孩子们会更容易接受） 2、过去将来时的一个重要用法是虚拟语气，这部分将在虚拟语气部分再具体介绍。 口语/写作中的高频时态用法 used to do sth.：过去常常做但现在不做了。 It was the first time that...：那是我第一次…，后接过去完成时。I’ll never forget this trip because it was the first time that I had traveled withou family. would rather do than do：宁愿…而不愿…，注意两个动词都要用原型As a result, people would rather buy new products than spend a large amount of money on repairing old ones. 被动语态动词的语态分为主动语态和被动语态。主动语态表示主语是动作的执行者，直接使用动词原形作为谓语，然后在该动词的基础上施加时态等语法；被动语态表示主语是动作的承受者，以be + 及物动词过去分词作为谓语，时态则通过be的不同形式来展现。 被动语态在口语/写作中的应用被动语态常用作强调动作的承受者，或者出于一些修辞的需要，或者用于转换人称以丰富句型结构。eg: He appeared on the stage and was warmly applauded by the audience.（他出现在舞台上，收到了观众热烈的欢迎。修辞的需要，且句型更丰富）eg: The old professor gave a lecture on American history and was well received.（这位老教授作了一个有关美国历史的讲座，受到了大家热烈的欢迎） 虚拟语气语气是一种动词形式，用以表示说话的意图和态度。 英语中的三种语气陈述语气：陈述语气用来陈述事实、提出疑问、表达感叹等，可以是肯定句/否定句/疑问句/感叹句。祈使语气：祈使语气用于表示请求、命令或警告。其实句的主语是听话的人（you），通常省略。祈使句肯定结构中一律用动词原形，否定结构在动词原形前加don’t。eg: Go and wash your hands.（去洗你的手——表命令）Watch your steps.（走路小心——警告）虚拟语气：虚拟语气是表示假设意义的动词形式，即所说的并不是事实，通常表示主观愿望、假设或建议。 虚拟语气在条件状语从句中的用法虚拟语气最常见的用法是在条件状语从句中，表示一种与事实相反的假设意义：“如果…就…”，根据是与现在/过去/将来的事实相反，谓语动词分为以下三种结构： 从句谓语（带if的句子） 主句谓语 与现在事实相反 一般过去式(did, be的过去式用were) should/would/could/might + 动词原形 与过去事实相反 had + 过去分词 should/would/could/might have + 动词原形 与将来事实相反 should + 动词原形were + 动词不定式 should/would/could/might + 动词原形 与现在事实相反If he studied at this school, he wouldd know you well.（如果他在这所学校学习的话，他会对你很熟悉） 与过去事实相反If I had seen the film, I would have told you about it.（如果我看过这场电影，我早就把电影内容告诉你了） 与将来事实相反与将来事实相反是指：将来发生的可能性很小或者虽有可能发生但说话人主观上不希望发生。If it should rain tomorrow, we would not go climbing. 省略if的用法如果从句的动词是were或谓语动词含有had/should，可将谓语动词中的if省略。这时从句要使用倒装语序，把were, had, should置于句首。eg: Were I at school again, I would study harder.eg: Had it not been for the bad weather yesterday, we would have arrived on time.（如果不是昨天糟糕的天气，我们就准时到了） 含蓄条件句指虚拟语气没有具体地表示出来，而是暗含在副词、介词短语、上下文中，这种句子叫含蓄条件句。常用词有：without, but for, otherwise等。eg: Without electricity, human life would be quite different today.（如果没有电，人们如今的生活将会有很大不同。与现在事实的相反，因此用would be） 虚拟语气表建议eg: He suggests that we should all go to see the film.（他建议我们都去看电影） 虚拟语气用法的固定搭配 利用虚拟语气提建议It is essential that sb. should do sth.：某人很有必要做某事，essential还可用important等词代替。eg: It is essential that we (should) learn a foreign language.It is high time that sb. did sth.：某人早该做某事了，表示“早该做，但还没做”的事情。eg: I think it is high time for government did something to address the problem.（我认为政府早该做些什么来解决这个问题）suggest that sb. should do sth. to...：建议某人做某事来… 利用虚拟语气从反面论述If it had not been for..., sb. could not have done sth.：如果没有…，某人不可能…eg: Take the famous scientist Thomas Edison for example. If it had not been for confidence, he could not have succeeded in producing the first electric lamp after thounsands of times of failure.（以著名的科学家托马斯.爱迪生为例。如果没有自信心，他不可能在失败了无数次之后成功制造出了世界上第一台电灯）Without sth., sb. would do.../sb. could have done sth.：如果没有…，某人将…/某人早该…eg: Without Internet, we would be deprived of the access to the outside world and we could not communicate with each other conveniently no matter how far we are apart.（如果没有互联网，我们将会与外界世界隔离开，我们也不可能不管相隔多远都能这么方便地相互交流）Without sth.还可替换为Were it not for sth. 非谓语动词非谓语动词是动词的非谓语形式，顾名思义，其在句子中不能充当谓语，但除了谓语的其他成分非谓语动词都可以充当，恰当地使用非谓语动词，可以使句子更精炼、结构更丰富。非谓语动词包括不定式、动名词、现在分词和过去分词四种。不定式：to do形式，具有n./adj./adv.的特征，可充当除了谓语的所有其他句子成分。动名词：doing形式，具有n.的特征，就相当于是个名词，直接当作名词使用就行了。分词：现在分词为doing，过去分词为done，分词具有adj./adv.的特征，将其当作形容词/副词来使用即可。 非谓语动词作主语非谓语动词作主语可以避免人称的重复。 不定式作主语不定式作主语表示一种“预期”的动作。Parents are firmly convinced that to send their children to nursery school will have favourable influence on the growth of children.（家长们确信将孩子送到幼儿园对孩子们的成长有利）It is essential/important to do sth.：不定式作形式主语也非常常见。It is quite common these days for young people to have a break from studing after graduating from high school.（高中毕业之后暂停学业一段时间在当今的年轻人中很常见） 动名词作主语动名词作主语没有什么特殊含义，就是表示动作的名词含义。Living in school can save me a great deal of time on the way between home and school everyday.（住在学校能节省我往返于家里和学校的很多时间） 非谓语动词作定语恰当地使用非谓语动词作定语可以使句子更精炼、句子结构更丰富。 不定式作定语：不定式放在名词后作后置定语表示将来的动作：The next train to arrive is from Washington.表动宾关系：I have much work to do. 动名词作定语动名词作定语和其修饰的名词没有逻辑关系，仅仅表示名词的性质、用途。washing machine：洗衣机 现在分词作定语现在分词表示主动的、正在进行的动作。单个现在分词作前置定语，现在分词短语作后置定语。Aid should be given to developing country.Students going abroad can access to another culture.I am a student majoring in Computer Science and Technology. 过去分词作定语过去分词表示被动的、已经完成的动作。单个过去分词作前置定语，过去分词短语作后置定语。Polluted air and water are harmful to people’s health.The extra money obtained from part-time job will strongly support students to continue to their study life.（业余工作挣来的钱将会强有力地支持学生继续他们的学业） 非谓语动词作状语不定式作状语通常起到“连接”两个句子的作用，可以使句子间的关系更紧凑。 表目的：不定式表目的。Goverments ought to make efforts to reduce the incresing gap between cities and countryside.（政府应该努力缩小日益增大的城乡差距） 表结果现在分词表结果：表示事情的影响/作用，可起到非限制性定语从句的作用。Smoking is an addictive menace, posing a health hazard not only for smokers but also for people surrounding them.（吸烟是一种让人上瘾的恶习，不仅对吸烟者的健康构成威胁，同时也会危机他们周围的人）posing a health hazard充当结果状语，也可用定从代替which poses a health hazard...。不定式表结果：通常只限于learn, find, to be told, see等具有“获知”意义的动词，表示一种意料之外的结果。He hurried to the station, only to find the train had left. 表原因：通常用于分词，现在分词表示主动关系，过去分词表示被动关系。Deeply influenced by excessive violence on th Internet, some teenagers go astray.（受网络上过多暴力的影响，一些青少年误入歧途）Not understanding the relationship between two cases, I asked the lawyer about it.（因为不了解两个案件之间的关系，我咨询了律师） 表让步/转折：While enjoying the great benefits brought by the Internet, we have to admit that Internet also has drawbacks.（虽然享受着互联网带来的巨大益处，我们也要承认互联网也有其弊端。while引导了表让步的非谓语动词短语，因为不用写主语，句子更加紧凑） 句法英语中有三种句子类型：简单句、并列举、主从复合句，八种句子成分：主、谓、宾、表、定、状、补、同位语，接下来分别介绍。 句子成分主谓宾不再介绍。 表语：位于系动词之后，用于说明主语的性质、特征、状态等。His father is a model teacher.（他父亲是一位模范教师） 定语：定语是修饰名词的词、短语或从句，单独一个词作定语放在所修饰词的前面，短语/从句作定语放在修饰词后面（后置定语）。There is a stone bridge over the river.（河上有座石桥，stone为定语） 状语：状语是修饰动词、形容词、副词等的成分，状语可表示时间、原因、目的、结果、条件、让步等。These products are selling quickly.（这些产品十分畅销，quickly为状语） 补语：英语中有些及物动词除了要有宾语之外，还要加上宾语补足语，才能使句子意义完整，宾语和宾语补足语一起构成符合宾语。I find English very difficult.（very difficult为补语）We elected Peter our monitor yesterday.（昨天我们选举Peter为我们的班长，our monitor为补语） 同位语：同位语跟在名词之后对其进行解释、限定，来说明名词的具体内容。同位语只作解释限定之用，并不影响句子结构，分析句子成分时可以将其去掉。Tom, our monitor, is a handsome boy.（our monitor为同位语，将其去掉并不影响主句结构。） 简单句简单句就是句子中只有一套主谓结构，句子中各成分是单词或短语充当的（没有从句），因为较简单就再赘述了。 并列句并列句是多个简单句使用并列连词连在一起的句子（句子间地位是平等的）。并列句之间有五种连接关系：同等、转折、对比、因果、选择。 同等关系由and, not only...but also等连词连接起来的，表达一种并列存在的关系。 转折关系由but连接，表示句子间的转折关系 对比关系由while, yet, whereas连接，表示句子间的对比（不那么强烈的转折）。Some of the changes caused by Internet in family life and education are beneficial while others are advese.（互联网引起了家庭生活和教育行业的改变，一些非常有益，另一些却相反）The government has made great efforts to preserve culture legacy, yet there are still many being severly damaged.（政府一直在尽力保护文化遗传，但仍然还有许多正遭受严重的破坏） 因果关系由because, so, therefore连接的，表示因果关系。 选择关系由or, otherwise连接的，表达句子的选择关系。Are you a vegeterian or do you have any special food requirements?（你是素食主义者吗？或者你有什么特别的食物要求吗？）We didn’t know his telephone number, otherwise we would have called him.（我们不知道他的电话号码，否则就给他打电话了） 主从复合句主从复合句由主句和从句构成的，从句充当主句中的某种句子成分（从句依赖于主句而存在），从句可以担任除谓语和补语之外的所有句子成分。从句中的疑问句都要用陈述语序。 从句的分类从句按照其功能可分为三大类：名词性从句、形容词性从句和副词性从句。名词性从句：在句子中起名词的作用，包括主语从句、宾语从句、表语从句、同位语从句，这些从句用法上大致相同，在句子中仅仅是所处的位置不同。形容词性从句：在句子中起形容词的作用，只有定语从句一种。副词性从句：在句子中起负次的作用，只有状语从句一种。 从句的引导词主从句的引导词有三种：从属连词、关系代词和关系副词。从属连词：仅仅起连接作用，不充当任何句子成分。关系代词：除了连接作用，还具有代词的词性，可充当从句中的主语、宾语、定语、表语。关系副词：在从句中充当状语。 主语从句引导词有三种：从属连词、关系代词和关系副词。 从属连词引导主语从句有that, whether，that仅仅用于对事情的描述，而whether还有“是否”之意，that和whether在句子中都不充当任何成分。That she finished reading an English novel surprised us all.（她读完了一部全英文小说让我们大吃一惊）Whether a joke gives pleasure or pain depends on a person’s outlook.（一个笑话会带来快乐还是痛苦取决于一个人的理解） 关系代词引导主语从句有who, what, which, whoever, whatever, whichever, whom, whose等。What the kids need is a peaceful growing environment.（孩子们需要的是一个和平的生长环境）Who will be the leader of the team has not been decided yet.（谁会成为这个队的领头人还没定下来）Whoever leaves the room last outght to turn off the light.（无论是谁最后一个离开教师都应该关灯）Whatever we achieved is attributed to the guidance of our teacher.（无论我们最终取得了什么都归功于我们老师的指导）注1：关系代词/副词放句首用于引导从句，且从句需采用陈述语序。注2：whoever = no matter who, whatever = no matter what, 表达的是一种肯定、确定的语气；而who, what则表达的是一种疑问、不确定的语气，注意体会。 关系副词引导主语从句有When, where, how, why, whenever, however等。When they will start has not been decided yet.（他们还没决定什么时候出发）Where we will have our party is not your business.（我们应该在哪开派对跟你没有关系） It作形式主语若主语从句太长，为避免头重脚轻，可用It作形式主语放最前面，而将主语从句放后面。在写作/口语可用来作连接词，表达观点、看法，常用句型有：It is a pity that...：遗憾的是…It is true that...：的确…It is true that computers have brought our life great conveniences.(的确，计算机给我们生活带来了极大便利)It is believed that...：据认为/人们人为…It is believed that it is a worthwhile task.（人们认为这是一项值得做的工作）It turns out that...：结果证明…It turns out that this method does not work well. （结果证明这种方法效果不佳）It happened that...：碰巧的是…，常用过去式。It happened that he was not there that day.（偏巧那天他不在）上述句型都是that作引导词，因此主语从句就是描述一个事实，下面句型则可以接关系代词/副词，表示更丰富的含义。It doesn&#39;t matter...：…是无所谓/无关紧要的。It doesn’t matter to me whether you go or not. （你去或不去，对我都没关系）It doesn’t matter where charities get their money from: what counts is what they do with it.（慈善机构从哪里筹得捐款的确无关紧要：关键是钱是怎么花的）It makes no difference...：…是毫无区别的。It makes no difference who goes. （谁去都一样。） 宾语从句引导词有三种：从属连词、关系代词和关系副词。 从属连词引导宾语从句有that, if, whether，that有时可省略（为避免语法错误一律不省略即可），if, whether不能省略。从属连词不充当任何句子成分。Everyone agrees that we should reply immediately.（所有人都认为我们应该立即做出回应） 关系代词引导宾语从句有what, who, whom, whose, whatever, whoever, whichever等词。Could you tell me who the teacher is?The polic were checking up on what the man had told him. 关系副词引导宾语从句有when, where, why, how, whenever等词。Having a car, he can get wherever he wants to go without much trouble. it作形式宾语如find, feel, believe, think这种表示观点的动词，后面跟宾语补足语，可以用it作形式宾语。I find it unbelievable that people can accept this sort of behaviour.（人们竟然能接受这种行为，我感到难以置信）I don’t think it unfair that top stars get high income.（我不认为顶级明星获得高收入不公平） 宾语从句的否定转移主句的谓语动词是think, believe, suppose, expect类似表示观点的动词，并且主句是第一人称，则从句的否定要转移到主句上来（出于礼貌，英语中常常否定自己，而非否定别人）。I don’t think he will come to my party.I don’t think it’s a good idea. 表语从句表语从句的结构比较简单，就是跟在系动词后面，表示主语的性质、特征。 从属连词引导表语从句有that, whether, as, as if, as though, because，注：if不能引导表语从句。My idea is that we should start making preparation right now.（我的想法是我们马上开始做准备工作）The question is whether the film is worth seeing again.（问题是这部电影是否值得再看一遍）The fact is that he left.（事实是他离开了） 关系代词引导表语从句有who, whom, whose, what, which。What I want to know is which plan we should choose. 关系副词引导表语从句有where, when, how, why, because。The local welfare office is where the government dispenses many of its services.（当地的福利机构就是政府提供很多服务的地方）He had seen the film before. That is why he did not see it last night.（他以前看过这部电影，所以他昨天晚上没有去看）He did not see the film last night. That is because he had seen it before. 半系动词引导表语从句半系动词引导表语从句多和as if连用，使用虚拟语气，表示“好像”的意思。The young man with long hair looks as if he were a girl.（那个长头发的年轻人看起来好像一个女孩）She seems as if she had done a great thing.（她看起来好像做了一件大事） 定语从句在主从复合句中，修饰某一名词或代词，充当定语成分的句子称为定语从句。被定从修饰的词称为先行词，定语从句的引导词有关系代词、关系副词和“介词+关系代词”。 关系代词引导定语从句有that, which, who, whom, whose，注：没有what。which指代物，who, whom指代人，that, whose指代人和物都可以。which, that在从句中担任宾语成分时可以省略，担任主语、定语成分时不能省略。关系代词在从句中可充当多种成分：作主语：引导词为who, which, thatMost of the workers who come from the country work much harder.（大部分来自乡村的工人工作都非常努力）可与非谓语替换：Most of the workers coming from the country work much harder.作宾语：引导词为whom, which, thatThe person (whom) you should write to is Mr.Ball.（你应该写信的那个人是波尔先生）注：关系代词在从句中作宾语时，可以省略作定语：引导词为whoseI have a friend whose father is a mayor.（我认识一位父亲是市长的朋友）We lived in a house whose window faces south.（我们住在一个窗户朝南的房子里） 关系代词that和which不能互换的情况 关系副词引导定语从句有when, where, whyJuly is the month when the weather is hot.（七月是天气热的时候）Do you remember the reason why he left early?（你还记得他早早离开的原因吗？） 介词+关系代词的用法I visited the city in which my father had worked for 10 years.（我去了我父亲工作了10年的那座城市）Every student should do the assigned tasks for which they are responsible independently.（每个学生都应该独立完成被分配的任务）注：当介词短语是固定搭配时，介词短语作为一个整体不能拆开，定语从句还是用“关系代词”引导。常见短语有：look for, take care of, listen to, look forward to, break into等，可以主观感受到短语拆开会特别别扭。This is the baby whom you will take care of.（这就是你将要照顾的那个婴儿）It is the right book that she was looking for.（这就是她一直在寻找的书） 非限制性定语从句非限制性定语从句和主句的关系不是很密切，只是对先行词作附加说明，或是将整个主句作为一件“事”来指代。非限制性从句和主句间用逗号分隔开，引导词有as, which。The apple tree, which I planted last year, has not borne any fruit.（这颗苹果树是我去年种下的，还没有结出果实）He married her, which was natural.（他和她结婚了，这是很自然的事）He changed his mind, which made me very angry.（他改变主意了，这使我很生气） 同位语从句同位语从句修饰词一般是“抽象”名词，通常有：news, idea, fact, question, doubt, hope, message等，同位语从句用来对抽象名词作解释说明。注：因为同位语从句有连接词，所以一般不用逗号分隔。 从属连词引导同位语从句有that, whether，注：if不能引导同位语从句。They were all very much worried over the fact that you were sick.（对你生病这件事，他们都很担心）Where did you get the idea that I could not come?（你在哪儿听说我不能来的消息？） 关系代词引导同位语从句有what, who, which。I have no idea what size shoes she wears.（我不知道她穿几号的鞋）The question who will take his place is still not clear.（谁接替他的位置还不清楚） 关系副词引导同位语从句有how, when, where。We haven’t yet settled the question where we are going to spend our summer vacation.（到哪儿去度暑假，这个问题我们还没有决定）We can’t solve the problem how we can travel faster than light.（我们解决不了如何超过光速这个问题） 分隔式同位语从句如果同位语从句的长度大大长于整个主句，或者主句结构非常简单，则同位语从句可以不紧挨着所修饰的名词，而将其放于整个句子的后面，起到平衡句子结构的作用。The thought came to her that maybe she had left the door open when she left home.（她突然想起她离开家时可能没把门关上）The news got about that he had divorced his wife. 同位语从句的固定搭配There be + no doubt that...：毫无疑问的是There is no doubt that you will succeed in your scientific research.（毫无疑问你在科研方面会取得成功）There is no doubt that Internet has brought our life lots of benefits.（毫无疑问互联网给我们生活带来了巨大的好处）on the ground that...：是因为…，= becauseI came to see you on the ground that Mr Anderson said that you were interested in our project.（我前来看你，是因为安德森先生说你对我们的工程很感兴趣）with the exception that...：除…之外，还有一种用法是with the exception of...(接词组)These components are exactly the same, with the exception that they listen to different JMS topics.（这些组件完全相同，只是它们监听不同的JMS主题） 状语从句状语从句在主句中作状语，可以修饰主句中的动词、形容词或副词。状语从句根据它们的含义分为时间、地点、原因、条件、目的、结果、方式、让步、比较这九类，虽然种类较多，但因为状语从句和汉语的结构、用法相似，因此难度不大。关键是要掌握各类状语从句的特殊连接词，在写作和口语中可以使句式更丰富。 时间状语从句when, while, after, before：常用引导词。till, until：两个词用法相同，都为“直到…，”用于肯定句中：He will be working until 5 o’clock.（他将一直工作到五点钟。）表示动作的终点，且动词不能是瞬时性，只能是延续性动词。用于否定句中：She didn’t sleep until eight.（她八点钟才睡觉。）表示动作的起点，延续性/瞬时性动词都可以。as soon as, the moment, the instant：一旦/一…就…，表示两件事紧接着发生。as soon as用法比较灵活，可用于各种时态中，在句子中的位置也不固定。The moment you do this thing, you will lose control.（一旦你做了这件事，你就会失去控制）= you will lose control as soon as you do this thing.I’ll return the book as soon as I have read it.（我一读完就把书还回去）As soon as I went in, Tom cried out with pleasure.（我一进门，Tom就高兴地叫起来） 地点状语从句引导词有where, wherever。A new school building was put up where there had once been a theatre.（一座新的学校在以前的剧院处建成了） 原因状语从句because, science：常用引导词，表示“因为”Since you have seen both fighters, who do you think will win?（既然两个拳击手你都见过了，你认为谁会赢？）= Seeing both fighters, who do you think will win?given that, considering that：鉴于/考虑到Given that they are inexperienced, they have done a good job.（考虑到他们没有经验，他们已经做的很好了） 条件状语从句if, unless：if表示如果，unless表示如果不/除非，= if notYou will be late if you don’t leave immediately.（你如果不立刻出发的话你就会迟到了）= You will be be late unless you leave immediately.if引导条件状语从句的时态：有主将从现，主情从现（情态动词），主祈从现（祈使句），虚拟语气这几种情况If it stops snowing, we can go out.（如果不下雪了，我们就可以出去了）主情从现If Bill comes, ask him to wait for me.（如果Bill来了，告诉他等我下）主祈从现If I were you, I would invite him to the party.（如果我是你，我会邀请他参加聚会）虚拟语气as long as：“只要…”，时态比较灵活，从句一般现在时，主句可以一般现在时，也可以将来时。As long as I deliver the goods, my boss is very happy.（只要我做好本职工作，我的老板就很高兴）As long as my heart still beats, I will go on working for the people.（只要我的心脏还在跳动，我就要为人民工作）on condition that...：在…的条件下I will come on condition that John is invited.（如果约翰被邀请了，我就来）He spoke to reporters on condition that he was not identified.（在不披露身份的条件下，他接受了记者的采访）supposing that...：假设Supposing that you come into a lot of money, what would you do then?（假设你得到许多钱，然后你会怎么办）Supposing that white were black, you would be right. （假如白色能变成黑色，那你就是对的了）虚拟语气 目的状语从句so that, in order that：目的是/为了…John shut everybody out of the kitchen so that he car prepare his grand surprise for the party.（约翰把其他人关在厨房外，目的是烹饪出令人惊喜的东西）for fear that, in case...：以免/唯恐…He worked hard for fear that he might be fired by the boss.（他拼命地干活惟恐被老板解雇）Emergency services were on hand in case there was any trouble.（紧急服务已经就位，以防发生任何问题） 让步状语从句though, although：尽管，即使They are still working in the field although it’s raining.（虽然在下雨，但他们仍在地里干活。）in spite of the fact that...：尽管…In spite of the fact that they don’t have a lot of money, they still decided to help him.（尽管他们也没什么钱，但还是决定帮助他）In spite of the fact that government has made great efforts to preserve culture legacy, there are still many being severly damaged.（尽管政府一直在尽力保护文化遗传，但仍然还有许多正遭受严重的破坏） 结果状语从句so that..., so...that, such...thatHe made such rapid progress that before long he began to write articles in English.（他进步很快，不久后就开始用英语写文章了） 方式状语从句as if：好像She speaks English fluently as if she were a native speakers.（她讲着流利的英语就像是当地人一样）the way...：…的方式I won’t talk to her the way Tom did.（我不会像Tom那样和她讲话） 比较状语从句as...as, not so...asThe construction industry is no longer as depressed as it was.（建筑业不再像以往那样萧条了）This new transformation is at least as consequential as that one was.（这一新的转变至少和那次一样重要） 强调句强调句是一种修辞，为了表达自己的意愿和情感，其不属于句子的结构，将强调句成分去掉后，句子依然成立（仅仅是情感没有以前强烈了而已）。强调句的类型有以下几种： It is/was + 被强调部分 + that/who +其他部分It is eating too much junk food that is harmful to people’s health.（正是因为吃了很多垃圾食品人们的健康才会收到损害）It is what charities do with the money, ranther than where they get it from that we should be concerned about.（我们应该关心的不是是慈善机构从哪里得到的钱，而是钱是怎么花的） do/did/does + 动词原形I do support the idea that ：我非常同意…I do support the idea that smoking is harmful to people’s health and it violates the rights and freedom of nonsmokers.（我非常赞同吸烟危害人们的健康，并且它侵犯了不吸烟人的自由）I do appreciate your timely help.（我非常感谢你的及时帮助）Distance-learning programs or attending in a college are all wonderful for individuals if they do really want to acuqire knoeledge.（如果人们真的想学知识，远程教育还是上大学都是不错的方式） 强调句和主语从句的区别强调句和主语从句都有It is/was ... that的结构，如何区分呢？一是根据句子本身的意思；此外可以将It is和that去掉，如果句子仍然成立，就是强调句；句子不成立就是主语从句。因为强调句只起强调作用，并不充当句子结构；而主语从句的It is是句子的形式主语和谓语，that是从属连词，这些都充当了句子结构，因此不能去掉。It is stability that destroys people’s ambition and barricades people’s steps.（安稳摧毁了人们的野心、阻挡了人们的脚步）强调句It is apparent that smell can evoke strong emotional responses.（很明显气味能唤起强烈的情感反映）主语从句 倒装句英语中最基本的结构是主、谓结构，倒装就是将这种语序加以颠倒，即谓语在主语前面，用以表示一定的句子结构或强调某一句子成分。 完全倒装完全倒装就是将谓语和主语完全颠倒过来。 There be句型There be句型就是最常见的完全倒装结构。There is a tree in front of the house. 介词短语位于句首时介词短语位于句首用于强调介词短语，这时要用完全倒装。In front of the house stands a tree.（房前有一个树）Along the dusty road came a group of tourists.（沿着尘土飞扬的路来了一对旅客） 部分倒装部分倒装只是将助动词、情态动词提到主语前面，实义动词还是放在正常位置。 only + 状语放句首，后面的句子要部分倒装。Only in this way can we finish the work.（只有这样，我们才能完成工作）Only after I had read the letter did I realize that I had misunderstood him.（看了信之后我才意识到我误解了他）Only when students are educated to behave well, can the sound progress of society be maintained, and positive social oreder be established.（只有教育好学生，才能使社会保持良性发展，建立积极向上的社会秩序） as, though引导的让步状语从句可以用部分倒装，但提前是被强调的部分，而不是助动词。Child as he is, he is very brave.（他虽然是个孩子，但非常勇敢）Tired as he was yesterday, he finished the task on time.（尽管他昨天很疲惫，但还是按时完成了工作） 独立主格结构独立主格结构由逻辑主语和逻辑谓语构成，其主语和主句的主语并不相同，作为句子的一个独立结构而存在。逻辑主语可以为名词或代词，逻辑谓语可以为分词、不定式、形容词、副词、介词短语等，注意其没有真正的谓语。非谓语动词在句子中作为状语而存在，大多可以转化为普通的状语形式，之所以将其单独抽出来是为了更好地对状语进行强调。 正常形式的独立主格结构Time permitting, I will go to see you.（时间允许的话，我会去看你）主语+现在分词构成独立主格结构。The last guest to arrive, our party will start.（等最后一个客人来了，派对就开始）主语+不定式。The meeting over, people soon left the metting room.（会议结束后，人们很快离开了会议室）主语+副词独立主格和非谓语动词作状语的不同：非谓语动词的主语和主句的主语是相同的，而独立主格的主语和主句是不同的。 with/without引导的独立主格结构这种结构多用作伴随状语，表示状态。He stood in the rain, with his clothes wet.（他站在雨里，衣服都湿了）With his homework done, Tom went out to party.（做完作业后Tom去参加派对了）The boy looks sad, with so much homework to do.（要做很多作业，男孩看上去很不开心）这种结构在写作中也经常用到：With the steady growth in the country’s economy as well as the people’s living standard, people attach more importance to education.（随着国家经济的增长和人民生活水平的提高，人们更加重视教育）表示一种趋势、趋向With the average temperature continuously rising, glaceries begin to melt and sea level gets higher than before.（随着平均气温的不断升高，冰川开始融化，海平面比以前上升了）Recently, this phenomenon has been brought to public attention, with people stading on both sides.（近来这个现象得到了公众的关注，人们持两种对立的观点）","categories":[],"tags":[{"name":"English","slug":"English","permalink":"https://renli1024.github.io/tags/English/"}]},{"title":"英语介词","slug":"English/英语介词用法","date":"2018-01-13T11:35:00.000Z","updated":"2018-10-08T23:24:26.574Z","comments":true,"path":"2018/01/13/English/英语介词用法/","link":"","permalink":"https://renli1024.github.io/2018/01/13/English/英语介词用法/","excerpt":"","text":"英语的词类优势就是介词，可用介词来扩展词汇的意义。 under 和 underneath：underneath是一个东西完全在另一个东西下面，一点都不能露出来；under则只是在下面就可以。因此underneath的适用范围要比under小，但也更具体。 介词的本质介词是用来表征对象间关系的，可以表征三种关系：空间关系：the cat sat on the mat, over his shoulder时间关系：on Thursday, in November抽象关系：for your eyes only 空间关系：是最基本的关系，有点、线/面、体三种形式。点：at the corner，corner可抽象为一个点线：on my way home，way可看成线的关系。面：on the table体：in Shanghai，把上海想成一个大城市，人很渺小，处于这个大城市之中。因此介词的不同反应了老外对后面词画面上的一个观感。 时间关系：是由空间关系引申而来的。点：在某个时间点用at，at that moment, at 9:15。面：面相比点要大一点，用on，on Monday, on the day。体：在一段比较长的时间中，人被时间“包裹”着，in May，in the Stone Age, in 2017，during…。补：因此介词的不同用法可以有不同的修辞功能，比如在周末，美国人用on the weekend/over the weekend；英国人则用at the weekend。这实则表明了两种文化的差异，即英国人比美国人认为周末要短。 抽象关系：同样由空间关系引申而来。on：空间上表“面”，the phone on the table，因此会有一种接触、支撑之意。即引申出来“压迫，背负”的意思：there is a lot of pressure on me，the difficult on them，He is short of brains. He is short on brains. 后一句比前一句有更大的鄙视意味（太short了以至于都压着brains了）。 of，for，to：to：有方向性，由A到B。外国人一碰到to这个介词，脑海里就会有由A向B的这个方向性。I’m going to China.I give the book to him.Ten to three.I look forward to your reply.I am addicted to the smoking.devoted to learning.reporter should stick to their ethic for：没有空间意义，更多是抽象意义。和to比，for表示一种授予关系里的接收方，强调授予关系。to强调空间移动，for强调角色的获利关系。The cake is for Tom. 蛋糕是留给Tom的，还未到Tom的手里，只是表明在人们意愿上蛋糕是留给Tom的。Money is important to me.Money is important for me. for比to更为严重，我更加地依赖钱。Smoking is bad for health. health是smoking的“获利方”。I did this for him. 这件事是我为他做的，专门为他做了某事，他属于获利方，强调目的性。I did this to him. 这件事是我对他做的，带有动作的指向之意，多指坏的不好的事情。 talk to &amp; talk with：with在空间中表示“附近”的意思，双方向；to则是单方向。talk with：你一句我一句，to则是单方向一个人讲。 of：of表示一种从属关系，表示不可或缺的一部分。The roof of the house. 房间的屋顶The roof for the house. 屋顶被刮掉了，专门又为这个房间买了个屋顶。 a day for mourninga day of mourning哀悼日的翻译肯定要用第二个，因为第一个仅仅表示这一天是用来哀悼的，哀不哀悼都可以；第二个则表示这一天全天就是哀悼，这一天和哀悼之间的关系更为强烈。 The answer to the question.The answer for the question.The answer of the question.to最为常用，answer和question的关系有点像solution和problem，key和door的关系，有一定指向性的。因此都是solution to the problem，key to the door。 He is like a brother to me.He is a brother of mine.第二个就是指真实的哥哥，第一个就只是像一个哥哥一样。 out of：常可当成独立介词来使用，有from的意思，表示一种动态的过程。He is walking out of the buliding.look out of the windowlook out the window如果仅表示“向窗外看，那有….”，强调结果，则用look out。若强调人站在屋里向窗外看这个过程（想象视线从屋里“动态”地射向外面），则用look out of。 over：想象一种抛物线的意象，fall over“摔倒”的感觉。 throughout：空间上意象就像穿隧道一样，全程贯穿。 《English preposition explained》 介词虽然能帮助理解，但还是有很多动词+介词构成的动词短语，没有多大规律可言，因此还是要靠长期的积累和记忆。","categories":[],"tags":[{"name":"English","slug":"English","permalink":"https://renli1024.github.io/tags/English/"}]},{"title":"English Grammer2","slug":"English/Grammer2","date":"2018-01-13T00:15:00.000Z","updated":"2019-05-29T01:32:39.447Z","comments":true,"path":"2018/01/13/English/Grammer2/","link":"","permalink":"https://renli1024.github.io/2018/01/13/English/Grammer2/","excerpt":"","text":"本篇笔记是根据《英语语法新思维初级教程》整理而来。 英文五种基本句型 英语句子可分为两部分，主语：表示我们要陈述的对象，以代词、名词或名词短语来充当。谓语：说明主语做什么，或说明主语的状况，以动词来充当。因此我们造句时，首先要考虑我们要陈述的对象是什么，写出主语；再考虑主语的动作或状态，写出谓语；再根据谓语动词的不同形式，选用以下五种句型，再填入相应的其他成分，即能造出一个句子了。 主系表I am a boy. 我是一个男孩Learning English is important. 学习英语很重要He looks happy. 他看起来很高兴。补：主系表结构主要用于描述主语的性质或状态，由特殊的系动词来连接，常用系动词：look 看起来是sound 听起来是smell 闻起来是taste 尝起来是feel 感觉是seem 似乎是appear 似乎是become 变成为turn 转变为 主谓Internet dating hurts. 网恋有害The fire is burning. 火在燃烧He died. 他死了补：主谓结构主要由不及物动词（vi）来引导，动词本身就可表达完整的意思，就不需要宾语了。 主谓宾These children are playing football.I love English.补：最常见的句型，由及物动词（vt）来引导，动词本身意思不完整，必须加上动作的施加对象（宾语）来构成完整句子。 主谓+间接宾语+直接宾语Chatting online will give you a lot of fun. 网上聊天会带给你很多乐趣He lent me ten yuan. 他借了我10元I will buy you a meal. 我会请你吃顿饭补：这种句型由双宾动词来引导，其后面接两个宾语：间接宾语通常是人，表示动作的接受者；直接宾语通常是物，表示动作的承受者。间接宾语和直接宾语合起来成为双宾语。 主谓宾宾补We can call Internet addicts a Webaholic. 我们可以管上网成瘾的人叫网虫。We elected John our chairman. 我们选举John为我们的主席。I found this answer wrong. 我发现答案是错的You can leave the door open. 你可以把门开着补：这种句型由宾补动词来引导，动词后面只接宾语无法表示完整的意思，必须再加上补充说明宾语的补足语来构成。补2:区分双宾语和宾语宾补，看两个词之间是否是修饰关系（可用is连接）-&gt;宾语宾补，还是动词引导的逻辑关系-&gt;双宾语。 英语中所有句子都是由五种句型演变而来，具体选用哪种是由动词的类型来决定的。","categories":[],"tags":[{"name":"English","slug":"English","permalink":"https://renli1024.github.io/tags/English/"}]},{"title":"Oral","slug":"English/口语","date":"2018-01-12T00:15:00.000Z","updated":"2019-05-29T01:36:37.026Z","comments":true,"path":"2018/01/12/English/口语/","link":"","permalink":"https://renli1024.github.io/2018/01/12/English/口语/","excerpt":"","text":"Meeting 普通问候Hello：较正式Hi：比较随和Hey：好朋友间 初次见面Nice to meet you. - Nice to meet you, too. / Me too. 长时间没见Long time no see. - Yeah.It’s been a long time.Good to see you again. - Me too. 意外的碰面What a small world. - Yeah, it’s really a small world.Fancy meeting you here. - Me too. 询问近况How are you (doing)? / How’s everything? / How is it going?情况好：Fine, thank you./ Good.情况一般：Same as usual./ Just so so.情况不好：Bad. IntroduceIntroduce yourself 姓名My name is Ren Li, you can call me Li. 籍贯I’m from China = I come from China. 爱好I like sth. / I like doing… 自我介绍前加上自荐语：Allow me to introduce myself. Introduce others 介绍一个人This is + 姓名 给两个人相互介绍This is my friend Nick, and that is roommate Wenshuo Zhang. 致谢用语 一般性的感谢Thank you. / Thanks.Thank you very much. / Thanks a lot.It’s very kind of you.（你真好） Thanks for sth/doing sthMany thanks for the lovely flowers.（花很漂亮，非常感谢。）I’d love to go to the party. Thanks for inviting me/Thanks for your invitation.（我非常愿意去参加派对。谢谢你邀请我。） 正式场合I really appreciate your help.（非常感谢你的帮助）Thank you for what you’ve done. 回答别人的感谢That’s all right. / Not at all.（不用谢）You’re welcome.（不客气）Forget it. （不值得一提） 别人帮忙没成功，还是要感谢Thank you just the same.（不管怎样，还是要谢谢你） Commonly-used Expression I am not buying it我不相信你的观点。 Sorry, I didn’t catch that.抱歉，我没听清/没听到 It’s not the end of the world.安慰用语 Make yourself at home.请自便，把这里当作你家一样。 No hard feelings.我没有其他意思（当你说了一些比较直接的话怕伤害到别人时） Thanks in advance.提前谢谢你","categories":[],"tags":[{"name":"English","slug":"English","permalink":"https://renli1024.github.io/tags/English/"}]},{"title":"环境配置","slug":"Other/环境配置","date":"2018-01-05T01:20:00.000Z","updated":"2019-08-02T12:47:33.585Z","comments":true,"path":"2018/01/05/Other/环境配置/","link":"","permalink":"https://renli1024.github.io/2018/01/05/Other/环境配置/","excerpt":"","text":"VSCode配置 对于左侧工作区中的文件，单击一下是浏览模式，下一次再打开其他文件就会覆盖掉窗口；双击是编辑模式，窗口会一直存在。 code-&gt;preferences-&gt;setting 调出设置界面，user settings：针对所有项目修改； workspace settings：只针对当前项目修改，当前目录下会生成一个.vscode文件，包含了设置信息。 设置视线区域内自动换行：&quot;editor.wordWrap&quot;: &quot;on&quot; Mac python nltk.download()报错：certificate verify failed (_ssl.c:749)解决： 12cd /Applications/Python 3.6 ./Install Certificates.command Mac下VSCode配置LaTex: 下载MacTex(Text live的Mac优化版) VSCode中下载LaTex Workshop拓展 对Workshop进行中文适配, 打开设置页面, 在右侧设置修改区贴上如下代码即可(设置Workshop默认编译程序为xelatex)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&quot;latex-workshop.latex.tools&quot;: [ &#123; // 编译工具和命令 &quot;name&quot;: &quot;xelatex&quot;, &quot;command&quot;: &quot;xelatex&quot;, &quot;args&quot;: [ &quot;-synctex=1&quot;, &quot;-interaction=nonstopmode&quot;, &quot;-file-line-error&quot;, &quot;-pdf&quot;, &quot;%DOC%&quot; ] &#125;, &#123; &quot;name&quot;: &quot;pdflatex&quot;, &quot;command&quot;: &quot;pdflatex&quot;, &quot;args&quot;: [ &quot;-synctex=1&quot;, &quot;-interaction=nonstopmode&quot;, &quot;-file-line-error&quot;, &quot;%DOC%&quot; ] &#125;, &#123; &quot;name&quot;: &quot;bibtex&quot;, &quot;command&quot;: &quot;bibtex&quot;, &quot;args&quot;: [ &quot;%DOCFILE%&quot; ] &#125; ], &quot;latex-workshop.latex.recipes&quot;: [ &#123; &quot;name&quot;: &quot;xelatex&quot;, &quot;tools&quot;: [ &quot;xelatex&quot; ] &#125;, &#123; &quot;name&quot;: &quot;xe-&gt;bib-&gt;xe-&gt;xe&quot;, &quot;tools&quot;: [ &quot;xelatex&quot;, &quot;bibtex&quot;, &quot;xelatex&quot;, &quot;xelatex&quot; ] &#125; ], VSCode 设置界面&amp;字体大小 整体界面大小：通过设置zoomlevel大小，可整体调节界面字体的大小（eg. -0.5） 编辑框字体大小：editor 命令行字体大小：terminal anaconda配置 anaconda是python的一个开源发行版本, 基于condo开发的, 集成了很多常用的数据分析的python包, 还可用来管理python包和开发环境.管理包是指: anaconda可用来方便地安装/卸载/更新包(和pip功能类似).管理开发环境是指: anaconda可以建立不同的开发环境(python2/python3..), 以满足不同的项目需求.anaconda和homebrew区别: homebrew是针对mac的一个包管理软件, 不仅可以安装管理python, 还可以安装管理其他开源软件; anaconda则是python的一个开源发行版本, 针对用python进行数据分析. 如何使用ana进行python开发:anaconda默认有一个base环境, 即最基础python的环境(取决于一开始下载的ana版本); 还可以自己再建立其他python环境.在ana中设置好python环境后, VScode中shift+command+p打开命令行, python interprtor select选择相应的环境即可. 安装pytorch: conda install pytorch torchvision -c pytorch jupyter文件目录是执行juypter notebook时的目录，和anaconda环境无关。 Eclipse和Tomact配置 tomact中运行的项目理论上应该在webapps目录下(表现为出现以项目名作为名字的文件夹)，但这需要eclipse部署才可以，而eclipse默认是不部署项目的，因此需要设置。不设置的话项目是以缓存文件的形式运行在tomact中，并不会出现实体文件夹。配置方法：eclispe底部栏server-双击tomact服务器-serverlocation中选中间项-Deploy path写为wepapps 关于部署jar包， 方法1：直接把jar包放到lib目录下。若eclipse设置了自动部署，相关的jar包也会导入到tomact项目，即可方便地以项目为单位进行包管理。自动部署方法https://blog.csdn.net/supercyclone/article/details/18939473 方法2：手动将jar包放到tomact 的webapp/lib目录下 项目文件位置：src文件下放java代码，webcontent下放jsp/html/css，webcontent/web-inf/lib下放jar包。 eclipse source-format自动调整代码缩进 win10配置 取消登陆密码：cmd输入netplwiz，取消勾选“要使用本计算机，用户必须输入用户名和密码”，之后会让你输入一套用户名和密码，每次开机系统即自动用这个账号密码来登陆。若因为某种原因这套账号密码错了，系统就无法自动登陆了，登陆界面还会多出一个账户。 如何切换全/半角有时候打字会莫名触发全/半角开关，导致输入字母间变为全角模式，间距特别大。而默认切换全/半角的开关Shift+Space被禁掉了，正常情况win10又只显示一个“输入指示符合”（日期左边），因此要切换全/半角就只能手动调出语言栏：右键日期左边的输入指示符号-显示语言栏-右键还原语言栏-点击那个太阳/月亮符号即可。 如何隐藏语言栏右击语言栏符号-高级键盘设置-取消勾选“使用桌面语言栏（如果可用）” Windows下如何在当前目录下，打开cmd命令窗口在当前目录下，按下shift + 鼠标右键，会出现“在此处打开命令窗口”的字样，然后点击即可。 Win下python装scrapy1、pip install scrapy测试是否装好：&gt;&gt;&gt;import scrapy&gt;&gt;&gt;scrapy.version_info，正常安装即会出现版本号，如(1,3,3)再在shell(git bash就行)中输scrapy，正常安装会出现相关提示信息 2、运行scrapy会提示找不到win32api，用pip装：pip install pypiwin32==220 dev-c++配置tools-环境-中文tools-enviroment-watch variable mouse，debug自动查看变量ctrl+滚轮，调代码大小tools-editor-code completion，代码补全tools-configure shortcuts-comment，设置注释快捷键。注释ctrl+k，取消注释ctrl+l。 masm配置 dosbox挂载masm： 123mount c d:\\masm //挂载masmc: //转到C盘debug //进入debug模式，之后即可输入命令 masm debug 命令-a命令：输入汇编指令-u命令：查看汇编代码；-t命令：执行下一条语句-g + 内存：跳转到该内存所对应的语句（再用t命令执行该条命令）-r命令：查看寄存器的内容（后可直接接寄存器的名称，就只查看该寄存器的内容）-d命令：后接内存地址，查看该地址后面8 * 16个字节空间的地址（每行16个字节，共8行）后面是对应的字符‘.’表示没有该数字对应的字符 debug 标志寄存器顺序：OF DF XX SF ZF XX PF CF 福昕阅读器 取消全屏模式下左键向下翻页/右键向上翻页功能：文件-偏好设置-全屏设置，对应项勾选掉即可。 Itunes 删除同步的文件：在总的界面上，先在下拉框选择影片，再点击家庭视频，右侧出现你有同步过的视频，然后把鼠标放在影视图片后面的信息那里（就是名称或者艺人那，就是不能放在图标上，放在图标上是没有删除的），点右键最下面一个,从资料库删除，点他就好了 CSDN打开慢 csdn打开慢, 是因为其广告加载有问题的，只需要在 C:\\Windows\\System32\\drivers\\etc\\hosts 文件中 添加这一行就可以了: 127.0.0.1 allyes.com Mac下Hexo配置命令要切到blog的目录下执行 本地预览：hexo server -g 部署服务端：hexo deploy -g 如果本地修改了主题配置，部署远程之前需要hexo clean清除之前的缓存文件，否则远程不会同步更新；且要清除浏览器缓存数据（chrome-more tools-clear browsing data）。","categories":[],"tags":[{"name":"Other","slug":"Other","permalink":"https://renli1024.github.io/tags/Other/"}]},{"title":"前端相关只是","slug":"Other/前端相关","date":"2018-01-05T01:19:00.000Z","updated":"2019-08-02T12:44:58.174Z","comments":true,"path":"2018/01/05/Other/前端相关/","link":"","permalink":"https://renli1024.github.io/2018/01/05/Other/前端相关/","excerpt":"","text":"如何调试前端代码 前端的代码都是可以在网页上直接修改的（因为不涉及到服务器，都是加载到你本地运行的），因此html、css、js都可以在本地就调试、修改。 调试方法：借助chrome的developer tool即可，里面的Source栏可以查看、调试源代码，Console栏可以查看输出信息。","categories":[],"tags":[{"name":"Other","slug":"Other","permalink":"https://renli1024.github.io/tags/Other/"}]},{"title":"Something_staged","slug":"Other/something_staged","date":"2018-01-01T00:15:00.000Z","updated":"2019-07-24T06:56:37.213Z","comments":true,"path":"2018/01/01/Other/something_staged/","link":"","permalink":"https://renli1024.github.io/2018/01/01/Other/something_staged/","excerpt":"暂存区：不知道记哪先记这里好了。","text":"暂存区：不知道记哪先记这里好了。","categories":[],"tags":[{"name":"Other","slug":"Other","permalink":"https://renli1024.github.io/tags/Other/"}]},{"title":"Mac OS X操作","slug":"Other/Mac备忘","date":"2017-01-19T00:15:00.000Z","updated":"2019-07-31T08:33:01.419Z","comments":true,"path":"2017/01/19/Other/Mac备忘/","link":"","permalink":"https://renli1024.github.io/2017/01/19/Other/Mac备忘/","excerpt":"","text":"购买在线下 AppleStore直营零售店买，全国统一定价；但若想要定制版（加内存、加硬盘），需要在官网买。买了三年的保修：电池不耐用了就可以换（电量小于80%），键盘有问题也可以换，所有的配件包括电源线都可以修。送了2300的beats耳机买mac14天无条件退换退货日期：2018-9-22延长保修计划：保修期到2021-9-7送的耳机：Beats Solo3 Wireless头戴式耳机-磨砂黑 快捷键编程：VSCode，eclipse，mysql，三指拖移：设置里设置分屏：长按绿箭切换屏幕：control+左右键/四指滑动Adobe reader中超链接跳转完，再跳转回原来页面：command+左右键； command相当于win中的cntrol，截图：command+shift+4touchbar设置：偏好设置-键盘-自定义功能栏chrome：com+con+f 全屏com+shi+f 全屏下是否显示标签页显示隐藏文件：com+shift+. 关闭软件的几种方法：最小化：后台还在运行关闭：后台不再运行了，但还保留com+q：彻底退出com+h：隐藏软件，软件还在后台运行（com+tab可以切换）中文输入法下默认英文标点: 勾选use halfwidth punctuation即可 Mac终端使用ctrl+d：删除一个字符，如果没有字符的话就相当于发送Eofctrl+c：取消当前行命令ctrl+z：挂起当前进程 苹果理念桌面不要放东西电脑不用关机，你手机关过机吗？电脑不用要鼠标。你安装的东西你自己删，别人不能给你电脑上随便安装，也不能随便去掉。 一些软件浏览器绿（护眼绿、豆沙绿）：C7EDCC较深一点：C1E6C6 adobloc去除百度右侧边广告：baidu.com###con-arbaidu.com##.QgDbJYbaidu.com##.DyOnwrbaidu.com###cr-contentbaidu.com###foot 学校vpn：上vpn.whut.edu.cn下载easyconnect for Mac 解压缩软件：Mac默认的解压缩软件只能ziprar格式：the unarchiver（app store下） pdf阅读器：adobe reader DC改背景色：首选项-辅助工具-替换文档颜色默认隐藏右边窗格：首选项-文档-记住工具窗格当前状态默认隐藏左边窗格：首选项-文档-重新打开文档时恢复上次视图设置 剪视频：final cut pro 轻量级修图：GIMP Mac默认无法读取ntfs格式硬盘：下载软件，mounty 移动硬盘分区：要把移动硬盘格式化为OS X扩展的格式，然后才能分区，每个分区可以再重新格式化为你想要的格式 向印象笔记不带格式粘贴：粘贴后shift+command+F，设为纯文本。 Mac磁盘格式：APFS：Mac默认的磁盘格式（win无法读写）Mac 扩展，Mac 扩展（日志式）：区别是后者多了日志功能，会把系统启动，软件安装及故障等保存为记录文件。Mac 扩展（区分大小写）Mac 扩展日志（区分大小写）：意思是aw.txt 和AW.txt是否会被认作不同的文件。mac默认是不区分大小写的，所以一般格式化成Mac 扩展（日志式）。FAT32和NTFS都是windows下的分区格式，FAT32兼容性好（win/mac都可以），但是不支持4G以上大文件；ntfs支持4G大文件，但在mac下只能读无法写。exFAT：windows/Mac都兼容。 视频播放器：IINA：不过要设置快进快退的时长和模式（exact模式），在keybing中设置。 卸载软件的软件：App Cleaner &amp; Uninstaller 录屏软件：apowersoft Screen Recorder 使鼠标和触摸板滚动方向相反：Scroll Server，开源软件，在官网上下载 调出符号键盘快捷键：control+command+space 用VirtualBox装win7 something neededVirtualBox：直接官网下Win7：ThinPC版，32位，原因：相当于轻量级win7，内存需求少，性能也够用VBoxGuestAdditions：Mac和win共享文件夹必须的拓展。 安装安装VBoxGuestAdditions：官网上（http://download.virtualbox.org/virtualbox/）找对应版本的virtualbox，点进去找.iso文件下载；先打开WinDows系统，devices-optical drives-选择对应的.iso文件挂载；之后在Win磁盘中选择.iso文件，安装x86版本即可。 Mac/win共享复制粘贴：devices-share dclipboard-bidirectional 键盘位对应|Windows|Mac||-|-||Win键|右command||ctrl|control| Windows txt文件到mac上乱码, 将GB2312转化为UTF-8iconv -f GB2312 -t UTF-8 源文件名.txt &gt; 目标文件名.txt Visual Studio for mac批量注释快捷键：command + /，取消注释也是这个。 去EasyConnect的EasyMonitor开机启动项有部分软件的开机启动项放在 /Library/LaunchDaemons 使用 sudo launchctl unload xxx.plist 可以去掉某个软件的开机自启 深信服的 EasyConnect 有一个进程叫做 EasyMonitor 可以说是非常流氓了，开机自启 + 常驻内存 + 内存泄露，时间长了以后会占用 1g 以上的内存。 它的 plist 位于 /Library/LaunchDaemons/com.sangfor.EasyMonitor.plist 使用上述命令可以干掉它。 干掉他这个进程非常开心，但是会遇到一个问题，再次启动 EasyConnect 的时候，它不乐意了，会提示初始化失败，请重新安装，这时候就得重新 load 这个 plist 了，执行 sudo launchctl load /Library/LaunchDaemons/com.sangfor.EasyMonitor.plist Windows下文件在mac上解压缩乱码 乱码问题只存在于中文字符，英文和数字都不存在此问题。因为windows的字符编码是gbk，mac则是unicode，这两者中文编码不统一，所以会有乱码问腿。 解决：使用The Unarchiever解压，不要用mac系统自动自带的解压缩软件。","categories":[],"tags":[{"name":"Other","slug":"Other","permalink":"https://renli1024.github.io/tags/Other/"}]}]}