<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>TensorFlow模型保存和重新加载 | Ren Li&#39;s blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
    <meta name="keywords" content="Ren Li's Blog" />
  
  <meta name="description" content="训练好的模型参数保存起来，以便以后直接使用或进行进一步的训练，这是我们经常要做的事情，本文对TensorFlow模型保存和重新加载的方法进行了介绍。">
<meta name="keywords" content="TensorFlow">
<meta property="og:type" content="article">
<meta property="og:title" content="TensorFlow模型保存和重新加载">
<meta property="og:url" content="https://renli1024.github.io/2019/04/03/TensorFlow/TensorFlow模型保存和加载/index.html">
<meta property="og:site_name" content="Ren Li&#39;s blog">
<meta property="og:description" content="训练好的模型参数保存起来，以便以后直接使用或进行进一步的训练，这是我们经常要做的事情，本文对TensorFlow模型保存和重新加载的方法进行了介绍。">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2019-06-12T03:22:06.269Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="TensorFlow模型保存和重新加载">
<meta name="twitter:description" content="训练好的模型参数保存起来，以便以后直接使用或进行进一步的训练，这是我们经常要做的事情，本文对TensorFlow模型保存和重新加载的方法进行了介绍。">
  
  
    <link rel="icon" href="/favicon.ico">
  
  <link href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  <script src="/js/pace.min.js"></script>
  

  
  

</head>

<body>
  <div id="container">
      <header id="header">
    <div id="header-outer">
        <div id="header-menu" class="header-menu-pos animated">
            <div class="header-menu-container">
                <a href="/" class="left">
                    <span class="site-title">Ren Li&#39;s Blog</span>
                </a>
                <nav id="header-menu-nav" class="right">
                    
                    <a  href="/">
                        <i class="fa fa-home"></i>
                        <span>Home</span>
                    </a>
                    
                    <a  href="/archives">
                        <i class="fa fa-archive"></i>
                        <span>Archives</span>
                    </a>
                    
                    <a  href="https://github.com/lrStyle">
                        <i class="fa fa-user"></i>
                        <span>Github</span>
                    </a>
                    
                </nav>
                <a class="mobile-header-menu-button">
                    <i class="fa fa-bars"></i>
                </a>
            </div>
        </div>
    </div>
</header>
      <div class="outer">
        <section id="main" class="body-wrap"><article id="post-TensorFlow/TensorFlow模型保存和加载" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 class="post-title" itemprop="name">
      TensorFlow模型保存和重新加载
    </h1>
    <div class="post-title-bar">
      <ul>
          
        <li>
          <i class="fa fa-calendar"></i>  2019-04-03
        </li>
        
      </ul>
    </div>
  

          
      </header>
    
    <div class="article-entry post-content" itemprop="articleBody">
      
            
            <p>训练好的模型参数保存起来，以便以后直接使用或进行进一步的训练，这是我们经常要做的事情，本文对TensorFlow模型保存和重新加载的方法进行了介绍。<br><a id="more"></a></p>
<ul>
<li>保存模型本质上保存的是模型的各项参数，对神经网络来说就是网络的结构信息、各个边的权值等，tf中提供了两种可以用来保存模型的格式：<ul>
<li>checkpoints格式，a format dependent on the code that created the model。对应的tf.train.Saver类。</li>
<li>SavedModel格式，a format independent of the code that created the model。对应tf.saved_model模块。</li>
</ul>
</li>
</ul>
<h2 id="tf-train-Saver"><a href="#tf-train-Saver" class="headerlink" title="tf.train.Saver"></a>tf.train.Saver</h2><h3 id="基本方法"><a href="#基本方法" class="headerlink" title="基本方法"></a>基本方法</h3><p>Saver类保存模型的基本方法为：<br>1、定义变量<br>2、使用Saver.save()方法保存<br>3、重新定义变量<br>4、使用Saver.restore()方法加载</p>
<ul>
<li>这种方法要求按照原有模型重新定义一遍变量和网络结构，restore()方法会将保存的值加载到对应的变量中（即加载到名字相同的变量）。</li>
<li>因为重新定义一遍网络太过麻烦，且要保证重新定义的变量名字、类型都与原变量相同，因此这种方法实际用处不大。</li>
<li>example code：<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># save the model</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf  </span><br><span class="line"></span><br><span class="line">W = tf.Variable([[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>]],dtype = tf.float32,name=<span class="string">'W'</span>) </span><br><span class="line">v = tf.Variable([[<span class="number">4</span>,<span class="number">4</span>],[<span class="number">5</span>,<span class="number">5</span>]], dtype = tf.int32, name=<span class="string">'v'</span>)</span><br><span class="line">s = tf.train.Saver()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    s.save(sess, <span class="string">"run/model"</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment"># restore the model</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 类型必须相同</span></span><br><span class="line">W = tf.Variable(tf.zeros([<span class="number">2</span>,<span class="number">3</span>], dtype = tf.float32), name=<span class="string">'W'</span>) </span><br><span class="line">v = tf.Variable(tf.zeros([<span class="number">2</span>,<span class="number">2</span>], dtype = tf.int32), name=<span class="string">'v'</span>)</span><br><span class="line">s = tf.train.Saver()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    s.restore(sess, <span class="string">'run/model'</span>) <span class="comment"># 只用传入文件前缀即可</span></span><br><span class="line">    print(W.eval())</span><br><span class="line">    print(v.eval())</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="不需要重新定义网络结构的加载方法"><a href="#不需要重新定义网络结构的加载方法" class="headerlink" title="不需要重新定义网络结构的加载方法"></a>不需要重新定义网络结构的加载方法</h3><p>很多时候我们都希望能够读取一个文件然后直接使用模型，而不是还要把模型重新定义一遍，因此就有了这种方法。基本流程为：<br>1、定义变量<br>2、使用Saver.save()方法保存<br>3、使用tf.train.import_meta_graph()加载网络结构，会返回一个saver对象<br>4、使用saver.restore()方法恢复网络中的变量值<br>5、使用graph.get_operation_by_name()和graph.get_tensor_by_name()方法获取op和tensor；使用collection机制获取之前保存的值。</p>
<ul>
<li><p>example code：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 不需要定义网络结构的方法</span></span><br><span class="line"><span class="comment"># store the model</span></span><br><span class="line">W = tf.Variable([[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>]],dtype = tf.float32,name=<span class="string">'W'</span>) </span><br><span class="line">v = tf.Variable([[<span class="number">4</span>,<span class="number">4</span>],[<span class="number">5</span>,<span class="number">5</span>]], name=<span class="string">'v'</span>)</span><br><span class="line">b = tf.Variable([[<span class="number">7</span>,<span class="number">7</span>], [<span class="number">8</span>,<span class="number">8</span>]], name=<span class="string">'b'</span>)</span><br><span class="line">tf.add_to_collection(<span class="string">'b_collection'</span>, b)</span><br><span class="line">s = tf.train.Saver()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    s.save(sess, <span class="string">"run/model"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># restore the model</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    s = tf.train.import_meta_graph(<span class="string">"run/model.meta"</span>)</span><br><span class="line">    s.restore(sess, <span class="string">"run/model"</span>) <span class="comment"># 只用传入文件前缀即可</span></span><br><span class="line">    graph = tf.get_default_graph()</span><br><span class="line">    W = graph.get_tensor_by_name(<span class="string">"W:0"</span>)</span><br><span class="line">    v = graph.get_tensor_by_name(<span class="string">"v:0"</span>)</span><br><span class="line">    b = tf.get_collection(<span class="string">"b_collection"</span>)[<span class="number">0</span>]</span><br><span class="line">    print(W.eval())</span><br><span class="line">    print(v.eval())</span><br><span class="line">    print(b.eval())</span><br></pre></td></tr></table></figure>
</li>
<li><p>如何获取op：<code>tf.Graph.get_operation_by_name(&#39;name&#39;)</code></p>
</li>
<li>如何获取tensor/variable/placeholder：<code>tf.Graph.get_tensor_by_name(&#39;name&#39;)</code>，注意tensor的命名规则：<code>&lt;op_name&gt;:&lt;output_index&gt;</code>。</li>
<li>对于Variable，<code>get_tensor_by_name</code>是获取了其内部封装的tensor，但可以像使用Variable那样使用这个的tensor（因为variable的外部op如<code>v/initial_value</code>,  <code>v/Assign</code>, <code>v/read</code>也是被保留在图中的）。</li>
<li>saver只会存tensorflow相关的数据：如tensor、operation和collection，对于python的变量类型（如string，int），saver默认不会保存，可以通过collection来存（但需要注意：string在collection中是以b’str’形式保存的，取出后需要转化为utf-8格式）。</li>
</ul>
<h4 id="如何重新开始训练模型"><a href="#如何重新开始训练模型" class="headerlink" title="如何重新开始训练模型"></a>如何重新开始训练模型</h4><ul>
<li>在初次定义模型时，不要把输入数据、标记数据定义为tensor类型，这样saver就不会保存训练数据，节省保存模型的大小。</li>
<li>恢复模型后可重新生成训练数据来训练，数据一般也会做shffule处理，所以不用担心会一直训练某一小部分的数据。</li>
<li>初次定义模型时养成好习惯，对tensor/opertaion等都要起好名字，这样才能在以后恢复。</li>
<li>需要恢复的重要变量有：train_op，loss，global_step，模型输入的placeholder等。训练过程其实就是<code>sess.run(loss, train_op)</code>，所以这些变量尤为重要。</li>
<li>不需要恢复optimizer类，只需要恢复<code>train_op</code>即可，<code>train_op</code>中就已经包含了当初定义的optimizer信息。</li>
<li>恢复模型后不用再<code>sess.run(tf.global_variables_initializer())</code>，否则保存的变量值都会被重新覆盖掉。</li>
</ul>
<h3 id="模型的保存格式"><a href="#模型的保存格式" class="headerlink" title="模型的保存格式"></a>模型的保存格式</h3><ul>
<li>模型和数据会被保存为三个文件：<code>filename.data-00000-of-00001</code>、<code>filename.index</code>、<code>filename.meta</code>，三个文件名字都是一样的，只是后缀不同。</li>
<li>三个文件作用如下：<code>.meta</code>文件存储计算图结构，<code>.data</code>文件存储计算图中所有的变量值，<code>.index</code>文件则负责指示如何在<code>.data</code>文件中查找计算图变量对应的值（相当于一个<code>.meta</code>文件和<code>.data</code>文件的映射）。</li>
</ul>
<h3 id="init"><a href="#init" class="headerlink" title="init"></a><strong>init</strong></h3><p><strong>init</strong>(<br>    var_list=None,<br>    reshape=False,<br>    sharded=False,<br>    max_to_keep=5,<br>    keep_checkpoint_every_n_hours=10000.0,<br>    name=None,<br>    restore_sequentially=False,<br>    saver_def=None,<br>    builder=None,<br>    defer_build=False,<br>    allow_empty=False,<br>    write_version=tf.train.SaverDef.V2,<br>    pad_step_number=False,<br>    save_relative_paths=False,<br>    filename=None<br>)</p>
<ul>
<li>参数解释：<ul>
<li>var_list：指定要保存的变量，默认是保存所传入Session中的全部变量；</li>
<li>max_to_keep：最多保存的模型数量，默认为5，即只保存最近的5次模型训练结果；若为None或0，则保存所有的模型。</li>
<li>keep_checkpoint_every_n_hours：每隔多长时间保存一次模型；</li>
<li>通常情况下直接调用构造函数即可，不用指定参数。</li>
</ul>
</li>
</ul>
<h3 id="tf-train-Saver-save"><a href="#tf-train-Saver-save" class="headerlink" title="tf.train.Saver.save()"></a>tf.train.Saver.save()</h3><p>save(<br>    sess,<br>    save_path,<br>    global_step=None,<br>    latest_filename=None,<br>    meta_graph_suffix=’meta’,<br>    write_meta_graph=True,<br>    write_state=True,<br>    strip_default_attrs=False<br>)</p>
<ul>
<li>函数作用：保存模型。</li>
<li>参数解释：<ul>
<li>sess：运行模型的session，默认是将session中所有的参数都保存下来；</li>
<li>save_path：保存模型的路径，可以是相对路径，也可以是绝对路径。</li>
<li>global_step：文件名后缀，用训练步数对文件名添加的数字标记。</li>
<li>注1：save_path其实是模型文件名的一部分（前缀），比如如果值为”ckpt/mnist”，会将模型保存到ckpt目录下，文件名为”mnist-xxx”，xxx为后缀，由global_step指定。</li>
<li>注2：无需事先创建目录，若路径中的目录不存在tf会自动创建。</li>
</ul>
</li>
<li>return：返回文件的绝对路径，type：string。</li>
</ul>
<h3 id="tf-train-Saver-restore"><a href="#tf-train-Saver-restore" class="headerlink" title="tf.train.Saver.restore()"></a>tf.train.Saver.restore()</h3><p>restore(<br>    sess,<br>    save_path<br>)</p>
<ul>
<li>函数作用：恢复之前保存的模型。</li>
<li>参数解释：<ul>
<li>sess：要恢复到哪个session；</li>
<li>save_path：文件保存的路径。可直接传入<code>save()</code>函数的返回值来掉用。</li>
</ul>
</li>
<li>return：void</li>
</ul>
<h3 id="tf-train-import-meta-graph"><a href="#tf-train-import-meta-graph" class="headerlink" title="tf.train.import_meta_graph"></a>tf.train.import_meta_graph</h3><p>tf.train.import_meta_graph(<br>    meta_graph_or_file,<br>    clear_devices=False,<br>    import_scope=None,<br>    **kwargs<br>)</p>
<ul>
<li>函数作用：加载计算图结构信息。</li>
<li>参数解释：<ul>
<li>meta_graph_or_file：.meta后缀文件路径</li>
</ul>
</li>
<li>return：返回一个Saver对象，可后续进行restore操作</li>
</ul>
<h3 id="tf-train-Saver-last-checkpoints"><a href="#tf-train-Saver-last-checkpoints" class="headerlink" title="tf.train.Saver.last_checkpoints"></a>tf.train.Saver.last_checkpoints</h3><ul>
<li>Saver类的一个属性，type：list，保存了储存在磁盘上的模型的名字（包括路径），依照产生顺序从旧到新排列。</li>
<li>list中任何一个元素都可以直接作为参数传给<code>restore()</code>函数。</li>
</ul>

            <div class="post-copyright">
    <hr />
    <div class="content">
        <p>Post Date： 2019-04-03</p>
        <p>版权声明：&nbsp;本文为原创文章，转载请注明出处</p>
    </div>
</div>

      
        
            

        
    </div>
    <footer class="article-footer">
        
        <ul class="article-footer-menu">
            
            
  <li class="article-footer-tags">
    <i class="fa fa-tags"></i>
      
    <a href="/tags/TensorFlow/" class="color1">TensorFlow</a>
      
  </li>

        </ul>
        
    </footer>
  </div>
</article>


    <aside class="post-toc-pos post-toc-top" id="post-toc">
        <nav class="post-toc-wrap">
            <ol class="post-toc"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#tf-train-Saver"><span class="post-toc-number">1.</span> <span class="post-toc-text">tf.train.Saver</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#基本方法"><span class="post-toc-number">1.1.</span> <span class="post-toc-text">基本方法</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#不需要重新定义网络结构的加载方法"><span class="post-toc-number">1.2.</span> <span class="post-toc-text">不需要重新定义网络结构的加载方法</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#如何重新开始训练模型"><span class="post-toc-number">1.2.1.</span> <span class="post-toc-text">如何重新开始训练模型</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#模型的保存格式"><span class="post-toc-number">1.3.</span> <span class="post-toc-text">模型的保存格式</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#init"><span class="post-toc-number">1.4.</span> <span class="post-toc-text">init</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#tf-train-Saver-save"><span class="post-toc-number">1.5.</span> <span class="post-toc-text">tf.train.Saver.save()</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#tf-train-Saver-restore"><span class="post-toc-number">1.6.</span> <span class="post-toc-text">tf.train.Saver.restore()</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#tf-train-import-meta-graph"><span class="post-toc-number">1.7.</span> <span class="post-toc-text">tf.train.import_meta_graph</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#tf-train-Saver-last-checkpoints"><span class="post-toc-number">1.8.</span> <span class="post-toc-text">tf.train.Saver.last_checkpoints</span></a></li></ol></li></ol>
        </nav>
    </aside>
    



    
</section>
        
      </div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info" class="inner">
      <p>
        Powered by  <a href="http://hexo.io/" target="_blank">Hexo</a>
        Theme <a href="//github.com/wongminho/hexo-theme-miho" target="_blank">MiHo</a>
      &copy; 2019 Ren Li<br>
      </p>
    </div>
  </div>
</footer>
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<script src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
<script>
  var mihoConfig = {
      root: "https://renli1024.github.io",
      animate: false,
      isHome: false,
      share: false,
      reward: 1
  }
</script>
<div class="sidebar">
    <div id="sidebar-search" title="Search">
        <i class="fa fa-search"></i>
    </div>
    <div id="sidebar-category" title="Categories">
        <i class="fa fa-book"></i>
    </div>
    <div id="sidebar-tag" title="Tags">
        <i class="fa fa-tags"></i>
    </div>
    <div id="sidebar-top">
        <span class="sidebar-top-icon"><i class="fa fa-angle-up"></i></span>
    </div>
</div>
<div class="sidebar-menu-box" id="sidebar-menu-box">
    <div class="sidebar-menu-box-container">
        <div id="sidebar-menu-box-categories">
            
        </div>
        <div id="sidebar-menu-box-tags">
            <a href="/tags/Algorithm/" style="font-size: 13.33px;">Algorithm</a> <a href="/tags/C/" style="font-size: 10px;">C++</a> <a href="/tags/C-Sharp/" style="font-size: 10px;">C_Sharp</a> <a href="/tags/English/" style="font-size: 15px;">English</a> <a href="/tags/Git/" style="font-size: 10px;">Git</a> <a href="/tags/JSP/" style="font-size: 10px;">JSP</a> <a href="/tags/Java/" style="font-size: 10px;">Java</a> <a href="/tags/Lingo/" style="font-size: 10px;">Lingo</a> <a href="/tags/Linux/" style="font-size: 11.67px;">Linux</a> <a href="/tags/Mac/" style="font-size: 11.67px;">Mac</a> <a href="/tags/MachineLearning/" style="font-size: 10px;">MachineLearning</a> <a href="/tags/Mathematics/" style="font-size: 11.67px;">Mathematics</a> <a href="/tags/Matlab/" style="font-size: 11.67px;">Matlab</a> <a href="/tags/Network/" style="font-size: 16.67px;">Network</a> <a href="/tags/Other/" style="font-size: 20px;">Other</a> <a href="/tags/Paper-Notes/" style="font-size: 15px;">Paper Notes</a> <a href="/tags/Python/" style="font-size: 18.33px;">Python</a> <a href="/tags/SQL/" style="font-size: 10px;">SQL</a> <a href="/tags/Swift/" style="font-size: 10px;">Swift</a> <a href="/tags/TensorFlow/" style="font-size: 18.33px;">TensorFlow</a> <a href="/tags/cs224n/" style="font-size: 16.67px;">cs224n</a> <a href="/tags/正则表达式/" style="font-size: 10px;">正则表达式</a> <a href="/tags/课程笔记/" style="font-size: 10px;">课程笔记</a>
        </div>
    </div>
    <a href="javascript:;" class="sidebar-menu-box-close">&times;</a>
</div>
<div class="mobile-header-menu-nav" id="mobile-header-menu-nav">
    <div class="mobile-header-menu-container">
        <span class="title">Menus</span>
        <ul class="mobile-header-menu-navbar">
            
            <li>
                <a  href="/">
                    <i class="fa fa-home"></i><span>Home</span>
                </a>
            </li>
            
            <li>
                <a  href="/archives">
                    <i class="fa fa-archive"></i><span>Archives</span>
                </a>
            </li>
            
            <li>
                <a  href="https://github.com/lrStyle">
                    <i class="fa fa-user"></i><span>Github</span>
                </a>
            </li>
            
        </ul>
    </div>
    <div class="mobile-header-tag-container">
        <span class="title">Tags</span>
        <div id="mobile-header-container-tags">
            <a href="/tags/Algorithm/" style="font-size: 13.33px;">Algorithm</a> <a href="/tags/C/" style="font-size: 10px;">C++</a> <a href="/tags/C-Sharp/" style="font-size: 10px;">C_Sharp</a> <a href="/tags/English/" style="font-size: 15px;">English</a> <a href="/tags/Git/" style="font-size: 10px;">Git</a> <a href="/tags/JSP/" style="font-size: 10px;">JSP</a> <a href="/tags/Java/" style="font-size: 10px;">Java</a> <a href="/tags/Lingo/" style="font-size: 10px;">Lingo</a> <a href="/tags/Linux/" style="font-size: 11.67px;">Linux</a> <a href="/tags/Mac/" style="font-size: 11.67px;">Mac</a> <a href="/tags/MachineLearning/" style="font-size: 10px;">MachineLearning</a> <a href="/tags/Mathematics/" style="font-size: 11.67px;">Mathematics</a> <a href="/tags/Matlab/" style="font-size: 11.67px;">Matlab</a> <a href="/tags/Network/" style="font-size: 16.67px;">Network</a> <a href="/tags/Other/" style="font-size: 20px;">Other</a> <a href="/tags/Paper-Notes/" style="font-size: 15px;">Paper Notes</a> <a href="/tags/Python/" style="font-size: 18.33px;">Python</a> <a href="/tags/SQL/" style="font-size: 10px;">SQL</a> <a href="/tags/Swift/" style="font-size: 10px;">Swift</a> <a href="/tags/TensorFlow/" style="font-size: 18.33px;">TensorFlow</a> <a href="/tags/cs224n/" style="font-size: 16.67px;">cs224n</a> <a href="/tags/正则表达式/" style="font-size: 10px;">正则表达式</a> <a href="/tags/课程笔记/" style="font-size: 10px;">课程笔记</a>
        </div>
    </div>
</div>
<div class="search-wrap">
    <span class="search-close">&times;</span>
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
            <i class="icon icon-lg icon-chevron-left"></i>
        </a>
        <input class="search-field" placeholder="Search..." id="keywords">
        <a id="search-submit" href="javascript:;">
            <i class="fa fa-search"></i>
        </a>
    <div class="search-container" id="search-container">
        <ul class="search-result" id="search-result">
        </ul>
    </div>
</div>

<div id="search-tpl">
    <li class="search-result-item">
        <a href="{url}" class="search-item-li">
            <span class="search-item-li-title" title="{title}">{title}</span>
        </a>
    </li>
</div>
<script src="/js/search.js"></script>
<script src="/js/main.js"></script>









  <script src="/js/pop-img.js"></script>
  <script>
     $(".article-entry p img").popImg();
  </script>

  </div>
</body>
</html>